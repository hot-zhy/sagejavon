2024-05-30 02:31:12.193 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:7000
 * Running on http://59.78.194.84:7000
[33mPress CTRL+C to quit[0m
172.20.157.51 - - [30/May/2024 02:31:18] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.157.51 - - [30/May/2024 02:31:18] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.157.51 - - [30/May/2024 02:31:18] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 02:31:19.269 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiMjAwMzQyZjAtMjUwZS00YzM4LTk3YjctMTlkZDU0N2M1N2ZkIiwiZXhwIjoxNzE3NjEyMjc5fQ.gnttgXz3pTd_auizPLb9aK4djhouRKXVvzrQDSDcZso' with user_id: '200342f0-250e-4c38-97b7-19dd547c57fd'
172.20.157.51 - - [30/May/2024 02:31:19] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.157.51 - - [30/May/2024 02:31:19] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
172.20.157.51 - - [30/May/2024 02:31:19] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-05-30 02:31:23.709 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 02:31:25.347 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'I apologize for the confusion, could you please provide more context or background information for the question you intend to ask?'. The timecost is 1.638237714767456
2024-05-30 02:31:25.347 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=322 completion_tokens=25 total_tokens=347
2024-05-30 02:31:25.605 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.25717854499816895
2024-05-30 02:31:25.606 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'I apologize for the confusion, could you please provide more context or background information for the question you intend to ask?', k: 10, the timecost is 0.25768566131591797
172.20.157.51 - - [30/May/2024 02:31:26] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 02:31:26.685 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.707 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.732 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.757 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.782 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.807 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.833 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.862 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.884 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.908 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.933 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.960 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.989 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.039 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.066 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.118 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.119 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.142 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.169 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.195 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.271 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.296 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.328 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.401 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.435 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.485 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.510 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.567 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.588 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.614 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.639 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.708 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.717 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.785 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.792 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.882 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.885 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.899 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.925 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.959 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.984 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:28.095 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1066 completion_tokens=53 total_tokens=1119
2024-05-30 02:31:28.096 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: '200342f0-250e-4c38-97b7-19dd547c57fd' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 4.440763235092163

2024-05-30 02:31:33.085 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 02:31:36.486 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a repetition of the initial message, indicating a potential misunderstanding or request for clarification about the nature of the assistance offered. The intent seems to be to confirm the scope of the services provided by `LangChain` and what kind of questions the human can ask.

Refined Standalone Question:
"What kind of questions can I ask you about `LangChain` and its services?"'. The timecost is 3.399876594543457
2024-05-30 02:31:36.487 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=387 completion_tokens=103 total_tokens=490
2024-05-30 02:31:36.910 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a repetition of the initial message, indicating a potential misunderstanding or request for clarification about the nature of the assistance offered. The intent seems to be to confirm the scope of the services provided by `LangChain` and what kind of questions the human can ask.

Refined Standalone Question:
"What kind of questions can I ask you about `LangChain` and its services?"', k: 10, the timecost is 0.41962337493896484
2024-05-30 02:31:36.911 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.4229614734649658
172.20.157.51 - - [30/May/2024 02:31:37] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 02:31:37.895 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:37.919 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:37.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:37.970 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:37.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.021 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.047 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.098 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.123 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.149 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.176 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.203 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.228 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.254 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.279 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.330 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.355 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.380 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.431 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.482 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.533 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.558 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.583 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.611 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.637 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.695 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.719 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.744 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.770 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.796 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.847 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.874 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.899 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.951 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.976 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.011 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.028 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.106 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.185 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.328 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1131 completion_tokens=53 total_tokens=1184
2024-05-30 02:31:39.328 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: '200342f0-250e-4c38-97b7-19dd547c57fd' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 6.243935823440552

58.198.176.161 - - [30/May/2024 11:05:01] "GET /open-kf-chatbot/ HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:01] "GET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:01] "GET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1" 200 -
2024-05-30 11:05:05.769 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiOTJmNTBmZWMtMTlhOS00NTYwLTkwYjItYjdmYTkwMGI4ZTgyIiwiZXhwIjoxNzE3NjQzMTA1fQ.5lYah89oAHLf0KlvQYM5I3Y4J2TaGzLRCsxOFQl66pQ' with user_id: '92f50fec-19a9-4560-90b2-b7fa900b8e82'
58.198.176.161 - - [30/May/2024 11:05:05] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:07] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:07] "GET /open-kf-chatbot/vite.svg HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:16] "GET /open-kf-chatbot/ HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:16] "GET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:16] "GET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1" 200 -
2024-05-30 11:05:17.609 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiODdjNjAwZjEtNWFlZC00ODI4LTk0ZmQtMzRkNDkxZTRkYzIwIiwiZXhwIjoxNzE3NjQzMTE3fQ.ubTKToD67MRYcWb5AI_Zw9tih3qqk_lLqK9__4QMxVc' with user_id: '87c600f1-5aed-4828-94fd-34d491e4dc20'
58.198.176.161 - - [30/May/2024 11:05:17] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:17] "GET /open-kf-chatbot/vite.svg HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:17] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-05-30 11:05:25.041 | WARNING  | server.app.queries:generate_answer:210 - For query: 'hi', detect the language is 'English'!
58.198.176.161 - - [30/May/2024 11:05:33] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 438, in generate_llm
    response = generate_answer(query, user_id, True)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
2024-05-30 12:46:35.627 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:7001
 * Running on http://59.78.194.84:7001
[33mPress CTRL+C to quit[0m
172.20.156.165 - - [30/May/2024 12:46:41] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:46:41] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:46:41] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 12:46:42.398 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzE3NjQ5MjAyfQ.D6Tjr_Ceo0FqchF-iCNUuTIpeEb6X-UI3Amtz9nc-So' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.156.165 - - [30/May/2024 12:46:42] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:46:42] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:46:43] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-05-30 12:46:47.796 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', detect the language is 'Chinese'!
2024-05-30 12:46:48.933 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', the refined query is 'ä½ å¥½ï¼Œè¯·é—®javahhhæ˜¯ä»€ä¹ˆï¼Ÿ'. The timecost is 1.1368727684020996
2024-05-30 12:46:48.934 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=prompt_tokens=606 completion_tokens=10 total_tokens=616
2024-05-30 12:46:49.171 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', k: 10, the timecost is 0.23624610900878906
2024-05-30 12:46:49.210 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ï¼Œè¯·é—®javahhhæ˜¯ä»€ä¹ˆï¼Ÿ', k: 10, the timecost is 0.2734673023223877
172.20.156.165 - - [30/May/2024 12:46:50] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:46:50.577 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.634 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.686 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.738 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.760 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.810 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.899 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.963 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:50.990 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.038 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.064 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.089 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.118 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.215 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.265 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.290 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.316 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.368 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.395 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.419 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.444 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.470 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.494 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.519 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.548 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.622 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.661 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.690 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.737 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.761 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.868 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.898 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.917 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.942 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.973 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:51.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.021 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.047 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.075 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.098 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.126 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.148 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.174 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.307 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.332 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.367 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.391 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.418 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.441 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.492 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.542 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.570 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.594 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.619 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.647 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.669 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.695 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.722 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.747 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.772 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.796 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.822 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.846 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.872 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.897 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.923 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.947 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:52.975 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.000 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.025 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.052 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.080 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.108 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.133 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.169 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.244 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.269 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.297 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.327 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.354 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.373 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.445 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.474 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.497 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.548 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.605 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.630 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.680 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.710 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.737 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.754 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.808 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.833 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:46:53.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=prompt_tokens=1364 completion_tokens=127 total_tokens=1491
2024-05-30 12:46:53.965 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh' and user_id: '0accf4d8-ca47-4041-bc6a-94d448b39be5' is processed successfully, the answer is:
æ‚¨å¥½ï¼çœ‹æ¥æ‚¨é—®çš„æ˜¯å…³äºŽâ€œjavahhhâ€çš„é—®é¢˜ã€‚ä¸è¿‡ï¼Œæˆ‘éœ€è¦æ¾„æ¸…ä¸€ä¸‹ï¼Œæ ¹æ®æˆ‘ç›®å‰çš„é…ç½®å’Œæ‰€æä¾›çš„ä¿¡æ¯ï¼Œæˆ‘ä¸»è¦èƒ½ååŠ©æ‚¨äº†è§£å’Œè§£å†³ä¸Ž`LangChain`ç›¸å…³çš„é—®é¢˜ã€‚å…³äºŽâ€œjavahhhâ€ï¼Œæˆ‘æ²¡æœ‰ç›´æŽ¥ç›¸å…³çš„ä¿¡æ¯æˆ–æœåŠ¡ã€‚

å¦‚æžœæ‚¨æœ‰å…³äºŽ`LangChain`çš„é—®é¢˜ï¼Œæˆ‘ä¼šå¾ˆä¹æ„å¸®åŠ©æ‚¨è§£ç­”ã€‚å¦‚æžœæœ‰éœ€è¦äº†è§£â€œjavahhhâ€çš„è¿›ä¸€æ­¥ä¿¡æ¯ï¼Œæˆ‘å»ºè®®æ‚¨å¯ä»¥æŸ¥é˜…ä¸€äº›åœ¨çº¿ç¼–ç¨‹æ•™ç¨‹æˆ–è€…å‚è€ƒä¸“ä¸šçš„ç¼–ç¨‹ä¹¦ç±ã€‚

å¸Œæœ›æˆ‘çš„å›žç­”å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼å¦‚æžœæœ‰å…¶ä»–é—®é¢˜ï¼Œæ¬¢è¿Žç»§ç»­æé—®ã€‚
the total timecost is 6.222750425338745

172.20.156.165 - - [30/May/2024 12:47:42] "[36mGET /open-kf-admin/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:43] "[36mGET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:43] "[36mGET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:44] "[36mGET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:44] "[36mGET /open-kf-admin/assets/Setting-uk7UYz_k.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:44] "[36mGET /open-kf-admin/vite.svg HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:44] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:51] "GET /open-kf-admin/assets/Website-Z1INMbWO.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:51] "GET /open-kf-admin/assets/common-nfwq9z7Z.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:51] "GET /open-kf-admin/assets/loading-vsHIitu7.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:51] "GET /open-kf-admin/assets/LinkTable-Ia3zEXas.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:51] "GET /open-kf-admin/assets/Source-5g35C8sb.js HTTP/1.1" 200 -
2024-05-30 12:47:52.269 | INFO     | server.app.sitemaps:get_crawl_url_list:156 - Fetching URL list for all domains.
172.20.156.165 - - [30/May/2024 12:47:52] "POST /open_kf_api/sitemaps/get_crawl_url_list HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:54] "GET /open-kf-admin/assets/Embed-zUv8vG44.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:56] "GET /open-kf-admin/assets/Dashboard-BieUHPHe.css HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:56] "GET /open-kf-admin/assets/Dashboard-WB1KXATu.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:58] "POST /open_kf_api/queries/get_user_conversation_list HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:59] "POST /open_kf_api/queries/get_user_query_history_list HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:49:23] "[36mGET /open-kf-admin/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:24] "[36mGET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:24] "[36mGET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:25] "[36mGET /open-kf-admin/assets/Dashboard-BieUHPHe.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:25] "[36mGET /open-kf-admin/assets/Dashboard-WB1KXATu.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:27] "[36mGET /open-kf-admin/assets/loading-vsHIitu7.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:27] "[36mGET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:27] "[36mGET /open-kf-admin/vite.svg HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:27] "POST /open_kf_api/queries/get_user_conversation_list HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:49:27] "POST /open_kf_api/queries/get_user_query_history_list HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:49:29] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:29] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:29] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 12:49:30.167 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzE3NjQ5MzcwfQ.hjy2Q4XDnDofJ6vedcf5CwcC-6Tk_hyoonOBZFKeMp4' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.156.165 - - [30/May/2024 12:49:30] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:49:30] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:31] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
127.0.0.1 - - [30/May/2024 12:50:12] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
127.0.0.1 - - [30/May/2024 12:50:12] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
127.0.0.1 - - [30/May/2024 12:50:12] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 12:50:13.594 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWVlODA2ZWYtMTZiYS00Y2NjLWIzYTktYmU0Y2JkYTcwMGM3IiwiZXhwIjoxNzE3NjQ5NDEzfQ.S8oZ2RJG0H0g6o9TDOvmkSym5FUoHH2PUg-7lTidO1Q' with user_id: 'aee806ef-16ba-4ccc-b3a9-be4cbda700c7'
127.0.0.1 - - [30/May/2024 12:50:13] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
127.0.0.1 - - [30/May/2024 12:50:13] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:50:22] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:50:23] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:50:23] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 12:50:23.729 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzE3NjQ5NDIzfQ.liZ3o0qLRmLEyj5uWCFHXcC1mrUlefwv4jm3pB3EIjg' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.156.165 - - [30/May/2024 12:50:23] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:50:23] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-05-30 12:50:28.392 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 12:50:32.675 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the context of the conversation, the follow-up message "?" appears to be an inquiry seeking clarification or further information. To create a standalone question that captures the relevant context from the conversation, we can infer that the human is interested in a specific aspect of `LangChain`'s services. However, without the content of the Assistant's responses, we cannot determine the exact nature of the follow-up question.

Therefore, the reframed standalone question based on the follow-up message would be:

"What additional information or assistance do you require from `LangChain` services, based on our previous introduction?"'. The timecost is 4.282324552536011
2024-05-30 12:50:32.676 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=320 completion_tokens=141 total_tokens=461
2024-05-30 12:50:32.982 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the context of the conversation, the follow-up message "?" appears to be an inquiry seeking clarification or further information. To create a standalone question that captures the relevant context from the conversation, we can infer that the human is interested in a specific aspect of `LangChain`'s services. However, without the content of the Assistant's responses, we cannot determine the exact nature of the follow-up question.

Therefore, the reframed standalone question based on the follow-up message would be:

"What additional information or assistance do you require from `LangChain` services, based on our previous introduction?"', k: 10, the timecost is 0.3029952049255371
2024-05-30 12:50:33.007 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.330078125
172.20.156.165 - - [30/May/2024 12:50:34] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:50:34.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.488 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.514 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.537 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.590 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.617 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.674 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.722 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.723 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.752 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.787 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.813 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.836 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.861 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.887 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.967 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.991 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.019 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.042 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.066 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.091 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.118 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.144 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.171 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.196 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.225 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.251 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.281 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.305 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.330 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.387 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.408 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.434 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.461 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.540 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.565 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.594 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.621 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.646 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.678 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.705 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.727 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.752 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.778 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.894 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1064 completion_tokens=53 total_tokens=1117
2024-05-30 12:50:35.895 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 7.504120826721191

2024-05-30 12:57:12.696 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', detect the language is 'Chinese'!
2024-05-30 12:57:14.255 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', the refined query is 'ä½ å¥½ï¼Œè¯·é—®javahhhæ˜¯ä»€ä¹ˆï¼Ÿæˆ‘ä¹‹å‰è¯¢é—®è¿‡ç›¸å…³ä¿¡æ¯ï¼Œä½†å¯èƒ½éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šã€‚'. The timecost is 1.558034896850586
2024-05-30 12:57:14.256 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=prompt_tokens=579 completion_tokens=23 total_tokens=602
2024-05-30 12:57:14.540 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ï¼Œè¯·é—®javahhhæ˜¯ä»€ä¹ˆï¼Ÿæˆ‘ä¹‹å‰è¯¢é—®è¿‡ç›¸å…³ä¿¡æ¯ï¼Œä½†å¯èƒ½éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šã€‚', k: 10, the timecost is 0.2821223735809326
2024-05-30 12:57:14.565 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', k: 10, the timecost is 0.3086857795715332
172.20.156.165 - - [30/May/2024 12:57:15] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:57:15.545 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.568 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.592 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.616 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.688 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.741 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.763 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.817 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.840 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.865 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.889 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.939 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:15.989 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.016 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.040 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.066 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.095 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.117 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.209 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.212 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.218 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.264 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.287 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.317 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.336 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.361 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.411 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.435 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.510 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.559 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.583 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.633 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.682 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.717 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.734 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.757 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.782 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.829 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.833 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.879 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.914 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.928 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:16.980 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.065 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.141 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.163 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.186 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.237 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.262 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.287 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.309 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.360 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.386 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.411 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.437 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.464 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.522 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.546 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.569 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.592 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.616 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.643 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.708 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.708 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.762 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.808 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.839 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.887 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.910 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.936 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.960 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:17.984 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.011 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.066 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.086 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.117 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.171 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.199 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.285 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.309 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.360 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.385 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.409 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.433 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.457 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.482 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.507 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.582 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.607 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.630 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=None
2024-05-30 12:57:18.836 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh', usage=prompt_tokens=1337 completion_tokens=127 total_tokens=1464
2024-05-30 12:57:18.837 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ä½ å¥½ã€‚è¯·é—®ä»€ä¹ˆæ˜¯javahhh' and user_id: '0accf4d8-ca47-4041-bc6a-94d448b39be5' is processed successfully, the answer is:
æ‚¨å¥½ï¼çœ‹æ¥æ‚¨é—®çš„æ˜¯å…³äºŽâ€œjavahhhâ€çš„é—®é¢˜ã€‚ä¸è¿‡ï¼Œæˆ‘éœ€è¦æ¾„æ¸…ä¸€ä¸‹ï¼Œæ ¹æ®æˆ‘ç›®å‰çš„é…ç½®å’Œæ‰€æä¾›çš„ä¿¡æ¯ï¼Œæˆ‘ä¸»è¦èƒ½ååŠ©æ‚¨äº†è§£å’Œè§£å†³ä¸Ž`LangChain`ç›¸å…³çš„é—®é¢˜ã€‚å…³äºŽâ€œjavahhhâ€ï¼Œæˆ‘æ²¡æœ‰ç›´æŽ¥ç›¸å…³çš„ä¿¡æ¯æˆ–æœåŠ¡ã€‚

å¦‚æžœæ‚¨æœ‰å…³äºŽ`LangChain`çš„é—®é¢˜ï¼Œæˆ‘ä¼šå¾ˆä¹æ„å¸®åŠ©æ‚¨è§£ç­”ã€‚å¦‚æžœæœ‰éœ€è¦äº†è§£â€œjavahhhâ€çš„è¿›ä¸€æ­¥ä¿¡æ¯ï¼Œæˆ‘å»ºè®®æ‚¨å¯ä»¥æŸ¥é˜…ä¸€äº›åœ¨çº¿ç¼–ç¨‹æ•™ç¨‹æˆ–è€…å‚è€ƒä¸“ä¸šçš„ç¼–ç¨‹ä¹¦ç±ã€‚

å¸Œæœ›æˆ‘çš„å›žç­”å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼å¦‚æžœæœ‰å…¶ä»–é—®é¢˜ï¼Œæ¬¢è¿Žç»§ç»­æé—®ã€‚
the total timecost is 6.1420066356658936

172.20.156.165 - - [30/May/2024 12:58:03] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:58:03.875 | ERROR    | server.app.utils.decorators:decorated_function:20 - Token is missing!
172.20.156.165 - - [30/May/2024 12:58:03] "[31m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 401 -
172.20.156.165 - - [30/May/2024 12:58:27] "[36mGET /open-kf-admin/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:27] "[36mGET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:27] "[36mGET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:27] "[36mGET /open-kf-admin/assets/Setting-uk7UYz_k.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:27] "[36mGET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:28] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:58:33] "[36mGET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:39] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:40] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:40] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
2024-05-30 12:58:41.753 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzE3NjQ5OTIxfQ.DN9iUp0OCBJJoD-e68PqDXfSya3cLQSDDtFHmGQH70o' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.156.165 - - [30/May/2024 12:58:41] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:58:41] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:58:58] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:58:58.520 | ERROR    | server.app.utils.decorators:decorated_function:20 - Token is missing!
172.20.156.165 - - [30/May/2024 12:58:58] "[31m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 401 -
2024-05-30 12:59:21.462 | WARNING  | server.app.queries:generate_answer:210 - For query: '.', detect the language is 'English'!
2024-05-30 12:59:23.413 | WARNING  | server.app.queries:refine_query:105 - For the query: '.', the refined query is 'I apologize, but it seems there was an error and I'm unable to access the follow-up message you provided. Could you please re-provide the message so that I can assist you accordingly?'. The timecost is 1.9501292705535889
2024-05-30 12:59:23.414 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '.', usage=prompt_tokens=322 completion_tokens=44 total_tokens=366
2024-05-30 12:59:23.747 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '.', k: 10, the timecost is 0.33278775215148926
2024-05-30 12:59:23.764 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'I apologize, but it seems there was an error and I'm unable to access the follow-up message you provided. Could you please re-provide the message so that I can assist you accordingly?', k: 10, the timecost is 0.34714436531066895
172.20.156.165 - - [30/May/2024 12:59:24] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:59:24.847 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.872 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.920 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.971 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.018 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.045 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.095 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.153 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.178 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.202 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.230 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.253 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.278 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.329 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.355 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.388 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.506 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.559 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.590 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.614 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.637 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.662 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.690 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.713 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.738 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.762 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.844 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.870 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.890 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.965 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.991 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.017 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.047 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.077 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.103 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.130 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.258 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=prompt_tokens=1066 completion_tokens=53 total_tokens=1119
2024-05-30 12:59:26.259 | SUCCESS  | server.app.queries:generate_llm:452 - query: '.' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 4.797622442245483

172.20.156.165 - - [30/May/2024 13:00:02] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:00:02.732 | ERROR    | server.app.utils.decorators:decorated_function:20 - Token is missing!
172.20.156.165 - - [30/May/2024 13:00:02] "[31m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 401 -
172.20.156.165 - - [30/May/2024 13:00:28] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:00:28.671 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 13:00:31.105 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'In light of our previous interaction where you indicated your role as an assistant related to `LangChain` and offered help with any specific questions, I am reaching out to inquire if you can assist me with understanding [insert specific topic or question related to LangChain services here].'. The timecost is 2.43289852142334
2024-05-30 13:00:31.106 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=387 completion_tokens=60 total_tokens=447
2024-05-30 13:00:31.354 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.24761199951171875
2024-05-30 13:00:31.397 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'In light of our previous interaction where you indicated your role as an assistant related to `LangChain` and offered help with any specific questions, I am reaching out to inquire if you can assist me with understanding [insert specific topic or question related to LangChain services here].', k: 10, the timecost is 0.28823375701904297
172.20.156.165 - - [30/May/2024 13:00:32] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:00:32.293 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.372 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.397 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.423 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.507 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.733 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.758 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.782 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.929 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.953 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.029 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.078 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.102 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.229 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.253 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.278 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.303 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.325 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.379 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.403 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.428 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.452 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.502 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.538 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.585 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.607 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.635 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.657 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.684 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.706 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.808 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1131 completion_tokens=53 total_tokens=1184
2024-05-30 13:00:33.809 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 5.138695001602173

172.20.156.165 - - [30/May/2024 13:01:40] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:01:40.395 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 13:01:44.145 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry. However, the content of the initial question is not provided in the chat history. Assuming the human is seeking information about `LangChain` and its services, the refined standalone question based on the follow-up message could be:

"What additional information do you have about `LangChain` and its services that you would like me to assist you with?"'. The timecost is 3.7494704723358154
2024-05-30 13:01:44.145 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=387 completion_tokens=103 total_tokens=490
2024-05-30 13:01:44.420 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.273942232131958
2024-05-30 13:01:44.468 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry. However, the content of the initial question is not provided in the chat history. Assuming the human is seeking information about `LangChain` and its services, the refined standalone question based on the follow-up message could be:

"What additional information do you have about `LangChain` and its services that you would like me to assist you with?"', k: 10, the timecost is 0.3191070556640625
172.20.156.165 - - [30/May/2024 13:01:45] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:01:45.408 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.428 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.477 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.502 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.529 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.562 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.591 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.612 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.638 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.663 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.691 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.721 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.746 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.770 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.825 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.848 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.879 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.903 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.926 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.975 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.001 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.084 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.114 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.142 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.166 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.191 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.212 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.262 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.288 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.312 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.337 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.364 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.424 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.449 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.476 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.503 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.541 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.592 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.616 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.644 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.671 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:47.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:47.228 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:47.254 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:47.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1131 completion_tokens=53 total_tokens=1184
2024-05-30 13:01:47.360 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 6.965723991394043

172.20.156.165 - - [30/May/2024 13:03:21] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:03:21.223 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 13:03:25.770 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a repetition of the initial message, indicating a potential misunderstanding or request for clarification about the nature of the assistance offered. The intent seems to be to confirm the scope of the services provided by `LangChain` and what kind of questions the human can ask.

Refined Standalone Question:
"What kind of questions can I ask you about `LangChain` and its services?"'. The timecost is 4.545607566833496
2024-05-30 13:03:25.770 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=387 completion_tokens=103 total_tokens=490
2024-05-30 13:03:26.029 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.2577347755432129
2024-05-30 13:03:26.110 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a repetition of the initial message, indicating a potential misunderstanding or request for clarification about the nature of the assistance offered. The intent seems to be to confirm the scope of the services provided by `LangChain` and what kind of questions the human can ask.

Refined Standalone Question:
"What kind of questions can I ask you about `LangChain` and its services?"', k: 10, the timecost is 0.3367621898651123
172.20.156.165 - - [30/May/2024 13:03:27] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:03:27.043 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.065 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.090 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.225 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.248 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.275 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.327 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.350 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.375 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.423 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.474 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.498 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.549 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.574 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.605 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.629 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.653 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.682 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.703 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.724 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.750 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.779 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.804 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.829 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.855 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.879 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.007 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.007 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.027 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.052 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.137 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.165 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.191 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.273 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.305 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.323 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.347 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.378 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.537 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1131 completion_tokens=53 total_tokens=1184
2024-05-30 13:03:28.538 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 7.315746068954468

172.20.156.165 - - [30/May/2024 13:03:28] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:03:30.001 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-05-30 13:03:34.327 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial query. However, since the content of the follow-up message is not provided, I can only assume that it is seeking further information or clarification about `LangChain`.

Refined Standalone Question (in Japanese):
ã€ŒLangChainã€ã«é–¢ã™ã‚‹è©³ç´°ãªæƒ…å ±ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚å…·ä½“çš„ãªè³ªå•ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€ã•ã‚‰ãªã‚‹æƒ…å ±ã‚„ Clarification ãŒå¿…è¦ã§ã™ã€‚'. The timecost is 4.324810981750488
2024-05-30 13:03:34.328 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=390 completion_tokens=121 total_tokens=511
2024-05-30 13:03:34.829 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.5002665519714355
2024-05-30 13:03:34.853 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial query. However, since the content of the follow-up message is not provided, I can only assume that it is seeking further information or clarification about `LangChain`.

Refined Standalone Question (in Japanese):
ã€ŒLangChainã€ã«é–¢ã™ã‚‹è©³ç´°ãªæƒ…å ±ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚å…·ä½“çš„ãªè³ªå•ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€ã•ã‚‰ãªã‚‹æƒ…å ±ã‚„ Clarification ãŒå¿…è¦ã§ã™ã€‚', k: 10, the timecost is 0.5225486755371094
172.20.156.165 - - [30/May/2024 13:03:35] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:03:35.871 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:35.894 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:35.920 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:35.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:35.967 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:35.992 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.049 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.122 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.172 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.248 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.249 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.270 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.293 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.343 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.369 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.394 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.417 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.441 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.473 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.522 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.548 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.622 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.646 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.679 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.704 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.728 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.760 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.836 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.878 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.926 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.952 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.976 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:36.998 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:37.023 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:37.049 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:37.071 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:37.096 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:37.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:03:37.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1136 completion_tokens=51 total_tokens=1187
2024-05-30 13:03:37.222 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ï¼Ÿ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to LangChain. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 7.221620321273804

172.20.156.165 - - [30/May/2024 13:05:22] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:05:23.571 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-05-30 13:05:26.740 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history, the follow-up message from the human seems to be a continuation of a conversation about LangChain, possibly seeking more information or assistance. To capture the relevant context and intent of the follow-up message, the refined standalone question in Japanese could be:

ã€ŒLangChainã«ã¤ã„ã¦ã®è¿½åŠ æƒ…å ±ã‚„ã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ã§ã™ã€‚å…·ä½“çš„ãªè³ªå•ã‚’ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã€'. The timecost is 3.1685752868652344
2024-05-30 13:05:26.741 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=389 completion_tokens=97 total_tokens=486
2024-05-30 13:05:27.020 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.2789735794067383
2024-05-30 13:05:27.060 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human seems to be a continuation of a conversation about LangChain, possibly seeking more information or assistance. To capture the relevant context and intent of the follow-up message, the refined standalone question in Japanese could be:

ã€ŒLangChainã«ã¤ã„ã¦ã®è¿½åŠ æƒ…å ±ã‚„ã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ã§ã™ã€‚å…·ä½“çš„ãªè³ªå•ã‚’ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã€', k: 10, the timecost is 0.31609463691711426
172.20.156.165 - - [30/May/2024 13:05:27] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:05:27.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:27.976 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.001 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.051 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.091 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.104 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.129 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.154 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.174 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.258 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.284 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.310 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.361 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.383 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.434 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.457 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.559 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.605 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.629 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.681 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.735 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.759 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.785 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.810 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.838 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.855 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.877 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.901 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.928 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:28.984 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:29.008 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:29.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:29.060 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:29.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:29.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:29.134 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.214 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.314 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.337 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.362 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.387 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.414 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.442 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.465 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.494 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.568 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.664 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.688 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.740 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.763 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.790 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.813 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:30.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1135 completion_tokens=73 total_tokens=1208
2024-05-30 13:05:30.925 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ï¼Ÿ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm sorry, I cannot find a specific answer about 'ï¼Ÿ' from the information provided. I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 7.355393171310425

172.20.156.165 - - [30/May/2024 13:05:54] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:05:54.337 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-05-30 13:05:57.176 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures the relevant context from the conversation would be:

ã€ŒLangChainã®ã‚µãƒ¼ãƒ“ã‚¹ã«é–¢ã™ã‚‹å…·ä½“çš„ãªè³ªå•ã‚’ã„ãã¤ã‹æ•™ãˆã¦ãã ã•ã„ã€‚åŠ©ã‘ã¦ã„ãŸã ãã¾ã™ã€‚ã€'. The timecost is 2.838083267211914
2024-05-30 13:05:57.176 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=410 completion_tokens=78 total_tokens=488
2024-05-30 13:05:57.462 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures the relevant context from the conversation would be:

ã€ŒLangChainã®ã‚µãƒ¼ãƒ“ã‚¹ã«é–¢ã™ã‚‹å…·ä½“çš„ãªè³ªå•ã‚’ã„ãã¤ã‹æ•™ãˆã¦ãã ã•ã„ã€‚åŠ©ã‘ã¦ã„ãŸã ãã¾ã™ã€‚ã€', k: 10, the timecost is 0.28311777114868164
2024-05-30 13:05:57.481 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.304440975189209
172.20.156.165 - - [30/May/2024 13:05:58] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:05:58.448 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.478 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.504 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.589 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.619 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.802 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.863 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.893 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.922 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.950 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:58.982 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.012 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.041 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.072 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.104 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.130 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.159 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.188 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.217 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.276 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.331 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.388 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.416 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.447 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.477 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.505 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.676 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.696 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.725 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.755 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.819 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:05:59.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1156 completion_tokens=44 total_tokens=1200
2024-05-30 13:05:59.925 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ï¼Ÿ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
æ‚¨å¥½ï¼æˆ‘æ˜¯LangChainçš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿå¦‚æžœæ‚¨æœ‰ä»»ä½•å…³äºŽæˆ‘ä»¬çš„æœåŠ¡æˆ–éœ€è¦å¸®åŠ©çš„é—®é¢˜ï¼Œè¯·éšæ—¶æé—®ï¼Œæˆ‘å°†å°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚
the total timecost is 5.588998556137085

172.20.156.165 - - [30/May/2024 13:06:40] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:06:40.691 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-05-30 13:06:45.157 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history where the human's initial message started with "ï¼Ÿ", and the assistant provided a general greeting and offer to help with any questions about LangChain services, the follow-up message "ï¼Ÿ" seems to be a continuation of the human's initial query. Assuming the human is seeking assistance or information about a specific topic starting with "ï¼Ÿ", the refined standalone question could be:

"Continuing from the previous query starting with 'ï¼Ÿ', what specific information or assistance are you seeking regarding LangChain services or related topics?"'. The timecost is 4.4648261070251465
2024-05-30 13:06:45.158 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=404 completion_tokens=116 total_tokens=520
2024-05-30 13:06:45.488 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.32939839363098145
2024-05-30 13:06:45.493 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history where the human's initial message started with "ï¼Ÿ", and the assistant provided a general greeting and offer to help with any questions about LangChain services, the follow-up message "ï¼Ÿ" seems to be a continuation of the human's initial query. Assuming the human is seeking assistance or information about a specific topic starting with "ï¼Ÿ", the refined standalone question could be:

"Continuing from the previous query starting with 'ï¼Ÿ', what specific information or assistance are you seeking regarding LangChain services or related topics?"', k: 10, the timecost is 0.33202195167541504
172.20.156.165 - - [30/May/2024 13:06:46] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:06:46.434 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.583 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.673 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.700 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.726 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.795 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.818 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.900 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.962 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:46.985 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.058 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.153 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.178 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.205 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.229 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.277 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.326 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.375 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.398 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.428 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.462 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.505 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.562 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.579 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.632 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.675 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.727 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.752 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.777 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.822 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.890 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.938 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.965 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:47.991 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.016 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.093 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.148 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.177 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.345 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.414 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.471 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.486 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:06:48.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1150 completion_tokens=73 total_tokens=1223
2024-05-30 13:06:48.769 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ï¼Ÿ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm sorry, I cannot find a specific answer about 'ï¼Ÿ' from the information provided. I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 8.078216791152954

172.20.156.165 - - [30/May/2024 13:07:27] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:07:27.536 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-05-30 13:07:31.735 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures all relevant context from the conversation would be:

ã€ŒLangChainã«ã¤ã„ã¦ã®è³ªå•ãŒã‚ã‚Šã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ã€Œï¼Ÿã€ã¨ã„ã†å†…å®¹ã®æƒ…å ±ã‚’æŽ¢ã—ã¦ã„ã¾ã—ãŸãŒã€è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãã®ãŸã‚ã€å†ã³åŒã˜å†…å®¹ã®è³ªå•ã‚’ã—ã¦ãŠã‚Šã¾ã™ã€‚ã“ã‚Œã¾ã§ã®æƒ…å ±ã‹ã‚‰é©åˆ‡ãªå›žç­”ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚ã€'. The timecost is 4.198830842971802
2024-05-30 13:07:31.736 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=404 completion_tokens=129 total_tokens=533
2024-05-30 13:07:32.001 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures all relevant context from the conversation would be:

ã€ŒLangChainã«ã¤ã„ã¦ã®è³ªå•ãŒã‚ã‚Šã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ã€Œï¼Ÿã€ã¨ã„ã†å†…å®¹ã®æƒ…å ±ã‚’æŽ¢ã—ã¦ã„ã¾ã—ãŸãŒã€è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãã®ãŸã‚ã€å†ã³åŒã˜å†…å®¹ã®è³ªå•ã‚’ã—ã¦ãŠã‚Šã¾ã™ã€‚ã“ã‚Œã¾ã§ã®æƒ…å ±ã‹ã‚‰é©åˆ‡ãªå›žç­”ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚ã€', k: 10, the timecost is 0.2625253200531006
2024-05-30 13:07:32.017 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.28084254264831543
172.20.156.165 - - [30/May/2024 13:07:33] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:07:33.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.161 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.189 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.209 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.258 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.290 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.307 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.338 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.373 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.422 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.504 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.529 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.553 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.579 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.626 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.700 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.733 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.757 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.781 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.840 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.889 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.914 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.939 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.966 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:33.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.044 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.068 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.092 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.118 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.143 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.168 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.213 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.238 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.264 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.289 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.321 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.507 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.542 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.569 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.593 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.616 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.668 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.738 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:34.814 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:35.052 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:35.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:35.104 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:07:35.205 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1150 completion_tokens=66 total_tokens=1216
2024-05-30 13:07:35.206 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ï¼Ÿ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I apologize, but I am unable to provide an answer to your question as it is not related to the provided context of `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 7.670782089233398

172.20.156.165 - - [30/May/2024 13:12:21] "GET /open-kf-chatbot/ HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 13:12:21] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 13:12:21] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 13:12:22.616 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzE3NjUwNzQyfQ.nwjv-pRcMkoS5YQmbYb9TC2IImGyIRTjDuStZKnbRFQ' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.156.165 - - [30/May/2024 13:12:22] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 13:12:22] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 13:12:22] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 13:12:25] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:12:26.170 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-05-30 13:12:31.159 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'In the conversation history provided, the Human has twice asked questions that the Assistant was unable to answer due to their context not being related to `LangChain`. Despite the Assistant indicating that they can only provide information related to `LangChain`, the Human has persisted with the same question marked as "ï¼Ÿ". To capture the intent of the follow-up message while adhering to the guidelines, the refined standalone question in Japanese could be:

" Continuing from the previous conversation, what is the specific question you intended to ask about `LangChain` that I was unable to answer?"'. The timecost is 4.988759994506836
2024-05-30 13:12:31.160 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=425 completion_tokens=127 total_tokens=552
2024-05-30 13:12:31.441 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.28075075149536133
2024-05-30 13:12:31.481 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'In the conversation history provided, the Human has twice asked questions that the Assistant was unable to answer due to their context not being related to `LangChain`. Despite the Assistant indicating that they can only provide information related to `LangChain`, the Human has persisted with the same question marked as "ï¼Ÿ". To capture the intent of the follow-up message while adhering to the guidelines, the refined standalone question in Japanese could be:

" Continuing from the previous conversation, what is the specific question you intended to ask about `LangChain` that I was unable to answer?"', k: 10, the timecost is 0.3177189826965332
172.20.156.165 - - [30/May/2024 13:12:32] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:12:32.573 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.619 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.680 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.708 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.731 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.754 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.787 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.808 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.831 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.858 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.931 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:32.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.062 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.093 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.166 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.261 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.285 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.307 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.330 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.354 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.386 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.412 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.473 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.505 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.624 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.651 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.673 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.726 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.803 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.831 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.855 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.877 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.905 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.932 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.958 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:33.980 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.028 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.056 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.113 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.166 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.193 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.222 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.244 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.265 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.316 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.338 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.375 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.395 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.421 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.450 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.512 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.563 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.591 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.613 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.639 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.667 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.693 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.723 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.781 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.807 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.830 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.951 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.953 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.953 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.963 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:34.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.038 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.060 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.088 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.119 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.167 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.198 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.239 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.283 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.310 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.338 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.387 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.412 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.433 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.484 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.515 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.537 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.562 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.585 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.612 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.637 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.663 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.690 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.711 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.731 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.774 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.844 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.863 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.886 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.913 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.940 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:35.989 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.019 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.042 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.102 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.132 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.157 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.184 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.239 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.346 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.395 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.422 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.445 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.495 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.563 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.601 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.625 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.647 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.695 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.718 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.774 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.802 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.834 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.854 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.877 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.911 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.933 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.952 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:36.984 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.013 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.095 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.145 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.172 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.198 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.249 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.275 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.306 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.336 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.357 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.385 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.410 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.440 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.463 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.512 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.560 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.593 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.616 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.639 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.670 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.693 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.716 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.737 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.761 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.805 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:37.977 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.054 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.080 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.142 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.161 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.187 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.210 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.235 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.263 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.291 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.314 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.338 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.395 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.422 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.446 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.472 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.582 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.607 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.636 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:12:38.680 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
172.20.156.165 - - [30/May/2024 13:12:51] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:12:51.250 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-05-30 13:12:59.592 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'In the conversation history provided, the Human has twice asked questions that the Assistant was unable to answer due to their context not being related to `LangChain`. Despite the Assistant indicating that they can only provide information related to `LangChain`, the Human has persisted with the same question. To capture the intent of the follow-up message while adhering to the guidelines, the refined standalone question in Japanese could be:

" Continuing from our previous conversation, could you please provide more information or clarify the nature of your inquiry regarding 'ï¼Ÿ' since it seems unrelated to the context of `LangChain`? " 

This question maintains the same language and intent of the follow-up message and references the historical question without directly using the Assistant's responses.'. The timecost is 8.340518951416016
2024-05-30 13:12:59.592 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=425 completion_tokens=164 total_tokens=589
2024-05-30 13:13:00.186 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'In the conversation history provided, the Human has twice asked questions that the Assistant was unable to answer due to their context not being related to `LangChain`. Despite the Assistant indicating that they can only provide information related to `LangChain`, the Human has persisted with the same question. To capture the intent of the follow-up message while adhering to the guidelines, the refined standalone question in Japanese could be:

" Continuing from our previous conversation, could you please provide more information or clarify the nature of your inquiry regarding 'ï¼Ÿ' since it seems unrelated to the context of `LangChain`? " 

This question maintains the same language and intent of the follow-up message and references the historical question without directly using the Assistant's responses.', k: 10, the timecost is 0.5906479358673096
2024-05-30 13:13:00.231 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.6375806331634521
172.20.156.165 - - [30/May/2024 13:13:01] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:13:01.133 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.258 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.308 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.331 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.357 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.445 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.458 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.549 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.550 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.551 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.558 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.584 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.645 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.646 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.667 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.693 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.716 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.741 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.814 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.844 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.891 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.919 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.942 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.967 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:01.992 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.017 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.042 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.067 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.093 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.145 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.169 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.198 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.248 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.270 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.295 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.346 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.372 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.397 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.422 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.447 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.497 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.521 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.550 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.625 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.696 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.697 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.725 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.775 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.802 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.826 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.852 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.877 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.905 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.957 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:02.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.004 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.061 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.088 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.111 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.169 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.255 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.305 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.330 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.356 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.382 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.408 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.435 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.462 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.512 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.587 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.638 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.663 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.716 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.741 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.804 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.827 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.881 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.908 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.931 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.962 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:03.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.032 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.082 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.131 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.185 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.208 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.281 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.306 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.332 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.390 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.414 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.451 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.479 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.503 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.526 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.551 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.576 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.629 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.662 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.684 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.707 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.732 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.757 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.808 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.833 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.889 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.919 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.957 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:04.981 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.027 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.138 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.165 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.194 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.235 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.239 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.262 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.289 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.397 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.420 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.446 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.471 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.504 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.524 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.574 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.601 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.628 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.653 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.702 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.728 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.754 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.907 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:05.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.018 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.048 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.069 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.089 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.117 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.141 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.219 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.246 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.322 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.350 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.398 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.436 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.463 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.488 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.517 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.544 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.565 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.591 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.621 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.644 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.669 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.703 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.724 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.745 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.795 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.820 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.872 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.900 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.932 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.961 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:06.983 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.029 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.063 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.091 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.119 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.191 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.215 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.266 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.345 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.370 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.396 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.420 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.450 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.479 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.507 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.528 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.554 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.634 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.668 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.693 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.814 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.847 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.885 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.940 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.963 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:07.992 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.033 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.061 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.136 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.235 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.243 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.262 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.288 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.316 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.339 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.407 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.424 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.449 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.506 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.531 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.558 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.584 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.635 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.659 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.685 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.792 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.819 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.851 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.875 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.929 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:08.977 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.030 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.058 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.133 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.181 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.210 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.259 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.312 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.393 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.434 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.443 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.533 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.546 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.598 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.625 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.650 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.678 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.713 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.733 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.760 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.785 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.839 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.867 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.895 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.923 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.969 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:09.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:10.018 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:10.044 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:10.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:10.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:10.124 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:10.151 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:13:10.248 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1171 completion_tokens=341 total_tokens=1512
2024-05-30 13:13:10.249 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ï¼Ÿ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
ãŠå®¢æ§˜ã€ã“ã‚“ã«ã¡ã¯ï¼ã”è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã¯ã€æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å¿…è¦ãªæƒ…å ±ã‚’åˆ†æžã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦ã€ã€Œï¼Ÿã€ã«ç‰¹å®šã®ç­”ãˆã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ LangChain ã«é–¢ã™ã‚‹æƒ…å ±ã§ã®è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã”è³ªå•ãŒ LangChain ã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã«é–¢é€£ã—ã¦ã„ãªã„å ´åˆã€ãŠç­”ãˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚å…·ä½“çš„ãªè³ªå•ãŒã‚ã‚Œã°ã€ãŠèžããã ã•ã„ã€‚ç§ã¯æœ€å–„ã§ç­”ãˆã‚’æä¾›ã—ã¾ã™ã€‚

### ã‚½ãƒ¼ã‚¹
- ""

ã“ã®å›žç­”ã¯ã€æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦ä½œæˆã•ã‚Œã¾ã—ãŸã€‚è³ªå•ã«åŸºã¥ã„ãŸå›žç­”ã¯ã€Markdown ã®ã‚¹yntaxã‚’ä½¿ç”¨ã—ã¦å®Œå…¨ã«æ•´å½¢ã•ã‚Œã¦ã„ã¾ã™ã€‚å…·ä½“çš„ãªå›žç­”ã«åŸºã¥ã„ãŸã‚½ãƒ¼ã‚¹ã¯ã€ã€Œ[Hyperlinks](URL)ã€ã®å½¢å¼ã§ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã¾ã™ã€‚è³ªå•ã«åŸºã¥ã„ãŸå›žç­”ã«ä½¿ç”¨ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã®æƒ…å ±ã¯ã€ã€Œ[Hyperlinks](URL)ã€ã®å½¢å¼ã§ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã¾ã™ã€‚
the total timecost is 18.999263048171997

172.20.156.165 - - [30/May/2024 13:15:15] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:15:15.698 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-05-30 13:15:18.884 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the context of our previous conversation where I inquired about `LangChain`, and considering your response that the question was not related to the provided context, I would like to ask a new question that pertains specifically to `LangChain`. Could you please explain what `LangChain` is and how it can be utilized in the context of language processing or artificial intelligence?'. The timecost is 3.1854074001312256
2024-05-30 13:15:18.884 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=693 completion_tokens=84 total_tokens=777
2024-05-30 13:15:19.161 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.27527832984924316
2024-05-30 13:15:19.206 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the context of our previous conversation where I inquired about `LangChain`, and considering your response that the question was not related to the provided context, I would like to ask a new question that pertains specifically to `LangChain`. Could you please explain what `LangChain` is and how it can be utilized in the context of language processing or artificial intelligence?', k: 10, the timecost is 0.31777381896972656
172.20.156.165 - - [30/May/2024 13:15:20] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:15:20.550 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.573 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.598 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.661 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.722 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.771 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.797 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.823 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.848 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.876 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.931 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.957 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:20.985 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.012 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.051 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.079 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.103 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.160 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.207 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.259 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.285 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.311 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.337 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.389 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.413 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.439 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.471 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.542 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.566 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.593 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.619 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.678 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.731 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.843 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.844 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.846 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.892 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.917 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:21.969 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.009 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.020 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.054 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.082 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.165 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.188 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.214 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.302 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.356 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.447 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.525 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.550 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.695 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.719 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.778 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.840 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.881 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.894 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.959 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:22.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.042 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.071 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.092 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.116 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.143 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.170 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.195 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.257 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.310 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.334 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.365 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.385 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.409 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.436 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.461 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.486 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.511 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.537 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.577 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.600 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.626 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.723 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.724 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.766 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.814 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.839 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.865 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.892 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:23.973 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.000 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.062 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.114 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.166 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.193 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.279 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.305 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.327 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.392 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.417 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.444 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.476 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.497 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.556 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.583 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.633 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.702 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.721 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.776 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.833 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.853 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.875 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.902 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:24.982 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.039 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.094 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.116 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.143 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.185 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.212 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.237 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.263 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.296 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.321 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.367 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.394 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.421 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.454 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.501 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.540 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.609 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.636 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.764 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.794 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.820 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.841 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.909 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:25.937 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:26.012 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:26.041 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:26.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:26.106 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:26.132 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:26.161 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:26.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:26.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:26.375 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1439 completion_tokens=196 total_tokens=1635
2024-05-30 13:15:26.376 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ï¼Ÿ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
ãŠå®¢æ§˜ã€ã“ã‚“ã«ã¡ã¯ï¼ã”è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã¯ã€æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å¿…è¦ãªæƒ…å ±ã‚’åˆ†æžã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦ã€ã€Œï¼Ÿã€ã«ç‰¹å®šã®ç­”ãˆã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ LangChain ã«é–¢ã™ã‚‹æƒ…å ±ã§ã®è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã”è³ªå•ãŒ LangChain ã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã«é–¢é€£ã—ã¦ã„ãªã„å ´åˆã€ãŠç­”ãˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚å…·ä½“çš„ãªè³ªå•ãŒã‚ã‚Œã°ã€ãŠèžããã ã•ã„ã€‚ç§ã¯æœ€å–„ã§ç­”ãˆã‚’æä¾›ã—ã¾ã™ã€‚

### ã‚½ãƒ¼ã‚¹
- ""
the total timecost is 10.678810119628906

172.20.156.165 - - [30/May/2024 13:15:44] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:15:44.901 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-05-30 13:15:52.287 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history where the Assistant explains that it needs more specific information to answer the Human's question, and that it can provide information related to LangChain, the follow-up message from the Human seems to be another question mark. The intent of the follow-up message is not clear from the given context.

If the follow-up message is intended to be a new question related to LangChain or requires further clarification, the refined standalone question could be:

```
ãŠå®¢æ§˜ãŒæœ€åˆã«æå‡ºã—ãŸè³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ãªè¿½åŠ çš„æƒ…å ±ãŒå¿…è¦ã§ã™ã‹ï¼ŸLangChainã«é–¢ã™ã‚‹è³ªå•ã¯ã©ã®ã‚ˆã†ãªå†…å®¹ã§ã‚ã‚Œã€è©³ç´°ã«ãŠèžãã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ
```

This question asks for the necessary additional information to answer the original question and also invites the Human to ask a question about LangChain. It is formulated in Japanese, maintains the length of the original follow-up message, and does not directly use the Assistant's responses.'. The timecost is 7.385509967803955
2024-05-30 13:15:52.288 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=824 completion_tokens=234 total_tokens=1058
2024-05-30 13:15:52.603 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history where the Assistant explains that it needs more specific information to answer the Human's question, and that it can provide information related to LangChain, the follow-up message from the Human seems to be another question mark. The intent of the follow-up message is not clear from the given context.

If the follow-up message is intended to be a new question related to LangChain or requires further clarification, the refined standalone question could be:

```
ãŠå®¢æ§˜ãŒæœ€åˆã«æå‡ºã—ãŸè³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ãªè¿½åŠ çš„æƒ…å ±ãŒå¿…è¦ã§ã™ã‹ï¼ŸLangChainã«é–¢ã™ã‚‹è³ªå•ã¯ã©ã®ã‚ˆã†ãªå†…å®¹ã§ã‚ã‚Œã€è©³ç´°ã«ãŠèžãã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ
```

This question asks for the necessary additional information to answer the original question and also invites the Human to ask a question about LangChain. It is formulated in Japanese, maintains the length of the original follow-up message, and does not directly use the Assistant's responses.', k: 10, the timecost is 0.3124065399169922
2024-05-30 13:15:52.622 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.33333802223205566
172.20.156.165 - - [30/May/2024 13:15:53] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:15:53.931 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.043 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.069 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.123 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.149 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.177 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.208 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.259 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.280 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.329 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.354 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.381 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.433 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.571 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.621 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.645 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.696 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.722 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.749 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.777 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.802 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.825 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.850 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.875 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.902 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.926 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.953 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:54.978 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.031 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.057 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.140 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.199 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.272 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.298 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.322 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.376 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.403 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.427 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.451 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.478 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.506 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.559 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.590 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.624 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.680 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.694 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.720 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.743 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.800 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.827 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.851 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.876 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.903 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.929 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:55.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.040 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.060 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.099 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.125 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.179 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.205 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.258 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.484 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.507 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.564 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.610 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.647 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.711 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.729 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.756 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.835 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.857 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.879 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.931 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:56.981 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.031 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.057 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.079 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.418 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.469 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.524 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.546 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.574 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.599 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.622 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.673 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.731 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.755 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.781 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.828 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.850 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.876 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.901 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.952 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:57.975 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.061 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.086 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.147 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.202 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.203 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.226 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.273 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.337 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.365 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.388 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.416 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.440 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.488 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.556 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.587 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.607 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.635 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.660 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.682 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.785 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.961 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:58.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.009 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.085 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.136 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.159 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.185 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.264 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.291 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.315 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.388 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.416 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.441 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.468 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.579 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.630 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.685 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.728 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.802 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.804 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-05-30 13:15:59.986 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1570 completion_tokens=196 total_tokens=1766
2024-05-30 13:15:59.987 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ï¼Ÿ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
ãŠå®¢æ§˜ã€ã“ã‚“ã«ã¡ã¯ï¼ã”è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã¯ã€æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å¿…è¦ãªæƒ…å ±ã‚’åˆ†æžã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦ã€ã€Œï¼Ÿã€ã«ç‰¹å®šã®ç­”ãˆã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ LangChain ã«é–¢ã™ã‚‹æƒ…å ±ã§ã®è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã”è³ªå•ãŒ LangChain ã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã«é–¢é€£ã—ã¦ã„ãªã„å ´åˆã€ãŠç­”ãˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚å…·ä½“çš„ãªè³ªå•ãŒã‚ã‚Œã°ã€ãŠèžããã ã•ã„ã€‚ç§ã¯æœ€å–„ã§ç­”ãˆã‚’æä¾›ã—ã¾ã™ã€‚

### ã‚½ãƒ¼ã‚¹
- ""
the total timecost is 15.087205410003662

172.20.156.165 - - [30/May/2024 13:18:23] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:18:23.516 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä½ å¥½ä½ å¥½', detect the language is 'Chinese'!
2024-05-30 13:18:24.707 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä½ å¥½ä½ å¥½', the refined query is 'ä½ å¥½ä½ å¥½ï¼è¯·é—®ä½ çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ'. The timecost is 1.1902351379394531
2024-05-30 13:18:24.708 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä½ å¥½ä½ å¥½', usage=prompt_tokens=681 completion_tokens=10 total_tokens=691
2024-05-30 13:18:24.977 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ä½ å¥½', k: 10, the timecost is 0.2684957981109619
2024-05-30 13:18:25.003 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ä½ å¥½ï¼è¯·é—®ä½ çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ', k: 10, the timecost is 0.29193115234375
172.20.156.165 - - [30/May/2024 13:18:26] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:18:26.184 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.261 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.313 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.383 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.389 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.417 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.439 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.491 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.516 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.567 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.644 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.668 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.692 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.718 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.743 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.796 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.818 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.850 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.868 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.922 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.949 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.972 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:26.997 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:27.022 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:27.049 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=None
2024-05-30 13:18:27.162 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ä½ å¥½', usage=prompt_tokens=1429 completion_tokens=37 total_tokens=1466
2024-05-30 13:18:27.163 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ä½ å¥½ä½ å¥½' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
æ‚¨å¥½ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚å¦‚æžœæ‚¨æœ‰ä»»ä½•å…³äºŽLangChainçš„é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚
the total timecost is 3.647916078567505

172.20.156.165 - - [30/May/2024 14:29:11] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:29:11.999 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä½ å¥½', detect the language is 'Chinese'!
2024-05-30 14:29:13.457 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä½ å¥½', the refined query is 'ä½ å¥½ï¼Œè¯·é—®æ‚¨ä¹‹å‰å’ŒåŠ©æ‰‹äº¤æµäº†ä»€ä¹ˆå†…å®¹ï¼Ÿæ˜¯åŸºäºŽè¿™äº›ä¿¡æ¯æ‚¨æƒ³ç»§ç»­æé—®å—ï¼Ÿ'. The timecost is 1.4566504955291748
2024-05-30 14:29:13.457 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä½ å¥½', usage=prompt_tokens=323 completion_tokens=23 total_tokens=346
2024-05-30 14:29:13.711 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½', k: 10, the timecost is 0.25314927101135254
2024-05-30 14:29:13.729 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ï¼Œè¯·é—®æ‚¨ä¹‹å‰å’ŒåŠ©æ‰‹äº¤æµäº†ä»€ä¹ˆå†…å®¹ï¼Ÿæ˜¯åŸºäºŽè¿™äº›ä¿¡æ¯æ‚¨æƒ³ç»§ç»­æé—®å—ï¼Ÿ', k: 10, the timecost is 0.26879334449768066
172.20.156.165 - - [30/May/2024 14:29:14] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:29:14.862 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:14.887 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:14.912 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:14.939 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:14.966 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:14.992 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.018 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.046 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.077 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.104 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.130 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.280 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.309 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.340 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.389 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.413 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.472 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.525 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.607 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.628 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.655 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.685 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.795 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.849 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.875 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.900 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:15.929 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:29:16.031 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=prompt_tokens=1069 completion_tokens=37 total_tokens=1106
2024-05-30 14:29:16.032 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ä½ å¥½' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
ä½ å¥½ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚å¦‚æžœæ‚¨æœ‰ä»»ä½•å…³äºŽLangChainçš„é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶æé—®ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚
the total timecost is 4.033985137939453

172.30.194.232 - - [30/May/2024 14:42:54] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:42:54.545 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä½ å¥½', detect the language is 'Chinese'!
2024-05-30 14:42:55.915 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä½ å¥½', the refined query is 'ä½ å¥½ï¼Œè¯·é—®æ‚¨ä¹‹å‰è¯¢é—®LangChainç›¸å…³é—®é¢˜çš„æ—¶å€™ï¼Œæœ‰ä»€ä¹ˆå…·ä½“çš„éœ€æ±‚æˆ–ç–‘é—®å—ï¼Ÿ'. The timecost is 1.3694467544555664
2024-05-30 14:42:55.916 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä½ å¥½', usage=prompt_tokens=311 completion_tokens=23 total_tokens=334
2024-05-30 14:42:56.228 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ï¼Œè¯·é—®æ‚¨ä¹‹å‰è¯¢é—®LangChainç›¸å…³é—®é¢˜çš„æ—¶å€™ï¼Œæœ‰ä»€ä¹ˆå…·ä½“çš„éœ€æ±‚æˆ–ç–‘é—®å—ï¼Ÿ', k: 10, the timecost is 0.3098440170288086
2024-05-30 14:42:56.241 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½', k: 10, the timecost is 0.3247108459472656
172.30.194.232 - - [30/May/2024 14:42:57] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:42:57.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.200 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.238 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.263 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.287 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.364 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.392 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.405 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.421 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.448 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.497 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.522 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.551 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.574 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.599 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.622 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.695 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.720 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.792 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.814 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.874 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.916 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:57.921 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:58.078 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:58.122 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:58.148 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:58.169 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:58.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:42:58.315 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=prompt_tokens=1057 completion_tokens=37 total_tokens=1094
2024-05-30 14:42:58.316 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ä½ å¥½' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
ä½ å¥½ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚å¦‚æžœæ‚¨æœ‰ä»»ä½•å…³äºŽLangChainçš„é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶æé—®ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚
the total timecost is 3.771937370300293

172.31.160.26 - - [30/May/2024 14:59:05] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:59:05.954 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä½ å¥½', detect the language is 'Chinese'!
2024-05-30 14:59:07.417 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä½ å¥½', the refined query is 'ä½ å¥½ï¼Œè¯·é—®æ‚¨ä¹‹å‰è¯¢é—®å…³äºŽLangChainçš„ä»€ä¹ˆé—®é¢˜ï¼Ÿæˆ‘çŽ°åœ¨éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯æ¥å¸®åŠ©æ‚¨ã€‚'. The timecost is 1.462228536605835
2024-05-30 14:59:07.417 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä½ å¥½', usage=prompt_tokens=362 completion_tokens=26 total_tokens=388
2024-05-30 14:59:07.722 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ï¼Œè¯·é—®æ‚¨ä¹‹å‰è¯¢é—®å…³äºŽLangChainçš„ä»€ä¹ˆé—®é¢˜ï¼Ÿæˆ‘çŽ°åœ¨éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯æ¥å¸®åŠ©æ‚¨ã€‚', k: 10, the timecost is 0.30204248428344727
2024-05-30 14:59:07.740 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½', k: 10, the timecost is 0.32254528999328613
172.31.160.26 - - [30/May/2024 14:59:08] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:59:08.697 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.721 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.746 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.773 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.797 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.823 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.852 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.878 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.935 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:08.980 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.207 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.242 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.264 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.285 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.310 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.336 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.389 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.414 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.440 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.492 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.517 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.567 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.593 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.619 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.643 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.722 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.742 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.805 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.819 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.843 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.869 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.893 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:09.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.002 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.051 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.084 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.103 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.130 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.153 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.178 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.203 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.254 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.307 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.333 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.390 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.415 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.441 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.467 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.493 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.519 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.546 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.571 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.691 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.729 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.777 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.830 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.881 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.907 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.933 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.960 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:10.986 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:11.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:11.048 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:11.066 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:11.089 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:11.112 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:11.152 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:11.170 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:11.203 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 14:59:11.328 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=prompt_tokens=1108 completion_tokens=90 total_tokens=1198
2024-05-30 14:59:11.329 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ä½ å¥½' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
ä½ å¥½ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚å¦‚æžœæ‚¨æœ‰ä»»ä½•å…³äºŽLangChainçš„é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶æé—®ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚å¦‚æžœæ‚¨æƒ³äº†è§£LangChainçš„ç›¸å…³ä¿¡æ¯ï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„å®˜æ–¹ç½‘ç«™ï¼š[LangChainå®˜ç½‘](http://www.langchain.com)ã€‚

Sources:
- [LangChainå®˜ç½‘](http://www.langchain.com)
the total timecost is 5.376306056976318

172.31.160.26 - - [30/May/2024 15:00:03] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:00:03.831 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', detect the language is 'Chinese'!
2024-05-30 15:00:04.956 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', the refined query is 'LangChainèƒ½æä¾›å“ªäº›æœåŠ¡æˆ–åŠŸèƒ½ï¼Ÿ'. The timecost is 1.1236329078674316
2024-05-30 15:00:04.957 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=prompt_tokens=419 completion_tokens=13 total_tokens=432
2024-05-30 15:00:05.215 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'LangChainèƒ½æä¾›å“ªäº›æœåŠ¡æˆ–åŠŸèƒ½ï¼Ÿ', k: 10, the timecost is 0.25598788261413574
2024-05-30 15:00:05.236 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', k: 10, the timecost is 0.2787466049194336
172.31.160.26 - - [30/May/2024 15:00:06] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:00:06.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.525 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.555 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.577 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.629 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.656 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.684 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.711 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.766 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.791 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.817 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.872 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.897 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.925 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.949 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:06.974 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.007 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.034 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.057 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.083 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.136 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.163 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.195 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.216 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.266 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.400 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.407 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.433 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.460 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.486 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.541 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.567 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.593 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.624 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.676 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.738 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:07.978 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.004 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.029 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.107 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.140 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.184 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.216 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.238 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.263 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.288 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.322 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.365 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.462 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.494 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.521 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.573 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.623 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.676 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.710 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.737 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.793 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.839 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.891 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:08.950 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.008 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.088 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.089 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.090 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.116 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.142 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.167 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.194 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.230 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.347 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.373 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.397 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.424 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.450 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.484 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.501 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.553 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.583 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.684 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.767 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.793 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.822 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.867 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.947 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.974 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:09.998 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:10.025 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:10.044 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:10.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:10.094 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:10.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:10.147 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:10.171 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=None
2024-05-30 15:00:10.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ', usage=prompt_tokens=1173 completion_tokens=130 total_tokens=1303
2024-05-30 15:00:10.288 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ä½ ä»¬langchainèƒ½å¹²ä»€ä¹ˆ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
æ‚¨å¥½ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æ ¹æ®æˆ‘ç›®å‰èŽ·å–çš„ä¿¡æ¯ï¼Œæˆ‘æ— æ³•ç›´æŽ¥å›žç­”â€œä½ ä»¬LangChainèƒ½å¹²ä»€ä¹ˆâ€çš„é—®é¢˜ã€‚ä¸è¿‡ï¼Œæˆ‘è¿™é‡Œæ˜¯ä¸ºäº†å¸®åŠ©æ‚¨èŽ·å–ä¸ŽLangChainç›¸å…³çš„ä¿¡æ¯å’Œå¸®åŠ©ã€‚å¦‚æžœæ‚¨æœ‰å…³äºŽLangChainçš„å…·ä½“é—®é¢˜æˆ–éœ€æ±‚ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚å¦‚æžœæ‚¨æƒ³äº†è§£æ›´å¤šå…³äºŽLangChainçš„ä¿¡æ¯ï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„å®˜æ–¹ç½‘ç«™ï¼š[LangChainå®˜ç½‘](http://www.langchain.com)ã€‚

Sources:
- [LangChainå®˜ç½‘](http://www.langchain.com)
the total timecost is 6.457250595092773

172.31.160.26 - - [30/May/2024 15:00:20] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:00:20.811 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä»‹ç»ä¸€ä¸‹java', detect the language is 'Chinese'!
2024-05-30 15:00:22.182 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä»‹ç»ä¸€ä¸‹java', the refined query is 'ä»‹ç»ä¸€ä¸‹Javaè¿™ç§ç¼–ç¨‹è¯­è¨€çš„ç›¸å…³ä¿¡æ¯ã€‚'. The timecost is 1.3697116374969482
2024-05-30 15:00:22.182 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä»‹ç»ä¸€ä¸‹java', usage=prompt_tokens=513 completion_tokens=10 total_tokens=523
2024-05-30 15:00:22.443 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä»‹ç»ä¸€ä¸‹Javaè¿™ç§ç¼–ç¨‹è¯­è¨€çš„ç›¸å…³ä¿¡æ¯ã€‚', k: 10, the timecost is 0.25927090644836426
2024-05-30 15:00:22.491 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä»‹ç»ä¸€ä¸‹java', k: 10, the timecost is 0.3085603713989258
172.31.160.26 - - [30/May/2024 15:00:24] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:00:24.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.386 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.417 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.450 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.476 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.501 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.526 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.553 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.602 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.627 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.655 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.683 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.713 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.738 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.763 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.791 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.843 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.871 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.893 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.921 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.975 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:24.997 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.024 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.047 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.122 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.149 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.174 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.200 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.230 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.253 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.309 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.329 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.354 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.380 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.457 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.506 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.559 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.590 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.647 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.673 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.724 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.749 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.773 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.798 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.823 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.854 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.875 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.901 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.959 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:25.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.071 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.090 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.140 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.219 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.246 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.266 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.291 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.316 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.341 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.371 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.394 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.419 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.447 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.473 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.524 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.623 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.650 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.682 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.703 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.725 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.781 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.827 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.853 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.939 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:26.990 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.041 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.549 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.575 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.611 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.627 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.704 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.734 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.772 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.797 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.822 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.849 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.871 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.945 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.974 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:27.998 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.025 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.050 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.077 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.104 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.132 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.160 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.215 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.293 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.346 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.372 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.399 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.428 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.460 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.486 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.537 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.589 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.615 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.645 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.699 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.723 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.784 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.831 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.889 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.941 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.967 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:28.994 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.022 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.051 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.078 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.113 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.143 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.166 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.193 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.271 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.323 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.352 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.378 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.404 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.482 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.510 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.563 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.594 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.645 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.675 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.700 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.730 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.752 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.779 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.805 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.897 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.898 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.919 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:29.998 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.027 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.064 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.101 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.173 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.232 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.296 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.321 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.371 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.568 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.620 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.647 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.708 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.764 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.791 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.818 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.872 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.952 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:30.976 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.031 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.059 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.085 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.138 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.164 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.195 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.218 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.246 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.268 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.295 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.400 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.425 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.508 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.588 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.614 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.643 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.668 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.694 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.720 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:31.747 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.088 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.116 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.144 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.172 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.229 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.314 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.368 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.400 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.426 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.453 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.514 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.567 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.594 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.623 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.675 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.711 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.734 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.759 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.840 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.868 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.922 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.948 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:32.975 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.016 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.043 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.067 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.094 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.147 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.177 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.208 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.350 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.403 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.454 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.510 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.563 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.592 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.617 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.644 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.699 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.728 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.755 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.781 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.843 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.893 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=None
2024-05-30 15:00:33.996 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä»‹ç»ä¸€ä¸‹java', usage=prompt_tokens=1261 completion_tokens=326 total_tokens=1587
2024-05-30 15:00:33.996 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ä»‹ç»ä¸€ä¸‹java' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
Javaæ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶â€œä¸€æ¬¡ç¼–å†™ï¼Œåˆ°å¤„è¿è¡Œâ€çš„ç†å¿µè‘—ç§°ã€‚å®ƒæ˜¯ç”±Sun Microsystemså…¬å¸åœ¨1995å¹´æŽ¨å‡ºçš„ï¼ŒåŽæ¥è¢«ç”²éª¨æ–‡å…¬å¸ï¼ˆOracleï¼‰æ”¶è´­ã€‚Javaåœ¨ä¼ä¸šçº§åº”ç”¨ã€ç§»åŠ¨åº”ç”¨ï¼ˆå°¤å…¶æ˜¯Androidï¼‰ã€ç½‘ç»œåº”ç”¨ç­‰æ–¹é¢æœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚

Javaçš„ç‰¹ç‚¹åŒ…æ‹¬ï¼š

1. **è·¨å¹³å°æ€§**ï¼šJavaä»£ç åœ¨ä¸åŒçš„æ“ä½œç³»ç»Ÿä¸Šå¯ä»¥è¢«ç›¸åŒçš„Javaè™šæ‹Ÿæœºï¼ˆJVMï¼‰æ‰§è¡Œã€‚
2. **é¢å‘å¯¹è±¡**ï¼šJavaæ˜¯ä¸€ç§é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€ï¼Œæ”¯æŒå°è£…ã€ç»§æ‰¿å’Œå¤šæ€ç­‰ç‰¹æ€§ã€‚
3. **å¼ºç±»åž‹è¯­è¨€**ï¼šJavaè¦æ±‚æ‰€æœ‰å˜é‡éƒ½å¿…é¡»å£°æ˜Žç±»åž‹ï¼Œè¿™æœ‰åŠ©äºŽæé«˜ç¨‹åºçš„ç¨³å®šæ€§å’Œå¯ç»´æŠ¤æ€§ã€‚
4. **å®‰å…¨æ€§**ï¼šJavaè®¾è®¡äº†å¤šç§æœºåˆ¶æ¥ç¡®ä¿ä»£ç çš„å®‰å…¨æ€§ï¼Œå¦‚æ²™ç®±å®‰å…¨æ¨¡åž‹ã€‚
5. **å¤šçº¿ç¨‹æ”¯æŒ**ï¼šJavaæä¾›äº†å†…ç½®çš„å¤šçº¿ç¨‹æ”¯æŒï¼Œæ–¹ä¾¿å¼€å‘è€…è¿›è¡Œå¹¶å‘ç¼–ç¨‹ã€‚

Javaç”Ÿæ€ç³»ç»Ÿéžå¸¸ä¸°å¯Œï¼Œæœ‰å¤§é‡çš„å¼€å‘å·¥å…·ã€åº“å’Œæ¡†æž¶ï¼Œå¦‚Eclipseã€IntelliJ IDEAã€Springç­‰ã€‚æ­¤å¤–ï¼ŒJavaç¤¾åŒºä¹Ÿéžå¸¸æ´»è·ƒï¼Œæœ‰è®¸å¤šåœ¨çº¿èµ„æºå’Œæ–‡æ¡£ä¾›å¼€å‘è€…å­¦ä¹ å’Œå‚è€ƒã€‚

å¦‚æžœæ‚¨å¯¹LangChainæœ‰ä»»ä½•å…·ä½“é—®é¢˜æˆ–éœ€æ±‚ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚å¦‚æžœæ‚¨æƒ³äº†è§£æ›´å¤šå…³äºŽLangChainçš„ä¿¡æ¯ï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„å®˜æ–¹ç½‘ç«™ï¼š[LangChainå®˜ç½‘](http://www.langchain.com)ã€‚

Sources:
- [LangChainå®˜ç½‘](http://www.langchain.com)
the total timecost is 13.186379432678223

172.30.154.145 - - [30/May/2024 15:14:19] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:14:19.343 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', detect the language is 'Chinese'!
2024-05-30 15:14:22.727 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', the refined query is 'ä½ å¥½ï¼Œè¯·é—®Javaæ˜¯ä¸€ç§ä»€ä¹ˆç¼–ç¨‹è¯­è¨€ï¼Œå®ƒæœ‰å“ªäº›ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ï¼Ÿ'. The timecost is 3.383230447769165
2024-05-30 15:14:22.728 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=prompt_tokens=753 completion_tokens=18 total_tokens=771
2024-05-30 15:14:22.997 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ï¼Œè¯·é—®Javaæ˜¯ä¸€ç§ä»€ä¹ˆç¼–ç¨‹è¯­è¨€ï¼Œå®ƒæœ‰å“ªäº›ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ï¼Ÿ', k: 10, the timecost is 0.26569032669067383
2024-05-30 15:14:23.003 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', k: 10, the timecost is 0.27454376220703125
172.30.154.145 - - [30/May/2024 15:14:24] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:14:24.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.011 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.037 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.062 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.088 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.114 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.140 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.164 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.215 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.248 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.265 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.296 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.323 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.372 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.397 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.448 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.473 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.499 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.526 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.553 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.577 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.600 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.625 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.678 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.700 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.726 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.774 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.799 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.824 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.848 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.874 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.921 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.945 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.970 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:25.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.022 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.046 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.068 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.096 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.196 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.222 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.273 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.294 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.370 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.412 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.417 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.442 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.491 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.568 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.646 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.669 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.694 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.719 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.794 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.817 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.867 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.892 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.916 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.940 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.966 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:26.997 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.022 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.047 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.071 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.145 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.180 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.195 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.339 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.360 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.409 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.444 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.585 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.631 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.635 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.659 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.683 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.733 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.785 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.809 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.840 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.858 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.932 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.933 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:27.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.044 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.068 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.188 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.189 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.207 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.293 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.294 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.333 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.382 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.482 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.506 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.531 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.557 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.581 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.606 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.630 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.655 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.679 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.705 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.730 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.755 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.830 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.880 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:28.982 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.007 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.043 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.057 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.082 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.107 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.132 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.187 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.213 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.237 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.262 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.285 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.312 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.360 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.409 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.435 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.484 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.512 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.584 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.634 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.655 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.683 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.704 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.728 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.776 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.826 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.848 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.936 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:29.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.064 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.113 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.136 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.160 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.184 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.208 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.306 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.336 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.358 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.382 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.407 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.508 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.529 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.557 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.670 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.694 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.729 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.756 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.836 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.861 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.886 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.910 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.962 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:30.988 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.037 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.065 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.096 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.113 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.162 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.186 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.219 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.243 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.327 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.387 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.394 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=None
2024-05-30 15:14:31.516 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ', usage=prompt_tokens=1509 completion_tokens=246 total_tokens=1755
2024-05-30 15:14:31.517 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ä½ å¥½ï¼Œè¯·é—®javaæ˜¯ä»€ä¹ˆï¼Ÿ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
ä½ å¥½ï¼Javaæ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶â€œä¸€æ¬¡ç¼–å†™ï¼Œåˆ°å¤„è¿è¡Œâ€çš„ç†å¿µè‘—ç§°ã€‚å®ƒæ˜¯ç”±Sun Microsystemså…¬å¸åœ¨1995å¹´æŽ¨å‡ºçš„ï¼ŒåŽæ¥è¢«ç”²éª¨æ–‡å…¬å¸ï¼ˆOracleï¼‰æ”¶è´­ã€‚Javaåœ¨ä¼ä¸šçº§åº”ç”¨ã€ç§»åŠ¨åº”ç”¨ï¼ˆå°¤å…¶æ˜¯Androidï¼‰ã€ç½‘ç»œåº”ç”¨ç­‰æ–¹é¢æœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚

Javaçš„ç‰¹ç‚¹åŒ…æ‹¬ï¼š

1. **è·¨å¹³å°æ€§**ï¼šJavaä»£ç åœ¨ä¸åŒçš„æ“ä½œç³»ç»Ÿä¸Šå¯ä»¥è¢«ç›¸åŒçš„Javaè™šæ‹Ÿæœºï¼ˆJVMï¼‰æ‰§è¡Œã€‚
2. **é¢å‘å¯¹è±¡**ï¼šJavaæ˜¯ä¸€ç§é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€ï¼Œæ”¯æŒå°è£…ã€ç»§æ‰¿å’Œå¤šæ€ç­‰ç‰¹æ€§ã€‚
3. **å¼ºç±»åž‹è¯­è¨€**ï¼šJavaè¦æ±‚æ‰€æœ‰å˜é‡éƒ½å¿…é¡»å£°æ˜Žç±»åž‹ï¼Œè¿™æœ‰åŠ©äºŽæé«˜ç¨‹åºçš„ç¨³å®šæ€§å’Œå¯ç»´æŠ¤æ€§ã€‚
4. **å®‰å…¨æ€§**ï¼šJavaè®¾è®¡äº†å¤šç§æœºåˆ¶æ¥ç¡®ä¿ä»£ç çš„å®‰å…¨æ€§ï¼Œå¦‚æ²™ç®±å®‰å…¨æ¨¡åž‹ã€‚
5. **å¤šçº¿ç¨‹æ”¯æŒ**ï¼šJavaæä¾›äº†å†…ç½®çš„å¤šçº¿ç¨‹æ”¯æŒï¼Œæ–¹ä¾¿å¼€å‘è€…è¿›è¡Œå¹¶å‘ç¼–ç¨‹ã€‚

Javaç”Ÿæ€ç³»ç»Ÿéžå¸¸ä¸°å¯Œï¼Œæœ‰å¤§é‡çš„å¼€å‘å·¥å…·ã€åº“å’Œæ¡†æž¶ï¼Œå¦‚Eclipseã€IntelliJ IDEAã€Springç­‰ã€‚æ­¤å¤–ï¼ŒJavaç¤¾åŒºä¹Ÿéžå¸¸æ´»è·ƒï¼Œæœ‰è®¸å¤šåœ¨çº¿èµ„æºå’Œæ–‡æ¡£ä¾›å¼€å‘è€…å­¦ä¹ å’Œå‚è€ƒã€‚
the total timecost is 12.17470669746399

172.30.154.145 - - [30/May/2024 15:14:52] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:14:52.750 | WARNING  | server.app.queries:generate_answer:210 - For query: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', detect the language is 'Chinese'!
2024-05-30 15:14:54.071 | WARNING  | server.app.queries:refine_query:105 - For the query: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', the refined query is 'Javaè¯­è¨€ä¸­çš„åŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ'. The timecost is 1.3209331035614014
2024-05-30 15:14:54.072 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=prompt_tokens=869 completion_tokens=10 total_tokens=879
2024-05-30 15:14:54.353 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', k: 10, the timecost is 0.2807590961456299
2024-05-30 15:14:54.358 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Javaè¯­è¨€ä¸­çš„åŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', k: 10, the timecost is 0.2825949192047119
172.30.154.145 - - [30/May/2024 15:14:55] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:14:55.667 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.688 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.716 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.744 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.792 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.825 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.919 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.941 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.969 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:55.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.025 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.049 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.075 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.100 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.126 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.150 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.180 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.255 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.281 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.306 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.331 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.413 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.632 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.659 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.689 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.719 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.744 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.787 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.831 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.884 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.908 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.932 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.960 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:56.982 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.007 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.058 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.086 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.115 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.137 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.161 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.235 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.238 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.312 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.337 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.362 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.388 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.412 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.441 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.490 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.569 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.666 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.688 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.718 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.744 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.767 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=None
2024-05-30 15:14:57.885 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ', usage=prompt_tokens=1625 completion_tokens=82 total_tokens=1707
2024-05-30 15:14:57.887 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'JavaåŸºæœ¬æ•°æ®ç±»åž‹æœ‰å“ªäº›ï¼Ÿ' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
Javaçš„åŸºæœ¬æ•°æ®ç±»åž‹åŒ…æ‹¬ä»¥ä¸‹å‡ ç§ï¼š

- æ•´æ•°ç±»åž‹ï¼š`byte`, `short`, `int`, `long`
- æµ®ç‚¹ç±»åž‹ï¼š`float`, `double`
- å­—ç¬¦ç±»åž‹ï¼š`char`
- å¸ƒå°”ç±»åž‹ï¼š`boolean`

è¿™äº›åŸºæœ¬æ•°æ®ç±»åž‹æ˜¯Javaç¼–ç¨‹è¯­è¨€ä¸­çš„åŸºç¡€ï¼Œç”¨äºŽæž„å»ºæ›´å¤æ‚çš„ç¨‹åºå’Œç®—æ³•ã€‚
the total timecost is 5.136991024017334

172.30.154.145 - - [30/May/2024 15:15:34] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:15:34.530 | WARNING  | server.app.queries:generate_answer:210 - For query: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', detect the language is 'Chinese'!
2024-05-30 15:15:36.006 | WARNING  | server.app.queries:refine_query:105 - For the query: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', the refined query is 'Javaä¸­çš„æ–‡ä»¶è¯»å†™åŠŸèƒ½æ˜¯å¦‚ä½•å®žçŽ°çš„ï¼Œèƒ½è¯¦ç»†è¯´æ˜Žå—ï¼Ÿ'. The timecost is 1.4751131534576416
2024-05-30 15:15:36.006 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=prompt_tokens=630 completion_tokens=16 total_tokens=646
2024-05-30 15:15:36.400 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', k: 10, the timecost is 0.3925144672393799
2024-05-30 15:15:36.407 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Javaä¸­çš„æ–‡ä»¶è¯»å†™åŠŸèƒ½æ˜¯å¦‚ä½•å®žçŽ°çš„ï¼Œèƒ½è¯¦ç»†è¯´æ˜Žå—ï¼Ÿ', k: 10, the timecost is 0.3973853588104248
172.30.154.145 - - [30/May/2024 15:15:37] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:15:37.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.565 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.586 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.611 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.639 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.662 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.692 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.718 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.747 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.775 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.827 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.854 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.878 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.932 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.956 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:37.984 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.008 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.038 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.062 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.112 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.162 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.188 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.212 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.263 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.317 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.343 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.370 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.420 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.476 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.525 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.555 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.575 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.599 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.628 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.650 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.770 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.776 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.827 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.854 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:38.877 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.231 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.232 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.237 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.238 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.333 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.334 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.334 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.360 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.361 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.362 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.362 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.383 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.409 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.458 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.515 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.558 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.584 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.621 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.691 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.725 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.760 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.826 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.857 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.884 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:39.908 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.118 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.142 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.168 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.194 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.742 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.790 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.841 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.868 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.893 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:40.982 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.033 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.060 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.115 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.140 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.165 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.191 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.218 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.294 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.317 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.426 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.449 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.502 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.554 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.629 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.678 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.679 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.693 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.729 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.782 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.796 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.841 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.884 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.910 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.937 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.963 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:41.990 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.013 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.045 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.064 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.155 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.184 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.265 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.287 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.313 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.364 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.391 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.421 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.444 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.566 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.590 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.625 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.642 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.671 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.697 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.725 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.750 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.777 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.810 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.836 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.865 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.891 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.920 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.950 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:42.976 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.020 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.050 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.099 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.126 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.157 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.189 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.223 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.266 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.343 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.370 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.402 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.431 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.589 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.601 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.631 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.670 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.697 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.729 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.772 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.797 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.825 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.854 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.881 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.909 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.935 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.960 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:43.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.039 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.065 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.098 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.174 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.198 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.225 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.313 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.544 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.545 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.545 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.546 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.575 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.575 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.576 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.576 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.605 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.631 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.685 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.794 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.885 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.910 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.936 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.965 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:44.990 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.017 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.094 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.242 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.269 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.358 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.381 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.412 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.426 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.451 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.479 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.504 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.555 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.584 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.606 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.632 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.660 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.688 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.793 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.819 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.900 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.951 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:45.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.003 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.083 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.226 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.491 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.492 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.492 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.493 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.493 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.493 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.517 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.519 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.541 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.602 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.620 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.645 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.673 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.700 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.752 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.810 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.835 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.973 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:46.998 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.024 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.076 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.113 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.129 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.159 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.185 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.213 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.265 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.376 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.393 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.423 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.449 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.527 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.553 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.611 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.637 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.663 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.740 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.794 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.871 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.898 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.925 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.950 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:47.977 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.002 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.032 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.057 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.084 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.135 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.162 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.191 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.217 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.270 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.317 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.330 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.398 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.398 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.429 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.488 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.544 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.604 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.627 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.653 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.676 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.760 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.851 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.852 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.873 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.892 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:48.972 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.205 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.205 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.207 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.208 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.209 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.311 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.339 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.368 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.394 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.448 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.479 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.533 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.557 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.585 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.638 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.717 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.743 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.796 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.822 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.937 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:49.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.042 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.068 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.099 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.138 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.153 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.179 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.207 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.232 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.288 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.316 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.514 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.515 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.565 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.643 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.750 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.776 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.804 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.859 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.887 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.917 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.941 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.971 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:50.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.020 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.255 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.257 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.257 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.261 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.281 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.291 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.401 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.423 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.449 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.587 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.617 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.659 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.734 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.735 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.790 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.816 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.871 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.900 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.925 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.951 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:51.981 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.037 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.067 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.099 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.136 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.162 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.186 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.215 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.295 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.321 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.380 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.404 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.482 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.505 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.556 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.585 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.612 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.637 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.662 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.691 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.719 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.744 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.772 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.797 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.823 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.858 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.884 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.913 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.939 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:52.992 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.017 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.045 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.075 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.119 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.188 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.209 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.235 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.313 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.377 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.403 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.516 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.560 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.690 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.766 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.793 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:53.889 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.125 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.126 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.126 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.127 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.127 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.154 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.155 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.174 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.202 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.229 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.387 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.414 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.488 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.517 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.541 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.570 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.623 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.705 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.731 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.759 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.869 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.895 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.921 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.959 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:54.986 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.044 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.082 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.137 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.163 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.217 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.244 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.279 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.305 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.334 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.402 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.474 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.526 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.552 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.609 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.632 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.659 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.686 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.727 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.816 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.844 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.869 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.894 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.953 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:55.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.004 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.031 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.058 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.086 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.145 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.172 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.199 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.225 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.281 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.307 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.334 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.361 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.405 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.434 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.458 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.490 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.515 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.544 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.570 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.621 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.702 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=None
2024-05-30 15:15:56.803 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™', usage=prompt_tokens=1388 completion_tokens=666 total_tokens=2054
2024-05-30 15:15:56.805 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'å…·ä½“ä»‹ç»ä¸€ä¸‹Javaä¸­çš„æ–‡ä»¶è¯»å†™' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
Javaä¸­çš„æ–‡ä»¶è¯»å†™æ“ä½œæ˜¯Java IOï¼ˆè¾“å…¥/è¾“å‡ºï¼‰çš„ä¸€éƒ¨åˆ†ï¼Œå®ƒå…è®¸ç¨‹åºè¯»å–å’Œå†™å…¥æ–‡ä»¶ç³»ç»Ÿä¸­çš„æ–‡ä»¶ã€‚åœ¨Javaä¸­ï¼Œæ–‡ä»¶è¯»å†™é€šå¸¸ä½¿ç”¨ä»¥ä¸‹å‡ ç§æ–¹å¼ï¼š

1. **ä½¿ç”¨ `FileInputStream` å’Œ `FileOutputStream`**ï¼šè¿™äº›æ˜¯ç”¨äºŽè¯»å–å’Œå†™å…¥æ–‡ä»¶çš„å­—èŠ‚æµã€‚`FileInputStream` ç”¨äºŽè¯»å–æ–‡ä»¶ï¼Œè€Œ `FileOutputStream` ç”¨äºŽå†™å…¥æ–‡ä»¶ã€‚

   ```java
   // è¯»å–æ–‡ä»¶
   FileInputStream in = new FileInputStream("file.txt");
   // å†™å…¥æ–‡ä»¶
   FileOutputStream out = new FileOutputStream("file.txt");
   ```

2. **ä½¿ç”¨ `BufferedReader` å’Œ `BufferedWriter`**ï¼šè¿™äº›ç±»æä¾›äº†ç¼“å†²åŠŸèƒ½ï¼Œå¯ä»¥æ›´é«˜æ•ˆåœ°è¯»å†™æ–‡æœ¬æ–‡ä»¶ã€‚

   ```java
   // è¯»å–æ–‡æœ¬æ–‡ä»¶
   BufferedReader reader = new BufferedReader(new FileReader("file.txt"));
   // å†™å…¥æ–‡æœ¬æ–‡ä»¶
   BufferedWriter writer = new BufferedWriter(new FileWriter("file.txt"));
   ```

3. **ä½¿ç”¨ `Scanner` ç±»**ï¼šå¯ä»¥ç”¨æ¥è¯»å–æ–‡æœ¬æ–‡ä»¶ä¸­çš„æ•°æ®ï¼Œç‰¹åˆ«æ˜¯å½“æ–‡ä»¶æ ¼å¼æ¯”è¾ƒè§„èŒƒæ—¶ã€‚

   ```java
   Scanner scanner = new Scanner(new File("file.txt"));
   while (scanner.hasNextLine()) {
       String line = scanner.nextLine();
       // å¤„ç†æ¯ä¸€è¡Œ
   }
   ```

4. **ä½¿ç”¨ `java.nio.file` åŒ…ä¸­çš„ç±»**ï¼šåœ¨Java 7åŠä»¥ä¸Šç‰ˆæœ¬ï¼Œ`java.nio.file` åŒ…æä¾›äº†æ›´çŽ°ä»£çš„æ–‡ä»¶æ“ä½œAPIï¼Œå¦‚ `Files` å’Œ `Paths` ç±»ã€‚

   ```java
   // è¯»å–æ‰€æœ‰è¡Œåˆ°Listé›†åˆä¸­
   List<String> lines = Files.readAllLines(Paths.get("file.txt"));
   // å°†Listä¸­çš„å†…å®¹å†™å…¥æ–‡ä»¶
   Files.write(Paths.get("file.txt"), lines, StandardOpenOption.CREATE);
   ```

æ¯ç§æ–¹æ³•éƒ½æœ‰å…¶ç”¨é€”å’Œé€‚ç”¨åœºæ™¯ã€‚å­—èŠ‚æµé€‚åˆå¤„ç†äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œè€Œå­—ç¬¦æµé€‚åˆå¤„ç†æ–‡æœ¬æ–‡ä»¶ã€‚ç¼“å†²æµå¯ä»¥æé«˜è¯»å†™æ•ˆçŽ‡ã€‚`Scanner` ç±»å’Œ `java.nio.file` åŒ…ä¸­çš„ç±»æä¾›äº†æ›´ç®€æ´ã€æ›´æ˜“äºŽç†è§£çš„è¯­æ³•ã€‚

ä»¥ä¸Šæ˜¯å…³äºŽJavaä¸­æ–‡ä»¶è¯»å†™æ“ä½œçš„åŸºæœ¬ä»‹ç»ã€‚å¦‚æžœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„ä»£ç ç¤ºä¾‹æˆ–å…¶ä»–é«˜çº§ç‰¹æ€§ï¼Œè¯·å‘ŠçŸ¥æˆ‘ä»¥ä¾¿è¿›ä¸€æ­¥æä¾›å¸®åŠ©ã€‚

**Sources:**
- [Oracle Java Documentation](https://docs.oracle.com/javase/tutorial/essential/io/index.html)
- [Java NIO.2 API Specification](https://docs.oracle.com/javase/10/docs/api/java/nio/file/package-summary.html)
the total timecost is 22.275317907333374

172.30.155.138 - - [30/May/2024 15:32:21] "GET /open-kf-admin/ HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:21] "GET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:21] "GET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:22] "GET /open-kf-admin/assets/Dashboard-WB1KXATu.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:22] "GET /open-kf-admin/assets/Dashboard-BieUHPHe.css HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:22] "GET /open-kf-admin/assets/loading-vsHIitu7.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:22] "GET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:22] "GET /open-kf-admin/vite.svg HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:23] "GET /open-kf-admin/assets/Login-VKBBRRSv.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:26] "POST /open_kf_api/account/login HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:36] "GET /open-kf-chatbot HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:36] "GET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:36] "GET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1" 200 -
2024-05-30 15:33:37.253 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYzNjZmE0OTEtZmQ1ZC00MjEwLWFhOTgtOWFiNmQyYTkwNmVhIiwiZXhwIjoxNzE3NjU5MjE3fQ.RAPOHVM8Rj21nUL2shC2orq0YeA17fp_nhyuEuS51Es' with user_id: 'c3cfa491-fd5d-4210-aa98-9ab6d2a906ea'
172.30.155.138 - - [30/May/2024 15:33:37] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:37] "GET /open-kf-chatbot/vite.svg HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:37] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-05-30 15:33:47.777 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä½ å¥½', detect the language is 'Chinese'!
2024-05-30 15:33:49.425 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä½ å¥½', the refined query is 'ä½ å¥½ï¼Œè¯·é—®æ‚¨ä¹‹å‰å’ŒåŠ©æ‰‹äº¤æµäº†ä»€ä¹ˆå†…å®¹ï¼Ÿæ‚¨æƒ³ç»§ç»­è¯¢é—®å…³äºŽ `LangChain` çš„å“ªäº›å…·ä½“é—®é¢˜ï¼Ÿ'. The timecost is 1.6467335224151611
2024-05-30 15:33:49.425 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä½ å¥½', usage=prompt_tokens=323 completion_tokens=30 total_tokens=353
2024-05-30 15:33:49.687 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ï¼Œè¯·é—®æ‚¨ä¹‹å‰å’ŒåŠ©æ‰‹äº¤æµäº†ä»€ä¹ˆå†…å®¹ï¼Ÿæ‚¨æƒ³ç»§ç»­è¯¢é—®å…³äºŽ `LangChain` çš„å“ªäº›å…·ä½“é—®é¢˜ï¼Ÿ', k: 10, the timecost is 0.25896763801574707
2024-05-30 15:33:49.748 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½', k: 10, the timecost is 0.3219790458679199
172.30.155.138 - - [30/May/2024 15:33:50] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:33:50.718 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:50.772 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:50.800 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:50.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:50.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:50.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:50.907 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:50.933 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:50.958 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:50.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.011 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.038 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.067 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.096 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.125 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.179 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.203 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.228 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.288 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.310 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.339 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.392 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.479 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.481 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.501 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.529 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.557 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.586 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.612 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.667 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-05-30 15:33:51.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=prompt_tokens=1069 completion_tokens=37 total_tokens=1106
2024-05-30 15:33:51.770 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'ä½ å¥½' and user_id: 'c3cfa491-fd5d-4210-aa98-9ab6d2a906ea' is processed successfully, the answer is:
ä½ å¥½ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚å¦‚æžœæ‚¨æœ‰ä»»ä½•å…³äºŽLangChainçš„é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶æé—®ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚
the total timecost is 3.9938669204711914

172.20.157.198 - - [30/May/2024 22:58:40] code 400, message Bad request version ('Ã€\x13Ã€')
172.20.157.198 - - [30/May/2024 22:58:40] "[35m[1m\x16\x03\x01\x00Ã¡\x01\x00\x00Ã\x03\x03Â¢Â»Âª\x16\x95Ã©Ã´Âµ\x0bP\x10Ã¤ÃˆvÃ­ÃŸÃ»\x8aÃ©Ã¼Â¢\x11ÃŸI\x0c>\x02>\x95Ãœ{x \x18KÃ«Â¬)Ã¼Â¬Ã…t\x7fÂ¦%ÂµÂ§\x1b_~Â½Ã’Ã¼s\x9c\x98",Ã²)qt\x17Ã¨~\x00$\x13\x01\x13\x02\x13\x03Ã€/Ã€+Ã€0Ã€,ÃŒÂ©ÃŒÂ¨Ã€\x09Ã€\x13Ã€[0m" HTTPStatus.BAD_REQUEST -
Traceback (most recent call last):
  File "rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
Traceback (most recent call last):
  File "/home/zhy/RAG-GPT/rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
Traceback (most recent call last):
  File "/home/zhy/RAG-GPT/rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
2024-07-07 20:05:53.643 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:7000
 * Running on http://59.78.194.84:7000
[33mPress CTRL+C to quit[0m
172.20.146.14 - - [07/Jul/2024 20:06:34] "[33mGET / HTTP/1.1[0m" 404 -
172.20.146.14 - - [07/Jul/2024 20:06:34] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
172.20.146.14 - - [07/Jul/2024 20:06:41] "GET /open-kf-admin/ HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:41] "GET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:41] "GET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:42] "GET /open-kf-admin/assets/Setting-uk7UYz_k.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:42] "GET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:42] "GET /open-kf-admin/vite.svg HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:42] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:49] "GET /open-kf-chatbot/ HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:49] "GET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:50] "GET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1" 200 -
2024-07-07 20:06:53.660 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiMjAwMzQyZjAtMjUwZS00YzM4LTk3YjctMTlkZDU0N2M1N2ZkIiwiZXhwIjoxNzIwOTU4ODEzfQ.q0hKFAoe5Gf487qNzMB3ss1CrQOt3WyYa19U2W0KYGw' with user_id: '200342f0-250e-4c38-97b7-19dd547c57fd'
172.20.146.14 - - [07/Jul/2024 20:06:53] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:53] "GET /open-kf-chatbot/vite.svg HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:54] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-07-07 20:06:58.469 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.14 - - [07/Jul/2024 20:07:06] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    response = generate_answer(query, user_id, True)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
2024-07-07 20:07:21.395 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.14 - - [07/Jul/2024 20:07:29] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    response = generate_answer(query, user_id, True)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
2024-07-07 20:09:43.773 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
Address already in use
Port 7000 is in use by another program. Either identify and stop that program, or start the server with a different port.
2024-07-07 20:12:32.362 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
Address already in use
Port 7000 is in use by another program. Either identify and stop that program, or start the server with a different port.
2024-07-07 20:12:50.577 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:7001
 * Running on http://59.78.194.84:7001
[33mPress CTRL+C to quit[0m
172.20.146.14 - - [07/Jul/2024 20:12:55] "[33mGET / HTTP/1.1[0m" 404 -
172.20.146.14 - - [07/Jul/2024 20:12:55] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
172.20.146.14 - - [07/Jul/2024 20:13:01] "GET /open-kf-chatbot/ HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:13:01] "GET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:13:01] "GET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1" 200 -
2024-07-07 20:13:04.146 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzIwOTU5MTg0fQ.QFTdFDongKX2eMJF2ezNg1GUEwDcKttwd8cBpldIdEE' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.146.14 - - [07/Jul/2024 20:13:04] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:13:04] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:13:04] "GET /open-kf-chatbot/vite.svg HTTP/1.1" 200 -
2024-07-07 20:13:06.708 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.14 - - [07/Jul/2024 20:13:14] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    response = generate_answer(query, user_id, True)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.14 - - [07/Jul/2024 20:14:07] "GET /open-kf-admin/ HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:08] "GET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:08] "GET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:11] "GET /open-kf-admin/assets/Setting-uk7UYz_k.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:11] "GET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:11] "GET /open-kf-admin/vite.svg HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:11] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:38] "GET /open-kf-admin/assets/Login-VKBBRRSv.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:47] "POST /open_kf_api/account/login HTTP/1.1" 200 -
2024-07-07 20:15:26.327 | INFO     | server.app.account:login:35 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWRtaW4iLCJleHAiOjE3MjA5NTkzMjZ9.yXmPvGT5IqA7OWt_10sui4F6I9P3qmifuCFe9UcLzZE'
172.20.146.14 - - [07/Jul/2024 20:15:26] "POST /open_kf_api/account/login HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:15:26] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:15:30] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:15:30] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:15:30] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-07-07 20:15:31.301 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzIwOTU5MzMxfQ.jO5coJKN30ajLrkpP5V5jqq64i-OGS8wHlPiGTNsf7Y' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.146.14 - - [07/Jul/2024 20:15:31] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:15:31] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:15:31] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
2024-07-07 20:15:33.124 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.14 - - [07/Jul/2024 20:15:41] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
2024-07-07 20:45:46.685 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.14 - - [07/Jul/2024 20:45:51] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:45:54] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
2024-07-07 20:46:41.647 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
Create tables in the SQLite database
Create indexes for the tables
Initialize the admin account
[INFO] account_name:'admin' already exists.
Initialize the bot settings
[INFO] the bot setting already exists.
SQLite init Done!


Init Chroma DB
Init Chroma DB Done!
2024-07-07 20:46:45.892 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
172.20.146.14 - - [07/Jul/2024 20:46:53] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.14 - - [07/Jul/2024 20:47:28] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:29] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:29] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-07-07 20:47:29.753 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzIwOTYxMjQ5fQ.gp1uT31p9cWRDuASPHOnAMDJocqOxotmTvzQHV5WOV4' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.146.14 - - [07/Jul/2024 20:47:29] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:47:29] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:47:30] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:33] "[36mGET /open-kf-admin/ HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:33] "[36mGET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:33] "[36mGET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:34] "[36mGET /open-kf-admin/assets/Setting-uk7UYz_k.js HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:34] "[36mGET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:34] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:47:36] "[36mGET /open-kf-admin/vite.svg HTTP/1.1[0m" 304 -
2024-07-07 20:47:36.835 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
172.20.146.14 - - [07/Jul/2024 20:47:44] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.14 - - [07/Jul/2024 20:55:58] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 20:55:58.166 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-07 20:56:01.046 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'ãŠå®¢æ§˜ã¯ä»¥å‰ã€`java`ã«é–¢ã™ã‚‹è³ªå•ã‚’ã—ã¾ã—ãŸã‹ï¼Ÿå…·ä½“çš„ãªå†…å®¹ã‚„ã”ä¸æ˜Žãªç‚¹ã‚’æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼ŸãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã—ãŸã‚‰ã€é æ…®ãªããŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚'. The timecost is 2.879232406616211
2024-07-07 20:56:01.047 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=557 completion_tokens=74 total_tokens=631
2024-07-07 20:56:01.983 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.9356746673583984
2024-07-07 20:56:01.984 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ãŠå®¢æ§˜ã¯ä»¥å‰ã€`java`ã«é–¢ã™ã‚‹è³ªå•ã‚’ã—ã¾ã—ãŸã‹ï¼Ÿå…·ä½“çš„ãªå†…å®¹ã‚„ã”ä¸æ˜Žãªç‚¹ã‚’æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼ŸãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã—ãŸã‚‰ã€é æ…®ãªããŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚', k: 10, the timecost is 0.9347405433654785
172.20.146.14 - - [07/Jul/2024 20:56:03] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 20:56:03.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.439 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.440 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.443 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.443 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.444 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.802 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.803 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.804 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.804 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.805 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.805 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.806 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.806 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.807 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.807 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.829 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.830 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.831 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.881 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.914 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.939 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.966 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:03.988 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.012 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.037 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.077 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.102 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.125 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.150 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.181 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.206 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.231 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.281 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.304 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.329 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.363 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.407 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.447 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.471 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.496 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.526 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.559 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.576 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.600 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.624 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.656 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.677 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.704 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.728 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.752 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.776 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.828 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.882 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.907 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.931 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.956 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:04.983 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.013 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.030 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.057 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.123 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.147 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.171 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.216 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.241 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.268 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.290 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.319 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.343 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.367 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.421 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.446 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.470 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.495 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.520 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.544 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.569 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.594 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.619 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.646 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.670 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.692 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.718 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.743 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.767 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.791 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.816 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.842 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.869 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.902 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:05.976 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:06.003 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:06.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:06.058 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 20:56:06.157 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1301 completion_tokens=112 total_tokens=1413
2024-07-07 20:56:06.159 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
ã“ã‚“ã«ã¡ã¯ï¼è³ªå•ãŒã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿã”ä¸æ˜Žãªç‚¹ã‚„`java`ã«é–¢ã™ã‚‹ã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ãªå ´åˆã¯ã€å…·ä½“çš„ãªè³ªå•ã‚’ãŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚ã“ã®åº¦ã¯ä½•ã®è³ªå•ã‚‚å—ã‘å–ã£ã¦ãŠã‚Šã¾ã›ã‚“ã§ã—ãŸãŒã€ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Œã°ã€é æ…®ãªããŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚

Sources: ''
the total timecost is 7.99364972114563

172.20.146.14 - - [07/Jul/2024 21:08:29] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:08:29.873 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-07 21:08:33.135 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry seeking assistance with a Java-related question. To capture the relevant context while adhering to the guidelines provided, the refined standalone question would be:

"In our previous interaction, you expressed a need for support regarding Java. Could you please provide a specific question or area of concern related to Java that you would like assistance with?"'. The timecost is 3.2610361576080322
2024-07-07 21:08:33.135 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=506 completion_tokens=94 total_tokens=600
2024-07-07 21:08:33.459 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry seeking assistance with a Java-related question. To capture the relevant context while adhering to the guidelines provided, the refined standalone question would be:

"In our previous interaction, you expressed a need for support regarding Java. Could you please provide a specific question or area of concern related to Java that you would like assistance with?"', k: 10, the timecost is 0.3203911781311035
2024-07-07 21:08:33.460 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.3241424560546875
172.20.146.14 - - [07/Jul/2024 21:08:34] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:08:34.468 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:34.489 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:34.513 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
172.20.146.14 - - [07/Jul/2024 21:08:38] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:08:38.701 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-07 21:08:42.098 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry seeking assistance with a Java-related question. To capture the relevant context while adhering to the guidelines, the refined standalone question would be:

"In our previous interaction, you expressed a need for support regarding Java. Could you please provide a specific question or area of concern related to Java that you would like assistance with now?"'. The timecost is 3.3962790966033936
2024-07-07 21:08:42.099 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=506 completion_tokens=94 total_tokens=600
2024-07-07 21:08:42.357 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry seeking assistance with a Java-related question. To capture the relevant context while adhering to the guidelines, the refined standalone question would be:

"In our previous interaction, you expressed a need for support regarding Java. Could you please provide a specific question or area of concern related to Java that you would like assistance with now?"', k: 10, the timecost is 0.25519490242004395
2024-07-07 21:08:42.380 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.2803530693054199
172.20.146.14 - - [07/Jul/2024 21:08:43] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:08:43.400 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.478 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.502 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.548 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.574 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.622 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.646 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.672 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.694 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.719 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.744 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.767 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.791 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.815 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.848 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.866 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.888 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.911 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.941 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.960 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:43.982 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.012 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.037 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.060 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.085 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.108 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.133 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.182 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.231 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.254 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.280 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.302 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.333 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.351 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.379 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.396 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.420 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.445 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.478 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.502 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.527 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.552 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.582 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.621 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.645 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.751 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.773 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.798 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.829 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.848 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.897 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.945 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:44.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.019 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.045 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.077 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.096 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.120 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.144 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.170 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.198 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.223 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.247 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.297 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.332 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.374 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.405 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.434 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.455 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.486 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.510 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.535 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.558 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.584 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.623 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.634 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.657 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.682 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.714 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.738 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.794 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.852 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.875 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.900 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.925 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.950 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:45.974 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:46.049 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:46.073 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:46.098 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:46.123 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:08:46.226 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1250 completion_tokens=106 total_tokens=1356
2024-07-07 21:08:46.227 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
ãŠå®¢æ§˜ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã¯ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã‹ã‚‰ã®ç‰¹å®šã®çŸ¥è­˜ãŒå¿…è¦ã§ã™ã€‚ã—ã‹ã—ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦ã€å…·ä½“çš„ãªè³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿå…·ä½“çš„ãªè³ªå•ã‚„ã”ä¸æ˜Žãªç‚¹ã‚’ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚

Sources: ''
the total timecost is 7.526385068893433

172.20.146.14 - - [07/Jul/2024 21:08:53] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:08:53.221 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-07-07 21:08:58.893 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry or a request for assistance with a Java (`java`) related issue. However, the message is incomplete and lacks specific details. To capture the relevant context while adhering to the guidelines provided, the follow-up message should be rewritten as a standalone question that refers back to the original conversation with the assistant. The rewritten question should be concise and preserve the original intent of the follow-up message.

Refined Standalone Question: "In our previous interaction, you mentioned that you couldn't provide a specific answer based on the information provided. Could you please clarify which information you require to give a detailed response regarding Java support?"'. The timecost is 5.670899152755737
2024-07-07 21:08:58.894 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=503 completion_tokens=158 total_tokens=661
2024-07-07 21:08:59.139 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.2443525791168213
2024-07-07 21:08:59.169 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry or a request for assistance with a Java (`java`) related issue. However, the message is incomplete and lacks specific details. To capture the relevant context while adhering to the guidelines provided, the follow-up message should be rewritten as a standalone question that refers back to the original conversation with the assistant. The rewritten question should be concise and preserve the original intent of the follow-up message.

Refined Standalone Question: "In our previous interaction, you mentioned that you couldn't provide a specific answer based on the information provided. Could you please clarify which information you require to give a detailed response regarding Java support?"', k: 10, the timecost is 0.27184104919433594
172.20.146.14 - - [07/Jul/2024 21:09:01] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:09:01.298 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.320 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.344 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.368 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.391 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.415 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.438 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.462 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.486 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.510 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.559 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.583 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.607 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.629 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.653 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.676 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.700 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.724 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.747 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.771 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.794 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.818 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.842 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.892 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.915 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.940 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.963 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.995 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.020 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.043 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.066 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.097 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.115 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.164 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.165 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.191 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.212 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.237 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.260 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.283 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.307 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.331 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.355 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.379 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.403 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.428 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.458 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.475 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.501 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.626 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1245 completion_tokens=53 total_tokens=1298
2024-07-07 21:09:02.627 | SUCCESS  | server.app.queries:generate_llm:451 - query: '?' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 9.405974388122559

172.20.146.14 - - [07/Jul/2024 21:10:20] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:10:21.042 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-07 21:10:25.459 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of a request for assistance or information. However, without the content of the assistant's responses, it's unclear what specifically the human is seeking. Therefore, the best approach is to craft a question that acknowledges the human's need for further clarification or help, without directly referencing the assistant's messages. 

Refined Standalone Question:
```
å‰ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ãªè¿½åŠ æƒ…å ±ãŒå¿…è¦ã§ã™ã‹ï¼Ÿ
```
(Translation: What additional information do you need to answer the previous question?)'. The timecost is 4.41569185256958
2024-07-07 21:10:25.459 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=445 completion_tokens=144 total_tokens=589
2024-07-07 21:10:25.716 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.2562263011932373
2024-07-07 21:10:25.726 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of a request for assistance or information. However, without the content of the assistant's responses, it's unclear what specifically the human is seeking. Therefore, the best approach is to craft a question that acknowledges the human's need for further clarification or help, without directly referencing the assistant's messages. 

Refined Standalone Question:
```
å‰ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ãªè¿½åŠ æƒ…å ±ãŒå¿…è¦ã§ã™ã‹ï¼Ÿ
```
(Translation: What additional information do you need to answer the previous question?)', k: 10, the timecost is 0.26326751708984375
172.20.146.14 - - [07/Jul/2024 21:10:26] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:10:26.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:26.783 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:26.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:26.829 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:26.852 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:26.875 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:26.898 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:26.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:26.944 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.028 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.028 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.041 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.064 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.088 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.111 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.136 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.158 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.180 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.226 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.273 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.305 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.319 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.342 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.365 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.389 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.413 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.439 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.464 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.488 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.506 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.530 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.553 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.582 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.622 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.646 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.668 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.713 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.737 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.760 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.784 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.814 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.833 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.880 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.903 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.951 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.974 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:27.996 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.070 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.094 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.117 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.141 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.164 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.187 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.211 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.265 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.289 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.313 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.335 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.358 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.383 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.405 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.428 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.452 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.474 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.498 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.523 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.547 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.569 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.595 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.617 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.641 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.664 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.686 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.708 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.732 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.763 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.779 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.802 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.825 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.848 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.871 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.895 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.925 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.956 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:28.980 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:29.003 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:29.025 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:29.053 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:29.072 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:29.096 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:29.165 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:29.190 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:29.212 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:29.235 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:10:29.340 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1189 completion_tokens=106 total_tokens=1295
2024-07-07 21:10:29.341 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
ãŠå®¢æ§˜ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã¯ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã‹ã‚‰ã®ç‰¹å®šã®çŸ¥è­˜ãŒå¿…è¦ã§ã™ã€‚ã—ã‹ã—ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦ã€å…·ä½“çš„ãªè³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿå…·ä½“çš„ãªè³ªå•ã‚„ã”ä¸æ˜Žãªç‚¹ã‚’ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚

Sources: ''
the total timecost is 8.299574613571167

172.20.146.14 - - [07/Jul/2024 21:15:54] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:15:54.780 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-07 21:15:57.503 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'ãŠå®¢æ§˜ã¯ã€ä»¥å‰ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚’ã—ã¦ã„ãŸã‹ï¼Ÿãã‚Œã«å¯¾ã™ã‚‹ Assistant ã®å›žç­”ã¯ã€ã©ã®ã‚ˆã†ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã‹ï¼Ÿãã‚Œã«åŸºã¥ã„ã¦ã€ç¾åœ¨ã®è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã‹ï¼Ÿ'. The timecost is 2.7221977710723877
2024-07-07 21:15:57.504 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=445 completion_tokens=74 total_tokens=519
2024-07-07 21:15:57.808 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ãŠå®¢æ§˜ã¯ã€ä»¥å‰ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚’ã—ã¦ã„ãŸã‹ï¼Ÿãã‚Œã«å¯¾ã™ã‚‹ Assistant ã®å›žç­”ã¯ã€ã©ã®ã‚ˆã†ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã‹ï¼Ÿãã‚Œã«åŸºã¥ã„ã¦ã€ç¾åœ¨ã®è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã‹ï¼Ÿ', k: 10, the timecost is 0.301389217376709
2024-07-07 21:15:57.832 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.32740259170532227
172.20.146.14 - - [07/Jul/2024 21:15:58] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:15:58.847 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:58.992 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.020 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.068 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.099 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.130 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.147 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.171 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.248 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.269 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.297 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.332 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.346 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.370 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.394 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.447 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.470 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.494 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.518 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.543 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.567 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.619 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.642 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.668 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.721 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.744 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.771 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.793 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.825 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.844 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.870 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.893 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.918 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.943 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.967 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:15:59.993 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.017 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.068 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.092 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.142 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.167 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.192 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.216 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.242 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.268 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.291 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.316 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.343 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.369 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.393 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.417 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.443 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.471 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.494 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.518 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.543 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.569 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.596 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.620 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.644 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.671 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.695 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.720 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.744 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.768 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.795 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.833 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.845 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.897 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:00.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.001 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.025 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.051 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.074 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.099 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.149 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.224 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.279 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.305 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.329 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.353 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.377 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.418 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.460 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.492 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.567 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.593 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.617 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.654 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:16:01.746 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1189 completion_tokens=106 total_tokens=1295
2024-07-07 21:16:01.747 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
ãŠå®¢æ§˜ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã¯ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã‹ã‚‰ã®ç‰¹å®šã®çŸ¥è­˜ãŒå¿…è¦ã§ã™ã€‚ã—ã‹ã—ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦ã€å…·ä½“çš„ãªè³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿå…·ä½“çš„ãªè³ªå•ã‚„ã”ä¸æ˜Žãªç‚¹ã‚’ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚

Sources: ''
the total timecost is 6.9681642055511475

172.20.146.14 - - [07/Jul/2024 21:24:43] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:24:43.174 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-07 21:24:45.516 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'ãŠå®¢æ§˜ã¯ã€ä»¥å‰ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚’ã—ã¦ã„ãŸã‹ï¼Ÿãã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«å¿…è¦ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ'. The timecost is 2.3406238555908203
2024-07-07 21:24:45.517 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=500 completion_tokens=49 total_tokens=549
2024-07-07 21:24:46.244 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ãŠå®¢æ§˜ã¯ã€ä»¥å‰ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚’ã—ã¦ã„ãŸã‹ï¼Ÿãã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«å¿…è¦ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ', k: 10, the timecost is 0.7243831157684326
2024-07-07 21:24:46.259 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.741180419921875
172.20.146.14 - - [07/Jul/2024 21:24:47] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:24:47.221 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.244 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.269 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.292 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.317 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.341 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.366 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.391 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.416 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.439 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.464 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.489 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.514 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.563 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.588 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.613 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.638 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.662 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.717 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.742 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.766 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.791 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.814 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.840 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.868 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.892 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.919 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.945 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:47.999 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.052 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.075 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.100 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.148 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.175 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.197 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.223 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.247 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.271 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.295 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.322 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.347 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.395 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.418 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.440 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.463 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.487 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.511 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.532 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.555 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.578 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.601 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.625 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.648 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.670 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.694 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.718 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.742 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.764 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.788 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.811 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.834 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.881 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.905 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.950 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.972 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:48.996 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.019 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.065 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.088 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.114 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.137 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.160 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.182 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.231 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.253 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.276 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.300 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.322 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.345 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.368 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.393 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.415 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.438 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.462 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.485 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.510 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.558 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.581 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.719 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:24:49.835 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1244 completion_tokens=106 total_tokens=1350
2024-07-07 21:24:49.836 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
ãŠå®¢æ§˜ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã¯ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã‹ã‚‰ã®ç‰¹å®šã®çŸ¥è­˜ãŒå¿…è¦ã§ã™ã€‚ã—ã‹ã—ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦ã€å…·ä½“çš„ãªè³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿå…·ä½“çš„ãªè³ªå•ã‚„ã”ä¸æ˜Žãªç‚¹ã‚’ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚

Sources: ''
the total timecost is 6.662122964859009

172.20.146.14 - - [07/Jul/2024 21:30:42] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:30:42.850 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-07 21:30:45.278 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'ãŠå®¢æ§˜ã¯ã€ä»¥å‰ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚’ã—ã¦ã„ãŸã‹ï¼Ÿãã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«å¿…è¦ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ'. The timecost is 2.4273524284362793
2024-07-07 21:30:45.279 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=500 completion_tokens=49 total_tokens=549
2024-07-07 21:30:45.597 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ãŠå®¢æ§˜ã¯ã€ä»¥å‰ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚’ã—ã¦ã„ãŸã‹ï¼Ÿãã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«å¿…è¦ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ', k: 10, the timecost is 0.3144049644470215
2024-07-07 21:30:46.006 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.7264013290405273
172.20.146.14 - - [07/Jul/2024 21:30:47] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:30:47.039 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.122 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.146 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.170 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.195 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.244 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.269 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.293 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.317 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.389 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.391 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.418 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.440 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.463 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.487 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.512 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.537 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.565 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.584 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.608 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.635 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.663 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.686 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.712 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.736 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.758 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.782 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.810 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.834 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.859 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.881 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.906 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.930 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.954 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:47.981 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.004 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.035 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.051 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.076 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.100 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.125 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.149 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.172 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.227 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.250 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.297 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.322 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.347 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.370 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.393 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.417 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.452 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.465 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.490 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.515 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.564 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.565 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.589 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.612 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.670 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.725 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.744 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.768 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.791 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.817 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.840 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.899 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.912 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.940 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.964 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:48.987 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.013 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.035 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.059 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.128 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.153 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.201 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.226 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.250 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.331 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.355 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.379 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.402 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.432 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.457 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.487 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.505 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.530 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.554 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.583 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.752 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.778 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-07 21:30:49.945 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1244 completion_tokens=106 total_tokens=1350
2024-07-07 21:30:49.946 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
ãŠå®¢æ§˜ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã¯ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã‹ã‚‰ã®ç‰¹å®šã®çŸ¥è­˜ãŒå¿…è¦ã§ã™ã€‚ã—ã‹ã—ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦ã€å…·ä½“çš„ãªè³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿå…·ä½“çš„ãªè³ªå•ã‚„ã”ä¸æ˜Žãªç‚¹ã‚’ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚

Sources: ''
the total timecost is 7.097132682800293

172.20.146.181 - - [08/Jul/2024 14:47:46] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:47:46.324 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
172.20.146.181 - - [08/Jul/2024 14:47:54] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:47:55] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:47:55.372 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
172.20.146.181 - - [08/Jul/2024 14:48:03] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:51:50] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:51:50.316 | WARNING  | server.app.queries:generate_answer:210 - For query: '?
', detect the language is 'English'!
172.20.146.181 - - [08/Jul/2024 14:51:58] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:52:54] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:52:54.488 | WARNING  | server.app.queries:generate_answer:210 - For query: '?
', detect the language is 'English'!
172.20.146.181 - - [08/Jul/2024 14:53:02] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:53:14] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:53:14.808 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.181 - - [08/Jul/2024 14:53:21] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:53:21.259 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.181 - - [08/Jul/2024 14:53:22] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:53:29] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
Traceback (most recent call last):
  File "rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
172.20.146.181 - - [08/Jul/2024 14:55:09] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:55:09.107 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.181 - - [08/Jul/2024 14:55:17] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:56:19] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:56:20.015 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-07-08 14:56:23.537 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the context of the conversation, the follow-up message "?" appears to be an inquiry seeking clarification or further information. To create a standalone question that captures the relevant context from the conversation, we can infer that the human is interested in a specific aspect of `LangChain`'s services, although the exact nature of their question is not explicit in the follow-up message.

Refined Standalone Question: "What additional information can you provide about LangChain's services?"'. The timecost is 3.5207910537719727
2024-07-08 14:56:23.537 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=320 completion_tokens=108 total_tokens=428
2024-07-08 14:56:23.872 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the context of the conversation, the follow-up message "?" appears to be an inquiry seeking clarification or further information. To create a standalone question that captures the relevant context from the conversation, we can infer that the human is interested in a specific aspect of `LangChain`'s services, although the exact nature of their question is not explicit in the follow-up message.

Refined Standalone Question: "What additional information can you provide about LangChain's services?"', k: 10, the timecost is 0.3304874897003174
2024-07-08 14:56:23.922 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.38358068466186523
172.20.146.181 - - [08/Jul/2024 14:56:24] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:56:24.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:24.950 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:24.968 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:24.996 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.028 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.052 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.080 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.104 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.130 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.156 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.183 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.235 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.294 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.310 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.335 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.367 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.391 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.414 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.439 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.462 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.486 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.510 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.559 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.581 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.606 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.631 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.661 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.680 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.703 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.728 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.752 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.776 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.799 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.847 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.882 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.896 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.919 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.944 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.971 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.997 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.026 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.054 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.076 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.100 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.123 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.148 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.273 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1062 completion_tokens=53 total_tokens=1115
2024-07-08 14:56:26.274 | SUCCESS  | server.app.queries:generate_llm:451 - query: '?' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 6.259382247924805

Traceback (most recent call last):
  File "rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
172.20.146.181 - - [08/Jul/2024 16:25:42] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:25:42.786 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿï¼Ÿï¼Ÿ', detect the language is 'Chinese'!
2024-07-08 16:25:44.228 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿï¼Ÿï¼Ÿ', the refined query is 'æ‚¨å¥½ï¼Œæˆ‘ä¹‹å‰è¯¢é—®äº†å…³äºŽ`LangChain`çš„æœåŠ¡ä¿¡æ¯ï¼Œæ‚¨æ˜¯å¦èƒ½å¸®æˆ‘è¯¦ç»†è§£ç­”ä¸€äº›ç›¸å…³é—®é¢˜ï¼Ÿ'. The timecost is 1.441460371017456
2024-07-08 16:25:44.229 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=prompt_tokens=324 completion_tokens=27 total_tokens=351
2024-07-08 16:25:44.543 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'æ‚¨å¥½ï¼Œæˆ‘ä¹‹å‰è¯¢é—®äº†å…³äºŽ`LangChain`çš„æœåŠ¡ä¿¡æ¯ï¼Œæ‚¨æ˜¯å¦èƒ½å¸®æˆ‘è¯¦ç»†è§£ç­”ä¸€äº›ç›¸å…³é—®é¢˜ï¼Ÿ', k: 10, the timecost is 0.3110363483428955
2024-07-08 16:25:44.549 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿï¼Ÿï¼Ÿ', k: 10, the timecost is 0.3193645477294922
172.20.146.181 - - [08/Jul/2024 16:25:45] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:25:45.569 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.591 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.616 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.640 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.665 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.690 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.713 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.737 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.786 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.812 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.838 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.861 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.884 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.909 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.940 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.957 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:45.981 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.005 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.029 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.056 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.078 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.100 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.125 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.175 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.203 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.227 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.256 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.278 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.303 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.327 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.374 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.400 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.423 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:25:46.517 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿ', usage=prompt_tokens=1070 completion_tokens=38 total_tokens=1108
2024-07-08 16:25:46.518 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿï¼Ÿï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
æ‚¨å¥½ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿå¦‚æžœæ‚¨æœ‰å…³äºŽ`LangChain`çš„å…·ä½“é—®é¢˜ï¼Œè¯·éšæ—¶æé—®ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚
the total timecost is 3.732966899871826

172.20.146.181 - - [08/Jul/2024 16:26:14] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:26:14.527 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-08 16:26:15.913 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Sorry, I couldn't understand your question. Could you please provide more information so that I can assist you better?'. The timecost is 1.3852038383483887
2024-07-08 16:26:15.914 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=313 completion_tokens=27 total_tokens=340
2024-07-08 16:26:16.178 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.26366639137268066
2024-07-08 16:26:16.207 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Sorry, I couldn't understand your question. Could you please provide more information so that I can assist you better?', k: 10, the timecost is 0.2902979850769043
172.20.146.181 - - [08/Jul/2024 16:26:17] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:26:17.142 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.165 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.186 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.232 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.254 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.277 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.302 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.323 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.349 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.370 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.396 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.420 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.445 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.468 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.489 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.511 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.556 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.580 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.606 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.624 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.651 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.670 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.692 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.716 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.745 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.765 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.789 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.814 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.837 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.858 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.884 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.908 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:17.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.028 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.040 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.066 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.087 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.109 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.132 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.154 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.192 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.203 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.226 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.271 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.295 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.316 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.339 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.362 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.385 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.408 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.437 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.476 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.501 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.522 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.547 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.573 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.622 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.646 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.666 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.711 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.734 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.790 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.805 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.825 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.848 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.872 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.896 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.916 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.943 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.971 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:18.988 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.010 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.034 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.056 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.079 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.101 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.168 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.170 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.193 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.217 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.240 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.263 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.286 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.308 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.333 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.358 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.387 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.406 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.430 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.474 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.526 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.550 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.576 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.619 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.642 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.665 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.687 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.711 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.736 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.758 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.782 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.804 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.827 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.852 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.874 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.896 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.918 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.941 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.964 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:19.988 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.012 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.033 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.057 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.081 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.104 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.129 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.149 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.201 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.218 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.243 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.267 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.289 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.357 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.380 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.403 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.426 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.451 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.480 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.504 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.532 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.540 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.571 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.588 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.611 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.634 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.658 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.681 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.708 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.729 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.750 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.774 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.796 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.820 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.866 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.918 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:20.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.018 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.040 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.062 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.085 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.111 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.200 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.263 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.286 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.313 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.336 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.357 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.378 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.400 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.425 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.447 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.470 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.495 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.516 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.544 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.563 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.587 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.611 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.632 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.668 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.682 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.706 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.731 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.755 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.779 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.799 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.822 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.847 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.868 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.901 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.917 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.961 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:21.991 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.030 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.060 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.080 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.102 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.175 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.218 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.241 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.269 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.292 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.311 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.336 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.356 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.380 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.402 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.428 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.450 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.474 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.498 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.521 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.544 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.570 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.590 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.614 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.644 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.660 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.728 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.752 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.775 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.851 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.875 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.898 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.944 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.981 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:22.999 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:23.013 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:23.037 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:23.059 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:23.082 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:23.106 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:23.128 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:23.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:23.178 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:23.197 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:26:23.314 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1057 completion_tokens=259 total_tokens=1316
2024-07-08 16:26:23.315 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
æ‚¨å¥½ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿå¦‚æžœæ‚¨æœ‰å…³äºŽ`LangChain`çš„å…·ä½“é—®é¢˜ï¼Œè¯·éšæ—¶æé—®ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚

å¦‚æžœæ‚¨çš„é—®é¢˜æ˜¯å…³äºŽå¦‚ä½•ä½¿ç”¨`LangChain`è¿›è¡Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›ä¸€äº›åŸºæœ¬çš„ä¿¡æ¯ã€‚`LangChain`æ˜¯ä¸€ä¸ªå¼€æºçš„è‡ªç„¶è¯­è¨€å¤„ç†æ¡†æž¶ï¼Œå®ƒæä¾›äº†ä¸°å¯Œçš„å·¥å…·å’Œåº“ï¼Œç”¨äºŽå¤„ç†å„ç§è‡ªç„¶è¯­è¨€ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€å‘½åå®žä½“è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æžç­‰ã€‚å®ƒåŸºäºŽPythonè¯­è¨€ï¼Œæ˜“äºŽå®‰è£…å’Œä½¿ç”¨ã€‚æ‚¨å¯ä»¥åœ¨å…¶å®˜æ–¹ç½‘ç«™[LangChainå®˜ç½‘](https://www.langchain.org/)ä¸Šæ‰¾åˆ°æ›´å¤šå…³äºŽå®ƒçš„ä¿¡æ¯ã€‚

å¦‚æžœæ‚¨çš„é—®é¢˜æ˜¯å…³äºŽ`LangChain`çš„æŸä¸ªç‰¹å®šåŠŸèƒ½æˆ–åº”ç”¨ï¼Œè¯·æä¾›æ›´å¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘èƒ½å¤Ÿä¸ºæ‚¨æä¾›æ›´å…·ä½“çš„ç­”æ¡ˆã€‚

å¦‚æžœæ‚¨çš„å•é¡Œæ˜¯ä¸Ž`LangChain`æ— å…³çš„å…¶ä»–å…§å®¹ï¼Œæˆ‘å¯èƒ½ç„¡æ³•æä¾›ç›¸é—œçš„ç­”æ¡ˆã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘å»ºè­°æ‚¨å°‹æ‰¾å…¶ä»–é©ç•¶çš„ä¾†æºæˆ–å°ˆæ¥­äººå£«ä»¥ç²å¾—æ‰€éœ€çš„å¹«åŠ©ã€‚

ä»¥ä¸Šæ˜¯é—œæ–¼`LangChain`çš„åŸºæœ¬ä¿¡æ¯ï¼Œå¦‚æžœæ‚¨æœ‰å…¶ä»–å•é¡Œï¼Œè«‹éš¨æ™‚æå•ã€‚

Sources:
- [LangChainå®˜ç½‘](https://www.langchain.org/)
the total timecost is 8.788235425949097

172.20.146.181 - - [08/Jul/2024 16:26:29] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:26:29.839 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', detect the language is 'Chinese'!
2024-07-08 16:26:32.549 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', the refined query is 'è¯·é—®æ‚¨ä¹‹å‰è¯¢é—®å…³äºŽ`LangChain`çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿè¿™æ ·æˆ‘å¯ä»¥æ›´å¥½åœ°ç†è§£æ‚¨çš„éœ€æ±‚å¹¶æä¾›æ›´å‡†ç¡®çš„å›žç­”ã€‚'. The timecost is 2.7090954780578613
2024-07-08 16:26:32.550 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=prompt_tokens=587 completion_tokens=27 total_tokens=614
2024-07-08 16:26:32.783 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'è¯·é—®æ‚¨ä¹‹å‰è¯¢é—®å…³äºŽ`LangChain`çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿè¿™æ ·æˆ‘å¯ä»¥æ›´å¥½åœ°ç†è§£æ‚¨çš„éœ€æ±‚å¹¶æä¾›æ›´å‡†ç¡®çš„å›žç­”ã€‚', k: 10, the timecost is 0.22902441024780273
2024-07-08 16:26:32.840 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', k: 10, the timecost is 0.28870081901550293
172.20.146.181 - - [08/Jul/2024 16:26:33] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:26:33.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:33.951 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:33.973 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.004 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.051 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.076 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.101 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.174 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.230 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.256 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.276 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.300 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.325 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.352 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.375 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.400 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.425 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.448 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.473 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.500 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.549 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.573 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.602 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.644 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.667 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.717 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.745 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.770 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.815 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.845 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.871 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.897 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.944 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:34.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.020 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.047 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.076 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.107 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.150 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.172 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.197 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.252 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.272 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.296 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.394 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.468 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.499 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.526 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.550 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.573 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.599 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.622 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.648 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.702 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.726 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.751 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.776 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.851 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.874 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=None
2024-07-08 16:26:35.979 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ', usage=prompt_tokens=1333 completion_tokens=80 total_tokens=1413
2024-07-08 16:26:35.980 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
å¯¹ä¸èµ·ï¼Œæˆ‘æ— æ³•ä»Žæä¾›çš„ä¿¡æ¯ä¸­æ‰¾åˆ°å…³äºŽ'ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ'çš„å…·ä½“ç­”æ¡ˆã€‚æˆ‘åœ¨æ­¤ä¸ºæ‚¨æä¾›ä¸Ž`LangChain`ç›¸å…³çš„ä¿¡æ¯æœåŠ¡ã€‚å¦‚æžœæ‚¨æœ‰å…³äºŽæˆ‘ä»¬çš„æœåŠ¡æˆ–éœ€è¦å¸®åŠ©çš„å…·ä½“é—®é¢˜ï¼Œè¯·éšæ—¶æé—®ï¼Œæˆ‘å°†å°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚

Sources:
- [LangChainå®˜ç½‘](https://www.langchain.org/)
the total timecost is 6.141411542892456

172.20.146.181 - - [08/Jul/2024 16:27:29] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:27:29.505 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-08 16:27:33.800 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures all relevant context from the conversation would be:

```
å‰å›žã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚LangChainã®ä½¿ã„æ–¹ã‚„ç‰¹å®šã®æ©Ÿèƒ½ã«ã¤ã„ã¦ã®è³ªå•ã§ã™ã€‚
```

This question is in Japanese, which matches the original language of the follow-up message, and it references the previous conversation about LangChain without directly using the Assistant's responses. It also remains concise to avoid altering the original intent of the follow-up message.'. The timecost is 4.2943525314331055
2024-07-08 16:27:33.801 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=628 completion_tokens=137 total_tokens=765
2024-07-08 16:27:34.075 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.2728431224822998
2024-07-08 16:27:34.131 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures all relevant context from the conversation would be:

```
å‰å›žã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚LangChainã®ä½¿ã„æ–¹ã‚„ç‰¹å®šã®æ©Ÿèƒ½ã«ã¤ã„ã¦ã®è³ªå•ã§ã™ã€‚
```

This question is in Japanese, which matches the original language of the follow-up message, and it references the previous conversation about LangChain without directly using the Assistant's responses. It also remains concise to avoid altering the original intent of the follow-up message.', k: 10, the timecost is 0.3270101547241211
172.20.146.181 - - [08/Jul/2024 16:27:35] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:27:35.281 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.354 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.380 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.404 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.435 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.454 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.484 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.503 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.535 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.554 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.579 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.604 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.651 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.657 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.685 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.706 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.730 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.756 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.780 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.807 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.831 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.855 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.881 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.905 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.931 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:35.979 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.003 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.057 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.080 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.102 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.126 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.152 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.180 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.206 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.225 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.250 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.299 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.328 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.347 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.373 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.396 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.421 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.446 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.484 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.499 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.551 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.584 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.622 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.695 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.719 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.794 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.818 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.864 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.890 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.912 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:36.935 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.120 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.298 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.324 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.351 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.420 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.422 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.447 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.473 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.495 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.558 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.577 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.612 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.624 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.649 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.675 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.698 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.727 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.746 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.771 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.836 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.853 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.878 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.901 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.925 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:37.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.025 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.053 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.073 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.097 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.122 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.146 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.181 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.260 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.273 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.299 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.325 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.363 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.421 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.459 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.482 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.508 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.530 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.558 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.578 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.602 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.627 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.649 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.674 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.700 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.728 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.751 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.775 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.825 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.850 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.874 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.902 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.925 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:38.973 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.000 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.023 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.048 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.072 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.098 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.122 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.155 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.204 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.227 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.279 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.303 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.330 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.369 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.395 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.466 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.491 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.553 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.583 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.607 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.632 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.672 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.685 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.708 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.736 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.760 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.783 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.807 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.834 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.882 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.913 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.933 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.955 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:39.980 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.009 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.034 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.058 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.084 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.108 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.137 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.157 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.182 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.212 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.232 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.281 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.304 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.329 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.464 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.490 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.513 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.562 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.589 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.613 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.636 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.667 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.699 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.718 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.741 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.766 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.793 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.817 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.890 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.919 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.982 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.983 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:40.993 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.015 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.039 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.071 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.098 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.116 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.140 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.167 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.208 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.215 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.240 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.264 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.338 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.362 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.388 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.415 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.438 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.465 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.486 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.518 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.563 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.595 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.620 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.661 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.683 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.705 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.729 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.756 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.779 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.812 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.828 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.854 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.877 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.904 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.929 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:41.980 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.009 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.032 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.064 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.083 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.106 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.130 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.156 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.186 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.204 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.230 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.278 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.304 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.327 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.357 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.379 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.403 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.429 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.505 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.530 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.554 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.612 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.632 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.657 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.679 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.704 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.731 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.757 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.779 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.829 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.862 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.882 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.910 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.948 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.957 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:42.986 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.008 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.033 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.114 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.115 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.115 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.133 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.158 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.183 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.233 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.281 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.312 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.336 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.362 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.385 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.411 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.461 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.485 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.511 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.535 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.561 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.591 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.609 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.638 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.661 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.685 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.709 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.737 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.763 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.787 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.813 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.836 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.861 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.887 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.911 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.952 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.962 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:43.987 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.011 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.066 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.067 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.088 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.150 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.167 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.190 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.214 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.263 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.294 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.316 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.342 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.378 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.393 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.421 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.446 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.473 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.498 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.526 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.549 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.623 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.654 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.722 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.746 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.774 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.796 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.819 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.890 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.912 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.937 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.959 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:44.981 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.009 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.041 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.062 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.084 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.109 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.131 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.155 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.177 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.200 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.224 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.294 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.315 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.341 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.364 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.388 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.473 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.496 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.511 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.604 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.626 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.697 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.721 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.753 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.775 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.797 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.814 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.850 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:45.865 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.094 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.123 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.164 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.188 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.215 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.236 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.283 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.365 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.383 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.412 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.455 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.482 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.502 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.528 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.552 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.589 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.600 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.626 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.648 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.678 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.722 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.743 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.773 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.797 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.822 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.844 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.871 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.906 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.917 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.958 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.974 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:46.992 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:47.015 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:47.046 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:47.064 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:47.086 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:47.111 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:27:47.256 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1372 completion_tokens=451 total_tokens=1823
2024-07-08 16:27:47.257 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
ãŠå®¢æ§˜ã€ã“ã‚“ã«ã¡ã¯ï¼ã©ã†ã„ãŸã—ã¾ã—ã¦ã€ä½•ã‹ãŠå›°ã‚Šã§ã—ã‚‡ã†ã‹ï¼Ÿ LangChainã«é–¢ã™ã‚‹è³ªå•ã‚„ã€ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦ã®è³ªå•ãªã©ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚ç§ã¯ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã‚‹é™ã‚Šã€æœ€å¤§ã®åŠªåŠ›ã‚’ã—ã¾ã™ã€‚

LangChainã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®è‡ªç„¶è¨€èªžå‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡žã€åå‰ã®å®Ÿä½“èªè­˜ã€æ„Ÿæƒ…åˆ†æžãªã©ã€ã•ã¾ã–ã¾ãªè‡ªç„¶è¨€èªžã®ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚Pythonè¨€èªžãƒ™ãƒ¼ã‚¹ã§ã€ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ä½¿ç”¨ã§ãã¾ã™ã€‚è©³ç´°ã¯å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ[LangChainå…¬å¼](https://www.langchain.org/)ã‚’ã”è¦§ãã ã•ã„ã€‚

ç‰¹å®šã®æ©Ÿèƒ½ã‚„å¿œç”¨ã«ã¤ã„ã¦ã®è³ªå•ãŒã‚ã‚Œã°ã€ã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‚ˆã†ã«ãŠé¡˜ã„ã—ã¾ã™ã€‚

è³ªå•ãŒLangChainã«é–¢é€£ã—ã¦ã„ãªã„å ´åˆã¯ã€ãã®ã“ã¨ã‚’ä¼ãˆã•ã›ã¦ã„ãŸã ãã€ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ããªã„ã¨è¨€ã„ã¾ã™ã€‚ãã®å ´åˆã€é©åˆ‡ãªæƒ…å ±æºã‚„å°‚é–€å®¶ã«å°‹ã­ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

ä»¥ä¸Šã€LangChainã«é–¢ã™ã‚‹åŸºæœ¬æƒ…å ±ã§ã™ã€‚ä»–ã®è³ªå•ãŒã‚ã‚Œã°ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚

æƒ…å ±æº:
- [LangChainå…¬å¼](https://www.langchain.org/)

æ–‡çŒ®æƒ…å ±:
ç¾åœ¨ã®è³ªå•ã«ç›´æŽ¥é–¢é€£ã™ã‚‹æ–‡çŒ®ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚
the total timecost is 17.75220775604248

172.20.146.181 - - [08/Jul/2024 16:28:27] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:28:27.591 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-08 16:28:32.317 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Given the conversation history, the follow-up message "ï¼Ÿ" seems to be a continuation of the human's inquiry. However, without additional context or a clear indication of the human's intent, it's challenging to rewrite the message as a standalone question. If the human's true intent cannot be determined, it is best not to modify the follow-up message to avoid generating an incorrect question.

As the follow-up message is short and lacks context, the refined standalone question based on the conversation history would simply be:

"In relation to the previous discussion about LangChain, what specific information are you seeking?"'. The timecost is 4.72478461265564
2024-07-08 16:28:32.317 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=820 completion_tokens=137 total_tokens=957
2024-07-08 16:28:32.603 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.28475522994995117
2024-07-08 16:28:32.613 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message "ï¼Ÿ" seems to be a continuation of the human's inquiry. However, without additional context or a clear indication of the human's intent, it's challenging to rewrite the message as a standalone question. If the human's true intent cannot be determined, it is best not to modify the follow-up message to avoid generating an incorrect question.

As the follow-up message is short and lacks context, the refined standalone question based on the conversation history would simply be:

"In relation to the previous discussion about LangChain, what specific information are you seeking?"', k: 10, the timecost is 0.2922182083129883
172.20.146.181 - - [08/Jul/2024 16:28:33] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:28:33.872 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:33.925 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:33.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:33.974 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.009 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.024 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.053 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.077 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.100 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.125 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.153 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.175 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.229 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.254 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.278 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.302 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.326 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.374 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.398 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.422 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.447 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.470 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.492 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.516 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.540 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.564 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.588 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.618 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.640 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.666 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.692 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.714 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.739 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.782 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.807 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.822 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.847 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.871 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.894 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.919 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.943 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.966 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:34.990 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.014 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.072 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.095 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.119 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.143 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.167 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.197 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.215 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.239 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.263 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.287 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.361 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.382 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.406 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.430 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.457 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.486 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.510 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.563 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.586 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.611 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.640 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.658 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.681 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.709 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.737 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.766 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.777 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.802 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.872 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.899 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.923 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.947 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:35.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.017 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.066 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.091 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.114 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.137 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.162 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.187 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.212 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.234 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.264 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.335 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.361 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.384 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.407 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.432 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.458 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.480 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.503 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.527 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.551 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.579 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.623 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.646 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.682 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.720 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.744 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.780 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.792 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.829 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.839 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.865 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.891 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.916 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.943 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.965 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:36.986 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.011 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.043 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.057 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.081 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.106 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.131 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.156 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.204 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.227 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.252 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.299 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.322 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.346 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.394 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.466 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.491 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.572 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.595 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.621 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.645 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.695 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.718 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.746 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.768 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.793 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.832 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.846 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.873 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.897 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.948 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:37.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.021 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.053 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.068 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.094 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.117 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.142 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.203 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.215 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.241 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.273 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.293 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.321 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.343 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.373 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.418 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.469 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.495 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.519 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.566 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.591 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.618 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.641 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.665 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.697 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.720 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.748 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.775 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.796 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.820 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.846 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.869 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.902 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.922 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:38.979 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.004 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.103 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.104 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.105 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.133 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.178 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.225 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.252 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.281 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.303 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.340 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.354 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.377 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.402 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.431 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.455 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.480 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.504 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.561 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.632 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.664 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.705 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.712 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.741 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.763 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.799 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.810 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.855 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.862 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.889 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.920 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.961 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.962 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:39.985 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.022 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.037 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.072 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.086 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.112 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.154 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.172 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.197 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.300 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.324 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.348 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.376 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.401 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.426 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.449 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.476 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.500 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.553 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.600 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.625 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.649 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.674 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.698 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.722 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.752 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.817 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.842 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.869 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.893 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.916 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.942 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.966 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:40.989 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.013 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.063 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.089 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.114 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.147 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.165 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.186 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.243 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.286 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.311 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.346 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.396 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.420 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.444 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.466 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.491 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.533 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.561 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.571 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.871 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.896 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.922 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.947 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.971 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:41.997 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.022 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.046 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.073 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.096 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.120 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.150 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.173 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.198 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.225 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.252 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.285 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.301 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.325 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.377 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.400 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.425 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.450 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.475 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.504 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.529 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.555 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.584 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.611 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.633 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.659 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.686 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.712 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.737 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.813 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.838 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.864 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.891 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.917 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.941 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.967 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:42.992 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.019 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.048 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.069 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.094 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.171 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.247 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.280 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.296 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.325 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.347 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.373 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.399 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.425 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.477 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.502 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.536 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.555 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.575 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.599 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.630 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.672 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.721 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.745 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.769 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.801 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.880 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.905 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.930 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:43.954 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:44.018 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:44.060 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:44.084 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:44.109 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:44.132 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:44.156 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:28:44.280 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1564 completion_tokens=394 total_tokens=1958
2024-07-08 16:28:44.281 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
ãŠå®¢æ§˜ã€ã“ã‚“ã«ã¡ã¯ï¼ã©ã†ã„ãŸã—ã¾ã—ã¦ã€ä½•ã‹ãŠå›°ã‚Šã§ã—ã‚‡ã†ã‹ï¼Ÿ LangChainã«é–¢ã™ã‚‹è³ªå•ã‚„ã€ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦ã®è³ªå•ãªã©ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚ç§ã¯ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã‚‹é™ã‚Šã€æœ€å¤§ã®åŠªåŠ›ã‚’ã—ã¾ã™ã€‚

LangChainã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®è‡ªç„¶è¨€èªžå‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡žã€åå‰ã®å®Ÿä½“èªè­˜ã€æ„Ÿæƒ…åˆ†æžãªã©ã€ã•ã¾ã–ã¾ãªè‡ªç„¶è¨€èªžã®ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚Pythonè¨€èªžãƒ™ãƒ¼ã‚¹ã§ã€ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ä½¿ç”¨ã§ãã¾ã™ã€‚è©³ç´°ã¯å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ[LangChainå…¬å¼](https://www.langchain.org/)ã‚’ã”è¦§ãã ã•ã„ã€‚

ç‰¹å®šã®æ©Ÿèƒ½ã‚„å¿œç”¨ã«ã¤ã„ã¦ã®è³ªå•ãŒã‚ã‚Œã°ã€ã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‚ˆã†ã«ãŠé¡˜ã„ã—ã¾ã™ã€‚

è³ªå•ãŒLangChainã«é–¢é€£ã—ã¦ã„ãªã„å ´åˆã¯ã€ãã®ã“ã¨ã‚’ä¼ãˆã•ã›ã¦ã„ãŸã ãã€ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ããªã„ã¨è¨€ã„ã¾ã™ã€‚ãã®å ´åˆã€é©åˆ‡ãªæƒ…å ±æºã‚„å°‚é–€å®¶ã«å°‹ã­ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

ä»¥ä¸Šã€LangChainã«é–¢ã™ã‚‹åŸºæœ¬æƒ…å ±ã§ã™ã€‚ä»–ã®è³ªå•ãŒã‚ã‚Œã°ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚
the total timecost is 16.69029402732849

172.20.146.181 - - [08/Jul/2024 16:28:46] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:28:46.713 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-08 16:29:02.979 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Messages from Human:
- **Human:** ï¼Ÿ
- **Human:** ï¼Ÿ

Messages from Assistant:
- **Assistant:** ãŠå®¢æ§˜ã€ã“ã‚“ã«ã¡ã¯ï¼ã©ã†ã„ãŸã—ã¾ã—ã¦ã€ä½•ã‹ãŠå›°ã‚Šã§ã—ã‚‡ã†ã‹ï¼Ÿ LangChainã«é–¢ã™ã‚‹è³ªå•ã‚„ã€ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦ã®è³ªå•ãªã©ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚ç§ã¯ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã‚‹é™ã‚Šã€æœ€å¤§ã®åŠªåŠ›ã‚’ã—ã¾ã™ã€‚
- **Assistant:** LangChainã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®è‡ªç„¶è¨€èªžå‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡žã€åå‰ã®å®Ÿä½“èªè­˜ã€æ„Ÿæƒ…åˆ†æžãªã©ã€ã•ã¾ã–ã¾ãªè‡ªç„¶è¨€èªžã®ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚Pythonè¨€èªžãƒ™ãƒ¼ã‚¹ã§ã€ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ä½¿ç”¨ã§ãã¾ã™ã€‚è©³ç´°ã¯å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ[LangChainå…¬å¼](https://www.langchain.org/)ã‚’ã”è¦§ãã ã•ã„ã€‚
- **Assistant:** ç‰¹å®šã®æ©Ÿèƒ½ã‚„å¿œç”¨ã«ã¤ã„ã¦ã®è³ªå•ãŒã‚ã‚Œã°ã€ã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‚ˆã†ã«ãŠé¡˜ã„ã—ã¾ã™ã€‚
- **Assistant:** è³ªå•ãŒLangChainã«é–¢é€£ã—ã¦ã„ãªã„å ´åˆã¯ã€ãã®ã“ã¨ã‚’ä¼ãˆã•ã›ã¦ã„ãŸã ãã€ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ããªã„ã¨è¨€ã„ã¾ã™ã€‚ãã®å ´åˆã€é©åˆ‡ãªæƒ…å ±æºã‚„å°‚é–€å®¶ã«å°‹ã­ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚
- **Assistant:** ä»¥ä¸Šã€LangChainã«é–¢ã™ã‚‹åŸºæœ¬æƒ…å ±ã§ã™ã€‚ä»–ã®è³ªå•ãŒã‚ã‚Œã°ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚
- **Assistant:** æƒ…å ±æº:
  - [LangChainå…¬å¼](https://www.langchain.org/)

Refined Standalone Question: ãŠå®¢æ§˜ãŒæœ€åˆã«é€ä¿¡ã—ãŸã€Œï¼Ÿã€ã¨ã„ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åŸºã¥ã„ã¦ã€ã©ã®ã‚ˆã†ãªè³ªå•ãŒã‚ã‚Šã¾ã—ãŸã‹ï¼ŸLangChainã«é–¢ã™ã‚‹è³ªå•ã‚„ã€ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦ã®è³ªå•ãªã©ã€ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚'. The timecost is 16.264931678771973
2024-07-08 16:29:02.980 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=1133 completion_tokens=562 total_tokens=1695
2024-07-08 16:29:03.293 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.31269049644470215
2024-07-08 16:29:03.336 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Messages from Human:
- **Human:** ï¼Ÿ
- **Human:** ï¼Ÿ

Messages from Assistant:
- **Assistant:** ãŠå®¢æ§˜ã€ã“ã‚“ã«ã¡ã¯ï¼ã©ã†ã„ãŸã—ã¾ã—ã¦ã€ä½•ã‹ãŠå›°ã‚Šã§ã—ã‚‡ã†ã‹ï¼Ÿ LangChainã«é–¢ã™ã‚‹è³ªå•ã‚„ã€ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦ã®è³ªå•ãªã©ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚ç§ã¯ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã‚‹é™ã‚Šã€æœ€å¤§ã®åŠªåŠ›ã‚’ã—ã¾ã™ã€‚
- **Assistant:** LangChainã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®è‡ªç„¶è¨€èªžå‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡žã€åå‰ã®å®Ÿä½“èªè­˜ã€æ„Ÿæƒ…åˆ†æžãªã©ã€ã•ã¾ã–ã¾ãªè‡ªç„¶è¨€èªžã®ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚Pythonè¨€èªžãƒ™ãƒ¼ã‚¹ã§ã€ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ä½¿ç”¨ã§ãã¾ã™ã€‚è©³ç´°ã¯å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ[LangChainå…¬å¼](https://www.langchain.org/)ã‚’ã”è¦§ãã ã•ã„ã€‚
- **Assistant:** ç‰¹å®šã®æ©Ÿèƒ½ã‚„å¿œç”¨ã«ã¤ã„ã¦ã®è³ªå•ãŒã‚ã‚Œã°ã€ã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‚ˆã†ã«ãŠé¡˜ã„ã—ã¾ã™ã€‚
- **Assistant:** è³ªå•ãŒLangChainã«é–¢é€£ã—ã¦ã„ãªã„å ´åˆã¯ã€ãã®ã“ã¨ã‚’ä¼ãˆã•ã›ã¦ã„ãŸã ãã€ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ããªã„ã¨è¨€ã„ã¾ã™ã€‚ãã®å ´åˆã€é©åˆ‡ãªæƒ…å ±æºã‚„å°‚é–€å®¶ã«å°‹ã­ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚
- **Assistant:** ä»¥ä¸Šã€LangChainã«é–¢ã™ã‚‹åŸºæœ¬æƒ…å ±ã§ã™ã€‚ä»–ã®è³ªå•ãŒã‚ã‚Œã°ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚
- **Assistant:** æƒ…å ±æº:
  - [LangChainå…¬å¼](https://www.langchain.org/)

Refined Standalone Question: ãŠå®¢æ§˜ãŒæœ€åˆã«é€ä¿¡ã—ãŸã€Œï¼Ÿã€ã¨ã„ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åŸºã¥ã„ã¦ã€ã©ã®ã‚ˆã†ãªè³ªå•ãŒã‚ã‚Šã¾ã—ãŸã‹ï¼ŸLangChainã«é–¢ã™ã‚‹è³ªå•ã‚„ã€ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦ã®è³ªå•ãªã©ã€ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚', k: 10, the timecost is 0.35330891609191895
172.20.146.181 - - [08/Jul/2024 16:29:04] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:29:04.625 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:04.648 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
172.20.146.181 - - [08/Jul/2024 16:29:19] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:29:19.141 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-08 16:29:36.621 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'Messages from Human:
- **Human:** ï¼Ÿ
- **Human:** ï¼Ÿ

Messages from Assistant:
- **Assistant:** ãŠå®¢æ§˜ã€ã“ã‚“ã«ã¡ã¯ï¼ã©ã†ã„ãŸã—ã¾ã—ã¦ã€ä½•ã‹ãŠå›°ã‚Šã§ã—ã‚‡ã†ã‹ï¼Ÿ LangChainã«é–¢ã™ã‚‹è³ªå•ã‚„ã€ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦ã®è³ªå•ãªã©ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚ç§ã¯ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã‚‹é™ã‚Šã€æœ€å¤§ã®åŠªåŠ›ã‚’ã—ã¾ã™ã€‚
- **Assistant:** LangChainã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®è‡ªç„¶è¨€èªžå‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡žã€åå‰ã®å®Ÿä½“èªè­˜ã€æ„Ÿæƒ…åˆ†æžãªã©ã€ã•ã¾ã–ã¾ãªè‡ªç„¶è¨€èªžã®ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚Pythonè¨€èªžãƒ™ãƒ¼ã‚¹ã§ã€ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ä½¿ç”¨ã§ãã¾ã™ã€‚è©³ç´°ã¯å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ[LangChainå…¬å¼](https://www.langchain.org/)ã‚’ã”è¦§ãã ã•ã„ã€‚
- **Assistant:** ç‰¹å®šã®æ©Ÿèƒ½ã‚„å¿œç”¨ã«ã¤ã„ã¦ã®è³ªå•ãŒã‚ã‚Œã°ã€ã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‚ˆã†ã«ãŠé¡˜ã„ã—ã¾ã™ã€‚
- **Assistant:** è³ªå•ãŒLangChainã«é–¢é€£ã—ã¦ã„ãªã„å ´åˆã¯ã€ãã®ã“ã¨ã‚’ä¼ãˆã•ã›ã¦ã„ãŸã ãã€ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ããªã„ã¨è¨€ã„ã¾ã™ã€‚ãã®å ´åˆã€é©åˆ‡ãªæƒ…å ±æºã‚„å°‚é–€å®¶ã«å°‹ã­ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚
- **Assistant:** ä»¥ä¸Šã€LangChainã«é–¢ã™ã‚‹åŸºæœ¬æƒ…å ±ã§ã™ã€‚ä»–ã®è³ªå•ãŒã‚ã‚Œã°ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚
- **Assistant:** æƒ…å ±æº:
  - [LangChainå…¬å¼](https://www.langchain.org/)

Refined Standalone Question: ãŠå®¢æ§˜ãŒæœ€åˆã«é€ä¿¡ã—ãŸã€Œï¼Ÿã€ã¨ã„ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åŸºã¥ã„ã¦ã€LangChainã«é–¢ã™ã‚‹ã©ã®ã‚ˆã†ãªè³ªå•ãŒã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿå…·ä½“çš„ãªè³ªå•å†…å®¹ã‚’æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ'. The timecost is 17.479336500167847
2024-07-08 16:29:36.622 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=1133 completion_tokens=552 total_tokens=1685
2024-07-08 16:29:38.113 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 1.4906928539276123
2024-07-08 16:29:38.171 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Messages from Human:
- **Human:** ï¼Ÿ
- **Human:** ï¼Ÿ

Messages from Assistant:
- **Assistant:** ãŠå®¢æ§˜ã€ã“ã‚“ã«ã¡ã¯ï¼ã©ã†ã„ãŸã—ã¾ã—ã¦ã€ä½•ã‹ãŠå›°ã‚Šã§ã—ã‚‡ã†ã‹ï¼Ÿ LangChainã«é–¢ã™ã‚‹è³ªå•ã‚„ã€ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦ã®è³ªå•ãªã©ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚ç§ã¯ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã‚‹é™ã‚Šã€æœ€å¤§ã®åŠªåŠ›ã‚’ã—ã¾ã™ã€‚
- **Assistant:** LangChainã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®è‡ªç„¶è¨€èªžå‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡žã€åå‰ã®å®Ÿä½“èªè­˜ã€æ„Ÿæƒ…åˆ†æžãªã©ã€ã•ã¾ã–ã¾ãªè‡ªç„¶è¨€èªžã®ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚Pythonè¨€èªžãƒ™ãƒ¼ã‚¹ã§ã€ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ä½¿ç”¨ã§ãã¾ã™ã€‚è©³ç´°ã¯å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ[LangChainå…¬å¼](https://www.langchain.org/)ã‚’ã”è¦§ãã ã•ã„ã€‚
- **Assistant:** ç‰¹å®šã®æ©Ÿèƒ½ã‚„å¿œç”¨ã«ã¤ã„ã¦ã®è³ªå•ãŒã‚ã‚Œã°ã€ã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‚ˆã†ã«ãŠé¡˜ã„ã—ã¾ã™ã€‚
- **Assistant:** è³ªå•ãŒLangChainã«é–¢é€£ã—ã¦ã„ãªã„å ´åˆã¯ã€ãã®ã“ã¨ã‚’ä¼ãˆã•ã›ã¦ã„ãŸã ãã€ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ããªã„ã¨è¨€ã„ã¾ã™ã€‚ãã®å ´åˆã€é©åˆ‡ãªæƒ…å ±æºã‚„å°‚é–€å®¶ã«å°‹ã­ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚
- **Assistant:** ä»¥ä¸Šã€LangChainã«é–¢ã™ã‚‹åŸºæœ¬æƒ…å ±ã§ã™ã€‚ä»–ã®è³ªå•ãŒã‚ã‚Œã°ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚
- **Assistant:** æƒ…å ±æº:
  - [LangChainå…¬å¼](https://www.langchain.org/)

Refined Standalone Question: ãŠå®¢æ§˜ãŒæœ€åˆã«é€ä¿¡ã—ãŸã€Œï¼Ÿã€ã¨ã„ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åŸºã¥ã„ã¦ã€LangChainã«é–¢ã™ã‚‹ã©ã®ã‚ˆã†ãªè³ªå•ãŒã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿå…·ä½“çš„ãªè³ªå•å†…å®¹ã‚’æ•™ãˆã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿ', k: 10, the timecost is 1.5463428497314453
172.20.146.181 - - [08/Jul/2024 16:29:39] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:29:39.403 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.445 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.469 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.493 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.522 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.548 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.569 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.593 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.617 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.640 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.669 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.719 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.743 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.768 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.792 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.818 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.866 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.889 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.913 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.937 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.961 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:39.985 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.010 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.033 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.058 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.083 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.106 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.134 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.160 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.182 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.231 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.254 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.282 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.304 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.330 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.352 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.376 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.401 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.426 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.450 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.473 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.498 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.523 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.552 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.580 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.607 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.627 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.695 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.718 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:40.742 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.693 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.717 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.743 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.820 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.848 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.868 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.893 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.917 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.944 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.974 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:41.999 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.023 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.047 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.073 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.110 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.121 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.148 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.199 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.223 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.248 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.273 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.535 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.536 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.536 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.537 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.537 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.539 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.539 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.919 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.920 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.948 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.950 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.950 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.951 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.951 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.952 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.952 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.954 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.954 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.978 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:42.993 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.018 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.070 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.095 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.145 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.167 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.193 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.215 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.277 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.299 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.323 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.359 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.394 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.422 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.446 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.465 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.492 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.521 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:43.539 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.174 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.175 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.177 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.177 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.203 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.204 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.205 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.205 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.206 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.206 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.208 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.208 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.232 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.242 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.266 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.293 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.314 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.342 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.417 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.439 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.512 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.547 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.573 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.620 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.644 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.672 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.719 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.741 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.766 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.792 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.820 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.850 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.887 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.910 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.964 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:44.982 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.005 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.034 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.053 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.077 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.104 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.129 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.226 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.250 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.299 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.327 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.427 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.481 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.502 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.526 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.550 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.574 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.623 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.649 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.676 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.700 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.725 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.749 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.773 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.801 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.822 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.849 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.872 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.898 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:45.948 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.020 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.047 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.069 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.097 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.122 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.144 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.169 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.195 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.218 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.245 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.268 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.303 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.318 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.347 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.366 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.393 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.417 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.465 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.490 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.516 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.540 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.567 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.593 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.616 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.640 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.666 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.689 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.731 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.739 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.764 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.789 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.814 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.839 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.863 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.889 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.914 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.940 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.965 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:46.992 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.017 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.041 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.066 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.092 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.164 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.205 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.214 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.239 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.474 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.499 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.525 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.549 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.575 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.601 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.626 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.653 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.677 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.702 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.728 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.759 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.784 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.809 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.836 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.861 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.892 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.915 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.941 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.965 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:47.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.017 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.041 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.069 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.102 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.120 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.143 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.169 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.219 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.220 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.323 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.324 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.324 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.326 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.346 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.374 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.397 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.426 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.482 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.499 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.527 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.552 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.576 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.611 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.627 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.659 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.678 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.710 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.738 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.759 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.784 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.809 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.839 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.859 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.885 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.914 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.934 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.961 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:48.990 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.012 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.036 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.063 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.087 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.111 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.134 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.157 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.183 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.233 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.257 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.279 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.304 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.327 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.352 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.406 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.517 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.565 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.589 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.614 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.635 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.658 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.683 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.707 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.730 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.778 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.801 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.883 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.904 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.932 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.958 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.976 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:49.998 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.023 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.045 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.069 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.092 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.118 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.141 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.213 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.290 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.315 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.338 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.361 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.386 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.411 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.436 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.465 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.482 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.576 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.596 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.623 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.701 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.717 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.747 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.763 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.787 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.810 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.835 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.881 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.905 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:50.931 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:51.318 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:51.318 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:51.324 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:51.375 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:51.395 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:29:51.512 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=prompt_tokens=1877 completion_tokens=418 total_tokens=2295
2024-07-08 16:29:51.513 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ï¼Ÿ' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
ãŠå®¢æ§˜ã€ã“ã‚“ã«ã¡ã¯ï¼ã©ã†ã„ãŸã—ã¾ã—ã¦ã€ä½•ã‹ãŠå›°ã‚Šã§ã—ã‚‡ã†ã‹ï¼ŸLangChainã«é–¢ã™ã‚‹è³ªå•ã‚„ã€ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦ã®è³ªå•ãªã©ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚ç§ã¯ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã‚‹é™ã‚Šã€æœ€å¤§ã®åŠªåŠ›ã‚’ã—ã¾ã™ã€‚

LangChainã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®è‡ªç„¶è¨€èªžå‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡žã€åå‰ã®å®Ÿä½“èªè­˜ã€æ„Ÿæƒ…åˆ†æžãªã©ã€ã•ã¾ã–ã¾ãªè‡ªç„¶è¨€èªžã®ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚Pythonè¨€èªžãƒ™ãƒ¼ã‚¹ã§ã€ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ä½¿ç”¨ã§ãã¾ã™ã€‚è©³ç´°ã¯å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ[LangChainå…¬å¼](https://www.langchain.org/)ã‚’ã”è¦§ãã ã•ã„ã€‚

ç‰¹å®šã®æ©Ÿèƒ½ã‚„å¿œç”¨ã«ã¤ã„ã¦ã®è³ªå•ãŒã‚ã‚Œã°ã€ã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‚ˆã†ã«ãŠé¡˜ã„ã—ã¾ã™ã€‚

è³ªå•ãŒLangChainã«é–¢é€£ã—ã¦ã„ãªã„å ´åˆã¯ã€ãã®ã“ã¨ã‚’ä¼ãˆã•ã›ã¦ã„ãŸã ãã€ãã‚Œã«ç­”ãˆã‚‹ã“ã¨ãŒã§ããªã„ã¨è¨€ã„ã¾ã™ã€‚ãã®å ´åˆã€é©åˆ‡ãªæƒ…å ±æºã‚„å°‚é–€å®¶ã«å°‹ã­ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

ä»¥ä¸Šã€LangChainã«é–¢ã™ã‚‹åŸºæœ¬æƒ…å ±ã§ã™ã€‚ä»–ã®è³ªå•ãŒã‚ã‚Œã°ã€ã©ã†ãžãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚

æƒ…å ±æº:
- [LangChainå…¬å¼](https://www.langchain.org/)
the total timecost is 32.373093605041504

172.20.146.181 - - [08/Jul/2024 16:30:01] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:30:01.601 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ï¼Ÿ', detect the language is 'Japanese'!
2024-07-08 16:30:05.525 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ï¼Ÿ', the refined query is 'LangChainã«ã¤ã„ã¦ã€å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‚’å‚ç…§ã—ã¦ã„ã¾ã—ãŸãŒã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿç‰¹ã«ã€Pythonè¨€èªžãƒ™ãƒ¼ã‚¹ã®LangChainã®ç°¡å˜ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•ã‚„ã€è‡ªç„¶è¨€èªžå‡¦ç†ã®æ©Ÿèƒ½ã«ã¤ã„ã¦ã®è©³ç´°ãªæƒ…å ±ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚'. The timecost is 3.923297643661499
2024-07-08 16:30:05.526 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ï¼Ÿ', usage=prompt_tokens=1100 completion_tokens=97 total_tokens=1197
2024-07-08 16:30:05.787 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'LangChainã«ã¤ã„ã¦ã€å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‚’å‚ç…§ã—ã¦ã„ã¾ã—ãŸãŒã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’æä¾›ã—ã¦ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿç‰¹ã«ã€Pythonè¨€èªžãƒ™ãƒ¼ã‚¹ã®LangChainã®ç°¡å˜ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•ã‚„ã€è‡ªç„¶è¨€èªžå‡¦ç†ã®æ©Ÿèƒ½ã«ã¤ã„ã¦ã®è©³ç´°ãªæƒ…å ±ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚', k: 10, the timecost is 0.25786876678466797
2024-07-08 16:30:05.801 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ï¼Ÿ', k: 10, the timecost is 0.2739379405975342
172.20.146.181 - - [08/Jul/2024 16:30:07] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:30:07.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
2024-07-08 16:30:07.216 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ï¼Ÿ', usage=None
172.20.146.181 - - [08/Jul/2024 16:47:46] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:47:46.273 | WARNING  | server.app.queries:generate_answer:210 - For query: 'æ‚¨å¥½', detect the language is 'Chinese'!
2024-07-08 16:47:48.154 | WARNING  | server.app.queries:refine_query:105 - For the query: 'æ‚¨å¥½', the refined query is 'æ‚¨å¥½ï¼è¯·é—®æ‚¨ä¹‹å‰æåˆ°çš„LangChainæ˜¯ä»€ä¹ˆï¼Œå®ƒèƒ½ç”¨äºŽå“ªäº›è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Ÿ'. The timecost is 1.8803341388702393
2024-07-08 16:47:48.155 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'æ‚¨å¥½', usage=prompt_tokens=1100 completion_tokens=22 total_tokens=1122
2024-07-08 16:47:48.435 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'æ‚¨å¥½', k: 10, the timecost is 0.27903056144714355
2024-07-08 16:47:48.475 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'æ‚¨å¥½ï¼è¯·é—®æ‚¨ä¹‹å‰æåˆ°çš„LangChainæ˜¯ä»€ä¹ˆï¼Œå®ƒèƒ½ç”¨äºŽå“ªäº›è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Ÿ', k: 10, the timecost is 0.31711292266845703
172.20.146.181 - - [08/Jul/2024 16:47:49] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:47:49.799 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:49.818 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:49.847 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:49.870 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:49.902 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:49.920 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:49.945 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:49.997 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.050 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.075 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.101 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.125 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.225 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.250 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.276 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.300 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.329 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.355 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.381 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.408 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.430 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.458 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.480 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.505 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.563 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.582 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.608 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.632 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.662 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.687 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.710 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.735 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.760 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.785 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:50.832 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.430 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.450 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.475 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.501 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.533 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.552 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.575 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.600 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.628 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.649 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.674 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.701 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.781 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.804 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.831 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.852 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.882 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.900 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.923 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.948 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.972 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:51.996 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.248 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.270 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.295 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.320 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.345 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.370 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.394 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.418 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.444 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.469 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.495 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.520 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.545 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.574 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.625 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.685 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.700 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.724 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.777 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.802 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.828 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.852 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.876 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.902 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.928 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.951 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:52.976 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.001 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.028 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.055 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.097 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.105 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.131 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.155 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.184 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.211 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.234 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.283 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.306 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.331 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.357 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.379 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.403 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.428 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.452 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.572 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.573 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.576 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.601 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.637 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.651 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.698 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.721 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.747 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.769 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.796 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.842 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.866 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.891 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.916 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.942 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.965 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:53.991 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.020 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.036 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.061 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.084 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.111 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.133 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.157 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.181 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.203 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.232 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.253 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.276 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.302 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.326 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.375 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.399 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.423 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.448 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.472 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.545 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.568 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.593 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.617 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.667 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.692 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.715 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.740 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.764 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.788 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.825 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.837 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.864 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.886 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.909 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.934 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.958 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:54.983 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.112 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.136 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.161 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.234 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.258 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.282 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.315 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.330 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.360 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.383 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.409 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.434 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.457 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.480 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.521 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.530 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.574 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.578 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.602 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=None
2024-07-08 16:47:55.713 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'æ‚¨å¥½', usage=prompt_tokens=1844 completion_tokens=202 total_tokens=2046
2024-07-08 16:47:55.714 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'æ‚¨å¥½' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
æ‚¨å¥½ï¼æˆ‘æ˜¯LangChainçš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿå¦‚æžœæ‚¨æœ‰ä»»ä½•å…³äºŽLangChainçš„é—®é¢˜ï¼Œæˆ–è€…éœ€è¦æˆ‘ä»¬çš„æœåŠ¡å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½æˆ‘æœ€å¤§çš„åŠªåŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚

LangChainæ˜¯ä¸€ä¸ªå¼€æºçš„è‡ªç„¶è¯­è¨€å¤„ç†æ¡†æž¶ï¼Œèƒ½å¤Ÿåº”å¯¹å„ç§è‡ªç„¶è¯­è¨€ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€å®žä½“è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æžç­‰ã€‚åŸºäºŽPythonè¯­è¨€ï¼Œæ˜“äºŽå®‰è£…å’Œä½¿ç”¨ã€‚æ›´å¤šä¿¡æ¯è¯·æŸ¥çœ‹æˆ‘ä»¬çš„å®˜æ–¹ç½‘ç«™[LangChainå®˜æ–¹](https://www.langchain.org/)ã€‚

å¦‚æžœæ‚¨æœ‰å…³äºŽç‰¹å®šåŠŸèƒ½æˆ–åº”ç”¨çš„é—®é¢˜ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›æ›´å…·ä½“çš„ä¿¡æ¯ã€‚å¦‚æžœæ‚¨çš„é—®é¢˜ä¸ŽLangChainæ— å…³ï¼Œæˆ‘ä¼šå‘ŠçŸ¥æ‚¨è¿™ä¸€ç‚¹ï¼Œå¹¶å»ºè®®æ‚¨å‘é€‚å½“çš„èµ„æ–™æ¥æºæˆ–ä¸“å®¶å’¨è¯¢ã€‚

ä»¥ä¸Šæ˜¯å…³äºŽLangChainçš„åŸºæœ¬ä¿¡æ¯ã€‚å¦‚æžœæ‚¨æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚

èµ„æ–™æ¥æºï¼š
- [LangChainå®˜æ–¹](https://www.langchain.org/)
the total timecost is 9.441723585128784

Traceback (most recent call last):
  File "rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
172.20.146.181 - - [08/Jul/2024 17:27:21] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 17:27:21.236 | WARNING  | server.app.queries:generate_answer:210 - For query: 'ä½ å¥½', detect the language is 'Chinese'!
2024-07-08 17:27:22.775 | WARNING  | server.app.queries:refine_query:105 - For the query: 'ä½ å¥½', the refined query is 'ä½ å¥½ï¼Œè¯·é—®æ‚¨ä¹‹å‰å’ŒåŠ©æ‰‹äº¤æµäº†ä»€ä¹ˆå†…å®¹ï¼Ÿæ‚¨æƒ³ç»§ç»­è¯¢é—®å…³äºŽ `LangChain` çš„å“ªäº›å…·ä½“é—®é¢˜ï¼Ÿ'. The timecost is 1.5381453037261963
2024-07-08 17:27:22.776 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'ä½ å¥½', usage=prompt_tokens=323 completion_tokens=30 total_tokens=353
2024-07-08 17:27:23.699 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½', k: 10, the timecost is 0.9221596717834473
2024-07-08 17:27:23.715 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'ä½ å¥½ï¼Œè¯·é—®æ‚¨ä¹‹å‰å’ŒåŠ©æ‰‹äº¤æµäº†ä»€ä¹ˆå†…å®¹ï¼Ÿæ‚¨æƒ³ç»§ç»­è¯¢é—®å…³äºŽ `LangChain` çš„å“ªäº›å…·ä½“é—®é¢˜ï¼Ÿ', k: 10, the timecost is 0.9362144470214844
172.20.146.181 - - [08/Jul/2024 17:27:24] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 17:27:24.699 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.720 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.743 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.766 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.789 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.812 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.835 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.858 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.883 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.904 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.952 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:24.976 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.000 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.022 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.046 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.069 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.092 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.185 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.208 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.232 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.256 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.314 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.338 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.363 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.390 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.421 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.436 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.492 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.514 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.537 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.574 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.621 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.644 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.675 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.692 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.788 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.813 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.858 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:25.900 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=None
2024-07-08 17:27:26.000 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: 'ä½ å¥½', usage=prompt_tokens=1067 completion_tokens=43 total_tokens=1110
2024-07-08 17:27:26.001 | SUCCESS  | server.app.queries:generate_llm:451 - query: 'ä½ å¥½' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
ä½ å¥½ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿå¦‚æžœæ‚¨æœ‰ä»»ä½•å…³äºŽLangChainçš„é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å‡†ç¡®å’Œç›¸å…³çš„ç­”æ¡ˆã€‚
the total timecost is 4.765963554382324


2024-05-30 02:31:12.193 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:7000
 * Running on http://59.78.194.84:7000
[33mPress CTRL+C to quit[0m
172.20.157.51 - - [30/May/2024 02:31:18] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.157.51 - - [30/May/2024 02:31:18] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.157.51 - - [30/May/2024 02:31:18] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 02:31:19.269 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiMjAwMzQyZjAtMjUwZS00YzM4LTk3YjctMTlkZDU0N2M1N2ZkIiwiZXhwIjoxNzE3NjEyMjc5fQ.gnttgXz3pTd_auizPLb9aK4djhouRKXVvzrQDSDcZso' with user_id: '200342f0-250e-4c38-97b7-19dd547c57fd'
172.20.157.51 - - [30/May/2024 02:31:19] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.157.51 - - [30/May/2024 02:31:19] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
172.20.157.51 - - [30/May/2024 02:31:19] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-05-30 02:31:23.709 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 02:31:25.347 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'I apologize for the confusion, could you please provide more context or background information for the question you intend to ask?'. The timecost is 1.638237714767456
2024-05-30 02:31:25.347 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=322 completion_tokens=25 total_tokens=347
2024-05-30 02:31:25.605 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.25717854499816895
2024-05-30 02:31:25.606 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'I apologize for the confusion, could you please provide more context or background information for the question you intend to ask?', k: 10, the timecost is 0.25768566131591797
172.20.157.51 - - [30/May/2024 02:31:26] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 02:31:26.685 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.707 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.732 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.757 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.782 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.807 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.833 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.862 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.884 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.908 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.933 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.960 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:26.989 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.039 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.066 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.118 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.119 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.142 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.169 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.195 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.271 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.296 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.328 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.401 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.435 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.485 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.510 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.567 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.588 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.614 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.639 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.708 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.717 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.785 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.792 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.882 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.885 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.899 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.925 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.959 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:27.984 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:28.095 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1066 completion_tokens=53 total_tokens=1119
2024-05-30 02:31:28.096 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: '200342f0-250e-4c38-97b7-19dd547c57fd' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 4.440763235092163

2024-05-30 02:31:33.085 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 02:31:36.486 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a repetition of the initial message, indicating a potential misunderstanding or request for clarification about the nature of the assistance offered. The intent seems to be to confirm the scope of the services provided by `LangChain` and what kind of questions the human can ask.

Refined Standalone Question:
"What kind of questions can I ask you about `LangChain` and its services?"'. The timecost is 3.399876594543457
2024-05-30 02:31:36.487 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=387 completion_tokens=103 total_tokens=490
2024-05-30 02:31:36.910 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a repetition of the initial message, indicating a potential misunderstanding or request for clarification about the nature of the assistance offered. The intent seems to be to confirm the scope of the services provided by `LangChain` and what kind of questions the human can ask.

Refined Standalone Question:
"What kind of questions can I ask you about `LangChain` and its services?"', k: 10, the timecost is 0.41962337493896484
2024-05-30 02:31:36.911 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.4229614734649658
172.20.157.51 - - [30/May/2024 02:31:37] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 02:31:37.895 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:37.919 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:37.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:37.970 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:37.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.021 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.047 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.098 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.123 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.149 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.176 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.203 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.228 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.254 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.279 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.330 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.355 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.380 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.431 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.482 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.533 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.558 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.583 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.611 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.637 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.695 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.719 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.744 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.770 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.796 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.847 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.874 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.899 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.951 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:38.976 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.011 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.028 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.106 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.185 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 02:31:39.328 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1131 completion_tokens=53 total_tokens=1184
2024-05-30 02:31:39.328 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: '200342f0-250e-4c38-97b7-19dd547c57fd' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 6.243935823440552

58.198.176.161 - - [30/May/2024 11:05:01] "GET /open-kf-chatbot/ HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:01] "GET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:01] "GET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1" 200 -
2024-05-30 11:05:05.769 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiOTJmNTBmZWMtMTlhOS00NTYwLTkwYjItYjdmYTkwMGI4ZTgyIiwiZXhwIjoxNzE3NjQzMTA1fQ.5lYah89oAHLf0KlvQYM5I3Y4J2TaGzLRCsxOFQl66pQ' with user_id: '92f50fec-19a9-4560-90b2-b7fa900b8e82'
58.198.176.161 - - [30/May/2024 11:05:05] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:07] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:07] "GET /open-kf-chatbot/vite.svg HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:16] "GET /open-kf-chatbot/ HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:16] "GET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:16] "GET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1" 200 -
2024-05-30 11:05:17.609 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiODdjNjAwZjEtNWFlZC00ODI4LTk0ZmQtMzRkNDkxZTRkYzIwIiwiZXhwIjoxNzE3NjQzMTE3fQ.ubTKToD67MRYcWb5AI_Zw9tih3qqk_lLqK9__4QMxVc' with user_id: '87c600f1-5aed-4828-94fd-34d491e4dc20'
58.198.176.161 - - [30/May/2024 11:05:17] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:17] "GET /open-kf-chatbot/vite.svg HTTP/1.1" 200 -
58.198.176.161 - - [30/May/2024 11:05:17] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-05-30 11:05:25.041 | WARNING  | server.app.queries:generate_answer:210 - For query: 'hi', detect the language is 'English'!
58.198.176.161 - - [30/May/2024 11:05:33] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 438, in generate_llm
    response = generate_answer(query, user_id, True)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
2024-05-30 12:46:35.627 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:7001
 * Running on http://59.78.194.84:7001
[33mPress CTRL+C to quit[0m
172.20.156.165 - - [30/May/2024 12:46:41] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:46:41] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:46:41] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 12:46:42.398 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzE3NjQ5MjAyfQ.D6Tjr_Ceo0FqchF-iCNUuTIpeEb6X-UI3Amtz9nc-So' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.156.165 - - [30/May/2024 12:46:42] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:46:42] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:46:43] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-05-30 12:46:47.796 | WARNING  | server.app.queries:generate_answer:210 - For query: '你好。请问什么是javahhh', detect the language is 'Chinese'!
2024-05-30 12:46:48.933 | WARNING  | server.app.queries:refine_query:105 - For the query: '你好。请问什么是javahhh', the refined query is '你好，请问javahhh是什么？'. The timecost is 1.1368727684020996
2024-05-30 12:46:48.934 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '你好。请问什么是javahhh', usage=prompt_tokens=606 completion_tokens=10 total_tokens=616
2024-05-30 12:46:49.171 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好。请问什么是javahhh', k: 10, the timecost is 0.23624610900878906
2024-05-30 12:46:49.210 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好，请问javahhh是什么？', k: 10, the timecost is 0.2734673023223877
172.20.156.165 - - [30/May/2024 12:46:50] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:46:50.577 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.634 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.686 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.738 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.760 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.810 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.899 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.963 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:50.990 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.038 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.064 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.089 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.118 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.215 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.265 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.290 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.316 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.368 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.395 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.419 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.444 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.470 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.494 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.519 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.548 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.622 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.661 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.690 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.737 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.761 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.868 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.898 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.917 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.942 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.973 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:51.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.021 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.047 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.075 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.098 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.126 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.148 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.174 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.307 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.332 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.367 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.391 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.418 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.441 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.492 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.542 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.570 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.594 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.619 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.647 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.669 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.695 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.722 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.747 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.772 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.796 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.822 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.846 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.872 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.897 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.923 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.947 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:52.975 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.000 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.025 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.052 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.080 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.108 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.133 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.169 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.244 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.269 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.297 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.327 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.354 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.373 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.445 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.474 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.497 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.548 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.605 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.630 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.680 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.710 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.737 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.754 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.808 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.833 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:46:53.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=prompt_tokens=1364 completion_tokens=127 total_tokens=1491
2024-05-30 12:46:53.965 | SUCCESS  | server.app.queries:generate_llm:452 - query: '你好。请问什么是javahhh' and user_id: '0accf4d8-ca47-4041-bc6a-94d448b39be5' is processed successfully, the answer is:
您好！看来您问的是关于“javahhh”的问题。不过，我需要澄清一下，根据我目前的配置和所提供的信息，我主要能协助您了解和解决与`LangChain`相关的问题。关于“javahhh”，我没有直接相关的信息或服务。

如果您有关于`LangChain`的问题，我会很乐意帮助您解答。如果有需要了解“javahhh”的进一步信息，我建议您可以查阅一些在线编程教程或者参考专业的编程书籍。

希望我的回答对您有所帮助！如果有其他问题，欢迎继续提问。
the total timecost is 6.222750425338745

172.20.156.165 - - [30/May/2024 12:47:42] "[36mGET /open-kf-admin/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:43] "[36mGET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:43] "[36mGET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:44] "[36mGET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:44] "[36mGET /open-kf-admin/assets/Setting-uk7UYz_k.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:44] "[36mGET /open-kf-admin/vite.svg HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:47:44] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:51] "GET /open-kf-admin/assets/Website-Z1INMbWO.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:51] "GET /open-kf-admin/assets/common-nfwq9z7Z.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:51] "GET /open-kf-admin/assets/loading-vsHIitu7.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:51] "GET /open-kf-admin/assets/LinkTable-Ia3zEXas.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:51] "GET /open-kf-admin/assets/Source-5g35C8sb.js HTTP/1.1" 200 -
2024-05-30 12:47:52.269 | INFO     | server.app.sitemaps:get_crawl_url_list:156 - Fetching URL list for all domains.
172.20.156.165 - - [30/May/2024 12:47:52] "POST /open_kf_api/sitemaps/get_crawl_url_list HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:54] "GET /open-kf-admin/assets/Embed-zUv8vG44.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:56] "GET /open-kf-admin/assets/Dashboard-BieUHPHe.css HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:56] "GET /open-kf-admin/assets/Dashboard-WB1KXATu.js HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:58] "POST /open_kf_api/queries/get_user_conversation_list HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:47:59] "POST /open_kf_api/queries/get_user_query_history_list HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:49:23] "[36mGET /open-kf-admin/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:24] "[36mGET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:24] "[36mGET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:25] "[36mGET /open-kf-admin/assets/Dashboard-BieUHPHe.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:25] "[36mGET /open-kf-admin/assets/Dashboard-WB1KXATu.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:27] "[36mGET /open-kf-admin/assets/loading-vsHIitu7.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:27] "[36mGET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:27] "[36mGET /open-kf-admin/vite.svg HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:27] "POST /open_kf_api/queries/get_user_conversation_list HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:49:27] "POST /open_kf_api/queries/get_user_query_history_list HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:49:29] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:29] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:29] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 12:49:30.167 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzE3NjQ5MzcwfQ.hjy2Q4XDnDofJ6vedcf5CwcC-6Tk_hyoonOBZFKeMp4' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.156.165 - - [30/May/2024 12:49:30] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:49:30] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:49:31] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
127.0.0.1 - - [30/May/2024 12:50:12] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
127.0.0.1 - - [30/May/2024 12:50:12] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
127.0.0.1 - - [30/May/2024 12:50:12] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 12:50:13.594 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWVlODA2ZWYtMTZiYS00Y2NjLWIzYTktYmU0Y2JkYTcwMGM3IiwiZXhwIjoxNzE3NjQ5NDEzfQ.S8oZ2RJG0H0g6o9TDOvmkSym5FUoHH2PUg-7lTidO1Q' with user_id: 'aee806ef-16ba-4ccc-b3a9-be4cbda700c7'
127.0.0.1 - - [30/May/2024 12:50:13] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
127.0.0.1 - - [30/May/2024 12:50:13] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:50:22] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:50:23] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:50:23] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 12:50:23.729 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzE3NjQ5NDIzfQ.liZ3o0qLRmLEyj5uWCFHXcC1mrUlefwv4jm3pB3EIjg' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.156.165 - - [30/May/2024 12:50:23] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:50:23] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-05-30 12:50:28.392 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 12:50:32.675 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the context of the conversation, the follow-up message "?" appears to be an inquiry seeking clarification or further information. To create a standalone question that captures the relevant context from the conversation, we can infer that the human is interested in a specific aspect of `LangChain`'s services. However, without the content of the Assistant's responses, we cannot determine the exact nature of the follow-up question.

Therefore, the reframed standalone question based on the follow-up message would be:

"What additional information or assistance do you require from `LangChain` services, based on our previous introduction?"'. The timecost is 4.282324552536011
2024-05-30 12:50:32.676 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=320 completion_tokens=141 total_tokens=461
2024-05-30 12:50:32.982 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the context of the conversation, the follow-up message "?" appears to be an inquiry seeking clarification or further information. To create a standalone question that captures the relevant context from the conversation, we can infer that the human is interested in a specific aspect of `LangChain`'s services. However, without the content of the Assistant's responses, we cannot determine the exact nature of the follow-up question.

Therefore, the reframed standalone question based on the follow-up message would be:

"What additional information or assistance do you require from `LangChain` services, based on our previous introduction?"', k: 10, the timecost is 0.3029952049255371
2024-05-30 12:50:33.007 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.330078125
172.20.156.165 - - [30/May/2024 12:50:34] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:50:34.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.488 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.514 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.537 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.590 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.617 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.674 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.722 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.723 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.752 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.787 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.813 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.836 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.861 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.887 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.967 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:34.991 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.019 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.042 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.066 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.091 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.118 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.144 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.171 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.196 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.225 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.251 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.281 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.305 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.330 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.387 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.408 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.434 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.461 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.540 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.565 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.594 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.621 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.646 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.678 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.705 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.727 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.752 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.778 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 12:50:35.894 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1064 completion_tokens=53 total_tokens=1117
2024-05-30 12:50:35.895 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 7.504120826721191

2024-05-30 12:57:12.696 | WARNING  | server.app.queries:generate_answer:210 - For query: '你好。请问什么是javahhh', detect the language is 'Chinese'!
2024-05-30 12:57:14.255 | WARNING  | server.app.queries:refine_query:105 - For the query: '你好。请问什么是javahhh', the refined query is '你好，请问javahhh是什么？我之前询问过相关信息，但可能需要更详细的解释。'. The timecost is 1.558034896850586
2024-05-30 12:57:14.256 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '你好。请问什么是javahhh', usage=prompt_tokens=579 completion_tokens=23 total_tokens=602
2024-05-30 12:57:14.540 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好，请问javahhh是什么？我之前询问过相关信息，但可能需要更详细的解释。', k: 10, the timecost is 0.2821223735809326
2024-05-30 12:57:14.565 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好。请问什么是javahhh', k: 10, the timecost is 0.3086857795715332
172.20.156.165 - - [30/May/2024 12:57:15] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:57:15.545 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.568 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.592 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.616 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.688 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.741 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.763 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.817 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.840 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.865 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.889 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.939 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:15.989 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.016 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.040 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.066 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.095 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.117 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.209 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.212 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.218 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.264 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.287 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.317 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.336 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.361 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.411 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.435 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.510 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.559 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.583 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.633 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.682 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.717 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.734 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.757 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.782 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.829 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.833 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.879 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.914 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.928 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:16.980 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.065 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.141 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.163 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.186 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.237 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.262 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.287 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.309 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.360 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.386 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.411 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.437 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.464 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.522 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.546 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.569 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.592 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.616 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.643 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.708 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.708 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.762 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.808 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.839 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.887 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.910 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.936 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.960 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:17.984 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.011 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.066 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.086 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.117 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.171 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.199 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.285 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.309 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.360 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.385 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.409 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.433 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.457 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.482 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.507 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.582 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.607 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.630 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=None
2024-05-30 12:57:18.836 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好。请问什么是javahhh', usage=prompt_tokens=1337 completion_tokens=127 total_tokens=1464
2024-05-30 12:57:18.837 | SUCCESS  | server.app.queries:generate_llm:452 - query: '你好。请问什么是javahhh' and user_id: '0accf4d8-ca47-4041-bc6a-94d448b39be5' is processed successfully, the answer is:
您好！看来您问的是关于“javahhh”的问题。不过，我需要澄清一下，根据我目前的配置和所提供的信息，我主要能协助您了解和解决与`LangChain`相关的问题。关于“javahhh”，我没有直接相关的信息或服务。

如果您有关于`LangChain`的问题，我会很乐意帮助您解答。如果有需要了解“javahhh”的进一步信息，我建议您可以查阅一些在线编程教程或者参考专业的编程书籍。

希望我的回答对您有所帮助！如果有其他问题，欢迎继续提问。
the total timecost is 6.1420066356658936

172.20.156.165 - - [30/May/2024 12:58:03] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:58:03.875 | ERROR    | server.app.utils.decorators:decorated_function:20 - Token is missing!
172.20.156.165 - - [30/May/2024 12:58:03] "[31m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 401 -
172.20.156.165 - - [30/May/2024 12:58:27] "[36mGET /open-kf-admin/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:27] "[36mGET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:27] "[36mGET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:27] "[36mGET /open-kf-admin/assets/Setting-uk7UYz_k.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:27] "[36mGET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:28] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:58:33] "[36mGET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:39] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:40] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 12:58:40] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
2024-05-30 12:58:41.753 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzE3NjQ5OTIxfQ.DN9iUp0OCBJJoD-e68PqDXfSya3cLQSDDtFHmGQH70o' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.156.165 - - [30/May/2024 12:58:41] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:58:41] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 12:58:58] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:58:58.520 | ERROR    | server.app.utils.decorators:decorated_function:20 - Token is missing!
172.20.156.165 - - [30/May/2024 12:58:58] "[31m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 401 -
2024-05-30 12:59:21.462 | WARNING  | server.app.queries:generate_answer:210 - For query: '.', detect the language is 'English'!
2024-05-30 12:59:23.413 | WARNING  | server.app.queries:refine_query:105 - For the query: '.', the refined query is 'I apologize, but it seems there was an error and I'm unable to access the follow-up message you provided. Could you please re-provide the message so that I can assist you accordingly?'. The timecost is 1.9501292705535889
2024-05-30 12:59:23.414 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '.', usage=prompt_tokens=322 completion_tokens=44 total_tokens=366
2024-05-30 12:59:23.747 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '.', k: 10, the timecost is 0.33278775215148926
2024-05-30 12:59:23.764 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'I apologize, but it seems there was an error and I'm unable to access the follow-up message you provided. Could you please re-provide the message so that I can assist you accordingly?', k: 10, the timecost is 0.34714436531066895
172.20.156.165 - - [30/May/2024 12:59:24] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 12:59:24.847 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.872 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.920 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.971 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:24.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.018 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.045 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.095 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.153 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.178 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.202 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.230 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.253 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.278 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.329 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.355 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.388 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.506 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.559 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.590 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.614 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.637 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.662 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.690 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.713 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.738 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.762 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.844 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.870 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.890 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.965 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:25.991 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.017 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.047 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.077 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.103 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.130 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=None
2024-05-30 12:59:26.258 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '.', usage=prompt_tokens=1066 completion_tokens=53 total_tokens=1119
2024-05-30 12:59:26.259 | SUCCESS  | server.app.queries:generate_llm:452 - query: '.' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 4.797622442245483

172.20.156.165 - - [30/May/2024 13:00:02] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:00:02.732 | ERROR    | server.app.utils.decorators:decorated_function:20 - Token is missing!
172.20.156.165 - - [30/May/2024 13:00:02] "[31m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 401 -
172.20.156.165 - - [30/May/2024 13:00:28] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:00:28.671 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 13:00:31.105 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'In light of our previous interaction where you indicated your role as an assistant related to `LangChain` and offered help with any specific questions, I am reaching out to inquire if you can assist me with understanding [insert specific topic or question related to LangChain services here].'. The timecost is 2.43289852142334
2024-05-30 13:00:31.106 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=387 completion_tokens=60 total_tokens=447
2024-05-30 13:00:31.354 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.24761199951171875
2024-05-30 13:00:31.397 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'In light of our previous interaction where you indicated your role as an assistant related to `LangChain` and offered help with any specific questions, I am reaching out to inquire if you can assist me with understanding [insert specific topic or question related to LangChain services here].', k: 10, the timecost is 0.28823375701904297
172.20.156.165 - - [30/May/2024 13:00:32] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:00:32.293 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.372 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.397 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.423 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.507 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.733 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.758 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.782 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.929 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.953 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:32.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.029 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.078 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.102 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.229 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.253 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.278 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.303 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.325 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.379 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.403 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.428 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.452 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.502 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.538 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.585 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.607 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.635 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.657 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.684 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.706 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:00:33.808 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1131 completion_tokens=53 total_tokens=1184
2024-05-30 13:00:33.809 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 5.138695001602173

172.20.156.165 - - [30/May/2024 13:01:40] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:01:40.395 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 13:01:44.145 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry. However, the content of the initial question is not provided in the chat history. Assuming the human is seeking information about `LangChain` and its services, the refined standalone question based on the follow-up message could be:

"What additional information do you have about `LangChain` and its services that you would like me to assist you with?"'. The timecost is 3.7494704723358154
2024-05-30 13:01:44.145 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=387 completion_tokens=103 total_tokens=490
2024-05-30 13:01:44.420 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.273942232131958
2024-05-30 13:01:44.468 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry. However, the content of the initial question is not provided in the chat history. Assuming the human is seeking information about `LangChain` and its services, the refined standalone question based on the follow-up message could be:

"What additional information do you have about `LangChain` and its services that you would like me to assist you with?"', k: 10, the timecost is 0.3191070556640625
172.20.156.165 - - [30/May/2024 13:01:45] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:01:45.408 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.428 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.477 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.502 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.529 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.562 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.591 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.612 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.638 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.663 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.691 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.721 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.746 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.770 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.825 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.848 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.879 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.903 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.926 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:45.975 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.001 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.084 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.114 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.142 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.166 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.191 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.212 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.262 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.288 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.312 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.337 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.364 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.424 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.449 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.476 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.503 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.541 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.592 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.616 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.644 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:46.671 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:47.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:47.228 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:47.254 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:01:47.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1131 completion_tokens=53 total_tokens=1184
2024-05-30 13:01:47.360 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 6.965723991394043

172.20.156.165 - - [30/May/2024 13:03:21] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:03:21.223 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-05-30 13:03:25.770 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a repetition of the initial message, indicating a potential misunderstanding or request for clarification about the nature of the assistance offered. The intent seems to be to confirm the scope of the services provided by `LangChain` and what kind of questions the human can ask.

Refined Standalone Question:
"What kind of questions can I ask you about `LangChain` and its services?"'. The timecost is 4.545607566833496
2024-05-30 13:03:25.770 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=387 completion_tokens=103 total_tokens=490
2024-05-30 13:03:26.029 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.2577347755432129
2024-05-30 13:03:26.110 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a repetition of the initial message, indicating a potential misunderstanding or request for clarification about the nature of the assistance offered. The intent seems to be to confirm the scope of the services provided by `LangChain` and what kind of questions the human can ask.

Refined Standalone Question:
"What kind of questions can I ask you about `LangChain` and its services?"', k: 10, the timecost is 0.3367621898651123
172.20.156.165 - - [30/May/2024 13:03:27] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:03:27.043 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.065 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.090 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.225 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.248 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.275 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.327 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.350 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.375 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.423 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.474 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.498 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.549 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.574 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.605 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.629 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.653 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.682 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.703 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.724 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.750 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.779 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.804 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.829 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.855 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.879 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:27.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.007 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.007 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.027 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.052 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.137 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.165 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.191 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.273 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.305 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.323 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.347 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.378 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-05-30 13:03:28.537 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1131 completion_tokens=53 total_tokens=1184
2024-05-30 13:03:28.538 | SUCCESS  | server.app.queries:generate_llm:452 - query: '?' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 7.315746068954468

172.20.156.165 - - [30/May/2024 13:03:28] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:03:30.001 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-05-30 13:03:34.327 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial query. However, since the content of the follow-up message is not provided, I can only assume that it is seeking further information or clarification about `LangChain`.

Refined Standalone Question (in Japanese):
「LangChain」に関する詳細な情報を教えてください。具体的な質問はありませんが、さらなる情報や Clarification が必要です。'. The timecost is 4.324810981750488
2024-05-30 13:03:34.328 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=390 completion_tokens=121 total_tokens=511
2024-05-30 13:03:34.829 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.5002665519714355
2024-05-30 13:03:34.853 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial query. However, since the content of the follow-up message is not provided, I can only assume that it is seeking further information or clarification about `LangChain`.

Refined Standalone Question (in Japanese):
「LangChain」に関する詳細な情報を教えてください。具体的な質問はありませんが、さらなる情報や Clarification が必要です。', k: 10, the timecost is 0.5225486755371094
172.20.156.165 - - [30/May/2024 13:03:35] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:03:35.871 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:35.894 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:35.920 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:35.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:35.967 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:35.992 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.049 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.122 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.172 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.248 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.249 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.270 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.293 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.343 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.369 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.394 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.417 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.441 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.473 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.522 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.548 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.622 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.646 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.679 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.704 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.728 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.760 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.836 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.878 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.926 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.952 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.976 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:36.998 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:37.023 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:37.049 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:37.071 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:37.096 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:37.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:03:37.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1136 completion_tokens=51 total_tokens=1187
2024-05-30 13:03:37.222 | SUCCESS  | server.app.queries:generate_llm:452 - query: '？' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm here to assist you with information related to LangChain. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 7.221620321273804

172.20.156.165 - - [30/May/2024 13:05:22] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:05:23.571 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-05-30 13:05:26.740 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history, the follow-up message from the human seems to be a continuation of a conversation about LangChain, possibly seeking more information or assistance. To capture the relevant context and intent of the follow-up message, the refined standalone question in Japanese could be:

「LangChainについての追加情報やサポートが必要です。具体的な質問をいただけますか？」'. The timecost is 3.1685752868652344
2024-05-30 13:05:26.741 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=389 completion_tokens=97 total_tokens=486
2024-05-30 13:05:27.020 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.2789735794067383
2024-05-30 13:05:27.060 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human seems to be a continuation of a conversation about LangChain, possibly seeking more information or assistance. To capture the relevant context and intent of the follow-up message, the refined standalone question in Japanese could be:

「LangChainについての追加情報やサポートが必要です。具体的な質問をいただけますか？」', k: 10, the timecost is 0.31609463691711426
172.20.156.165 - - [30/May/2024 13:05:27] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:05:27.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:27.976 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.001 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.051 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.091 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.104 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.129 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.154 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.174 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.258 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.284 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.310 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.361 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.383 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.434 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.457 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.559 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.605 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.629 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.681 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.735 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.759 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.785 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.810 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.838 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.855 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.877 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.901 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.928 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:28.984 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:29.008 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:29.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:29.060 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:29.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:29.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:29.134 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.214 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.314 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.337 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.362 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.387 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.414 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.442 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.465 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.494 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.568 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.664 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.688 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.740 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.763 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.790 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.813 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:30.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1135 completion_tokens=73 total_tokens=1208
2024-05-30 13:05:30.925 | SUCCESS  | server.app.queries:generate_llm:452 - query: '？' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm sorry, I cannot find a specific answer about '？' from the information provided. I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 7.355393171310425

172.20.156.165 - - [30/May/2024 13:05:54] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:05:54.337 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-05-30 13:05:57.176 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures the relevant context from the conversation would be:

「LangChainのサービスに関する具体的な質問をいくつか教えてください。助けていただきます。」'. The timecost is 2.838083267211914
2024-05-30 13:05:57.176 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=410 completion_tokens=78 total_tokens=488
2024-05-30 13:05:57.462 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures the relevant context from the conversation would be:

「LangChainのサービスに関する具体的な質問をいくつか教えてください。助けていただきます。」', k: 10, the timecost is 0.28311777114868164
2024-05-30 13:05:57.481 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.304440975189209
172.20.156.165 - - [30/May/2024 13:05:58] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:05:58.448 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.478 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.504 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.589 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.619 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.802 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.863 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.893 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.922 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.950 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:58.982 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.012 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.041 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.072 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.104 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.130 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.159 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.188 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.217 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.276 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.331 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.388 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.416 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.447 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.477 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.505 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.676 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.696 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.725 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.755 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.819 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:05:59.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1156 completion_tokens=44 total_tokens=1200
2024-05-30 13:05:59.925 | SUCCESS  | server.app.queries:generate_llm:452 - query: '？' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
您好！我是LangChain的人工智能助手。请问有什么可以帮助您的吗？如果您有任何关于我们的服务或需要帮助的问题，请随时提问，我将尽我所能为您提供准确和相关的答案。
the total timecost is 5.588998556137085

172.20.156.165 - - [30/May/2024 13:06:40] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:06:40.691 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-05-30 13:06:45.157 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history where the human's initial message started with "？", and the assistant provided a general greeting and offer to help with any questions about LangChain services, the follow-up message "？" seems to be a continuation of the human's initial query. Assuming the human is seeking assistance or information about a specific topic starting with "？", the refined standalone question could be:

"Continuing from the previous query starting with '？', what specific information or assistance are you seeking regarding LangChain services or related topics?"'. The timecost is 4.4648261070251465
2024-05-30 13:06:45.158 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=404 completion_tokens=116 total_tokens=520
2024-05-30 13:06:45.488 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.32939839363098145
2024-05-30 13:06:45.493 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history where the human's initial message started with "？", and the assistant provided a general greeting and offer to help with any questions about LangChain services, the follow-up message "？" seems to be a continuation of the human's initial query. Assuming the human is seeking assistance or information about a specific topic starting with "？", the refined standalone question could be:

"Continuing from the previous query starting with '？', what specific information or assistance are you seeking regarding LangChain services or related topics?"', k: 10, the timecost is 0.33202195167541504
172.20.156.165 - - [30/May/2024 13:06:46] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:06:46.434 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.583 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.673 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.700 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.726 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.795 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.818 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.900 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.962 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:46.985 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.058 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.153 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.178 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.205 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.229 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.277 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.326 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.375 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.398 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.428 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.462 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.505 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.562 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.579 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.632 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.675 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.727 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.752 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.777 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.822 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.890 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.938 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.965 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:47.991 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.016 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.093 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.148 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.177 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.345 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.414 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.471 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.486 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:06:48.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1150 completion_tokens=73 total_tokens=1223
2024-05-30 13:06:48.769 | SUCCESS  | server.app.queries:generate_llm:452 - query: '？' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I'm sorry, I cannot find a specific answer about '？' from the information provided. I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 8.078216791152954

172.20.156.165 - - [30/May/2024 13:07:27] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:07:27.536 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-05-30 13:07:31.735 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures all relevant context from the conversation would be:

「LangChainについての質問があります。具体的には、「？」という内容の情報を探していましたが、見つかりませんでした。そのため、再び同じ内容の質問をしております。これまでの情報から適切な回答をお願いします。」'. The timecost is 4.198830842971802
2024-05-30 13:07:31.736 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=404 completion_tokens=129 total_tokens=533
2024-05-30 13:07:32.001 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures all relevant context from the conversation would be:

「LangChainについての質問があります。具体的には、「？」という内容の情報を探していましたが、見つかりませんでした。そのため、再び同じ内容の質問をしております。これまでの情報から適切な回答をお願いします。」', k: 10, the timecost is 0.2625253200531006
2024-05-30 13:07:32.017 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.28084254264831543
172.20.156.165 - - [30/May/2024 13:07:33] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:07:33.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.161 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.189 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.209 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.258 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.290 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.307 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.338 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.373 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.422 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.504 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.529 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.553 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.579 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.626 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.700 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.733 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.757 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.781 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.840 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.889 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.914 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.939 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.966 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:33.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.044 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.068 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.092 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.118 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.143 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.168 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.213 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.238 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.264 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.289 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.321 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.507 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.542 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.569 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.593 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.616 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.668 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.738 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:34.814 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:35.052 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:35.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:35.104 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:07:35.205 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1150 completion_tokens=66 total_tokens=1216
2024-05-30 13:07:35.206 | SUCCESS  | server.app.queries:generate_llm:452 - query: '？' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
I apologize, but I am unable to provide an answer to your question as it is not related to the provided context of `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 7.670782089233398

172.20.156.165 - - [30/May/2024 13:12:21] "GET /open-kf-chatbot/ HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 13:12:21] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 13:12:21] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-05-30 13:12:22.616 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzE3NjUwNzQyfQ.nwjv-pRcMkoS5YQmbYb9TC2IImGyIRTjDuStZKnbRFQ' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.156.165 - - [30/May/2024 13:12:22] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 13:12:22] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
172.20.156.165 - - [30/May/2024 13:12:22] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.156.165 - - [30/May/2024 13:12:25] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:12:26.170 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-05-30 13:12:31.159 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'In the conversation history provided, the Human has twice asked questions that the Assistant was unable to answer due to their context not being related to `LangChain`. Despite the Assistant indicating that they can only provide information related to `LangChain`, the Human has persisted with the same question marked as "？". To capture the intent of the follow-up message while adhering to the guidelines, the refined standalone question in Japanese could be:

" Continuing from the previous conversation, what is the specific question you intended to ask about `LangChain` that I was unable to answer?"'. The timecost is 4.988759994506836
2024-05-30 13:12:31.160 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=425 completion_tokens=127 total_tokens=552
2024-05-30 13:12:31.441 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.28075075149536133
2024-05-30 13:12:31.481 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'In the conversation history provided, the Human has twice asked questions that the Assistant was unable to answer due to their context not being related to `LangChain`. Despite the Assistant indicating that they can only provide information related to `LangChain`, the Human has persisted with the same question marked as "？". To capture the intent of the follow-up message while adhering to the guidelines, the refined standalone question in Japanese could be:

" Continuing from the previous conversation, what is the specific question you intended to ask about `LangChain` that I was unable to answer?"', k: 10, the timecost is 0.3177189826965332
172.20.156.165 - - [30/May/2024 13:12:32] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:12:32.573 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.619 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.680 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.708 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.731 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.754 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.787 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.808 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.831 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.858 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.931 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:32.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.062 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.093 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.166 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.261 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.285 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.307 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.330 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.354 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.386 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.412 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.473 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.505 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.624 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.651 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.673 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.726 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.803 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.831 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.855 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.877 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.905 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.932 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.958 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:33.980 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.028 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.056 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.113 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.166 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.193 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.222 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.244 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.265 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.316 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.338 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.375 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.395 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.421 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.450 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.512 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.563 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.591 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.613 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.639 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.667 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.693 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.723 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.781 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.807 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.830 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.951 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.953 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.953 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.963 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:34.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.038 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.060 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.088 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.119 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.167 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.198 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.239 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.283 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.310 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.338 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.387 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.412 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.433 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.484 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.515 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.537 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.562 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.585 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.612 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.637 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.663 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.690 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.711 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.731 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.774 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.844 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.863 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.886 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.913 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.940 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:35.989 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.019 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.042 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.102 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.132 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.157 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.184 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.239 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.346 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.395 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.422 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.445 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.495 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.563 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.601 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.625 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.647 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.695 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.718 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.774 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.802 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.834 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.854 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.877 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.911 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.933 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.952 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:36.984 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.013 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.095 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.145 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.172 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.198 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.249 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.275 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.306 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.336 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.357 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.385 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.410 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.440 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.463 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.512 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.560 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.593 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.616 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.639 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.670 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.693 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.716 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.737 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.761 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.805 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:37.977 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.054 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.080 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.142 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.161 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.187 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.210 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.235 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.263 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.291 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.314 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.338 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.395 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.422 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.446 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.472 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.582 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.607 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.636 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:12:38.680 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
172.20.156.165 - - [30/May/2024 13:12:51] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:12:51.250 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-05-30 13:12:59.592 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'In the conversation history provided, the Human has twice asked questions that the Assistant was unable to answer due to their context not being related to `LangChain`. Despite the Assistant indicating that they can only provide information related to `LangChain`, the Human has persisted with the same question. To capture the intent of the follow-up message while adhering to the guidelines, the refined standalone question in Japanese could be:

" Continuing from our previous conversation, could you please provide more information or clarify the nature of your inquiry regarding '？' since it seems unrelated to the context of `LangChain`? " 

This question maintains the same language and intent of the follow-up message and references the historical question without directly using the Assistant's responses.'. The timecost is 8.340518951416016
2024-05-30 13:12:59.592 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=425 completion_tokens=164 total_tokens=589
2024-05-30 13:13:00.186 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'In the conversation history provided, the Human has twice asked questions that the Assistant was unable to answer due to their context not being related to `LangChain`. Despite the Assistant indicating that they can only provide information related to `LangChain`, the Human has persisted with the same question. To capture the intent of the follow-up message while adhering to the guidelines, the refined standalone question in Japanese could be:

" Continuing from our previous conversation, could you please provide more information or clarify the nature of your inquiry regarding '？' since it seems unrelated to the context of `LangChain`? " 

This question maintains the same language and intent of the follow-up message and references the historical question without directly using the Assistant's responses.', k: 10, the timecost is 0.5906479358673096
2024-05-30 13:13:00.231 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.6375806331634521
172.20.156.165 - - [30/May/2024 13:13:01] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:13:01.133 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.258 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.308 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.331 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.357 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.445 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.458 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.549 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.550 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.551 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.558 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.584 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.645 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.646 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.667 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.693 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.716 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.741 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.814 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.844 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.891 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.919 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.942 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.967 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:01.992 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.017 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.042 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.067 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.093 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.145 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.169 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.198 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.248 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.270 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.295 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.346 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.372 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.397 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.422 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.447 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.497 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.521 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.550 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.625 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.696 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.697 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.725 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.775 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.802 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.826 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.852 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.877 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.905 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.957 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:02.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.004 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.061 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.088 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.111 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.169 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.255 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.305 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.330 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.356 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.382 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.408 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.435 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.462 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.512 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.587 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.638 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.663 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.716 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.741 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.804 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.827 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.881 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.908 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.931 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.962 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:03.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.032 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.082 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.131 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.185 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.208 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.281 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.306 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.332 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.390 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.414 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.451 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.479 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.503 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.526 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.551 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.576 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.629 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.662 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.684 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.707 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.732 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.757 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.808 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.833 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.889 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.919 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.957 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:04.981 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.027 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.138 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.165 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.194 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.235 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.239 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.262 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.289 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.397 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.420 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.446 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.471 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.504 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.524 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.574 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.601 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.628 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.653 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.702 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.728 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.754 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.907 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:05.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.018 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.048 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.069 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.089 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.117 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.141 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.219 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.246 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.322 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.350 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.398 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.436 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.463 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.488 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.517 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.544 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.565 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.591 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.621 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.644 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.669 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.703 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.724 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.745 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.795 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.820 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.872 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.900 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.932 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.961 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:06.983 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.029 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.063 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.091 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.119 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.191 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.215 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.266 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.345 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.370 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.396 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.420 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.450 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.479 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.507 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.528 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.554 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.634 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.668 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.693 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.814 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.847 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.885 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.940 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.963 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:07.992 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.033 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.061 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.136 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.235 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.243 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.262 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.288 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.316 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.339 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.407 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.424 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.449 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.506 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.531 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.558 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.584 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.635 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.659 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.685 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.792 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.819 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.851 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.875 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.929 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:08.977 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.030 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.058 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.133 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.181 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.210 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.259 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.312 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.393 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.434 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.443 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.533 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.546 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.598 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.625 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.650 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.678 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.713 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.733 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.760 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.785 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.839 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.867 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.895 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.923 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.969 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:09.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:10.018 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:10.044 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:10.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:10.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:10.124 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:10.151 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:13:10.248 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1171 completion_tokens=341 total_tokens=1512
2024-05-30 13:13:10.249 | SUCCESS  | server.app.queries:generate_llm:452 - query: '？' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
お客様、こんにちは！ご質問に答えるためには、提供されたコンテキストに基づいて必要な情報を分析する必要があります。しかし、提供された情報に基づいて、「？」に特定の答えを見つけることができません。 LangChain に関する情報での質問に答えることができます。ご質問が LangChain に関するサービスに関連していない場合、お答えすることができません。具体的な質問があれば、お聞きください。私は最善で答えを提供します。

### ソース
- ""

この回答は、提供されたコンテキストに基づいて作成されました。質問に基づいた回答は、Markdown のスyntaxを使用して完全に整形されています。具体的な回答に基づいたソースは、「[Hyperlinks](URL)」の形式でリンクされています。質問に基づいた回答に使用されたコンテキスト内の情報は、「[Hyperlinks](URL)」の形式でリンクされています。
the total timecost is 18.999263048171997

172.20.156.165 - - [30/May/2024 13:15:15] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:15:15.698 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-05-30 13:15:18.884 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the context of our previous conversation where I inquired about `LangChain`, and considering your response that the question was not related to the provided context, I would like to ask a new question that pertains specifically to `LangChain`. Could you please explain what `LangChain` is and how it can be utilized in the context of language processing or artificial intelligence?'. The timecost is 3.1854074001312256
2024-05-30 13:15:18.884 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=693 completion_tokens=84 total_tokens=777
2024-05-30 13:15:19.161 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.27527832984924316
2024-05-30 13:15:19.206 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the context of our previous conversation where I inquired about `LangChain`, and considering your response that the question was not related to the provided context, I would like to ask a new question that pertains specifically to `LangChain`. Could you please explain what `LangChain` is and how it can be utilized in the context of language processing or artificial intelligence?', k: 10, the timecost is 0.31777381896972656
172.20.156.165 - - [30/May/2024 13:15:20] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:15:20.550 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.573 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.598 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.661 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.722 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.771 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.797 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.823 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.848 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.876 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.931 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.957 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:20.985 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.012 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.051 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.079 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.103 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.160 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.207 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.259 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.285 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.311 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.337 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.389 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.413 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.439 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.471 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.542 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.566 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.593 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.619 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.678 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.731 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.843 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.844 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.846 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.892 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.917 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:21.969 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.009 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.020 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.054 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.082 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.165 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.188 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.214 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.302 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.356 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.447 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.525 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.550 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.695 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.719 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.778 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.840 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.881 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.894 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.959 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:22.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.042 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.071 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.092 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.116 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.143 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.170 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.195 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.257 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.310 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.334 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.365 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.385 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.409 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.436 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.461 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.486 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.511 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.537 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.577 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.600 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.626 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.723 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.724 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.766 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.814 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.839 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.865 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.892 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:23.973 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.000 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.062 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.114 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.166 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.193 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.279 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.305 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.327 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.392 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.417 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.444 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.476 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.497 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.556 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.583 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.633 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.702 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.721 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.776 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.833 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.853 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.875 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.902 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:24.982 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.039 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.094 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.116 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.143 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.185 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.212 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.237 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.263 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.296 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.321 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.367 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.394 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.421 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.454 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.501 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.540 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.609 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.636 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.764 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.794 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.820 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.841 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.909 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:25.937 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:26.012 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:26.041 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:26.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:26.106 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:26.132 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:26.161 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:26.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:26.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:26.375 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1439 completion_tokens=196 total_tokens=1635
2024-05-30 13:15:26.376 | SUCCESS  | server.app.queries:generate_llm:452 - query: '？' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
お客様、こんにちは！ご質問に答えるためには、提供されたコンテキストに基づいて必要な情報を分析する必要があります。しかし、提供された情報に基づいて、「？」に特定の答えを見つけることができません。 LangChain に関する情報での質問に答えることができます。ご質問が LangChain に関するサービスに関連していない場合、お答えすることができません。具体的な質問があれば、お聞きください。私は最善で答えを提供します。

### ソース
- ""
the total timecost is 10.678810119628906

172.20.156.165 - - [30/May/2024 13:15:44] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:15:44.901 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-05-30 13:15:52.287 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history where the Assistant explains that it needs more specific information to answer the Human's question, and that it can provide information related to LangChain, the follow-up message from the Human seems to be another question mark. The intent of the follow-up message is not clear from the given context.

If the follow-up message is intended to be a new question related to LangChain or requires further clarification, the refined standalone question could be:

```
お客様が最初に提出した質問に答えるために、どのような追加的情報が必要ですか？LangChainに関する質問はどのような内容であれ、詳細にお聞きいただけますか？
```

This question asks for the necessary additional information to answer the original question and also invites the Human to ask a question about LangChain. It is formulated in Japanese, maintains the length of the original follow-up message, and does not directly use the Assistant's responses.'. The timecost is 7.385509967803955
2024-05-30 13:15:52.288 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=824 completion_tokens=234 total_tokens=1058
2024-05-30 13:15:52.603 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history where the Assistant explains that it needs more specific information to answer the Human's question, and that it can provide information related to LangChain, the follow-up message from the Human seems to be another question mark. The intent of the follow-up message is not clear from the given context.

If the follow-up message is intended to be a new question related to LangChain or requires further clarification, the refined standalone question could be:

```
お客様が最初に提出した質問に答えるために、どのような追加的情報が必要ですか？LangChainに関する質問はどのような内容であれ、詳細にお聞きいただけますか？
```

This question asks for the necessary additional information to answer the original question and also invites the Human to ask a question about LangChain. It is formulated in Japanese, maintains the length of the original follow-up message, and does not directly use the Assistant's responses.', k: 10, the timecost is 0.3124065399169922
2024-05-30 13:15:52.622 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.33333802223205566
172.20.156.165 - - [30/May/2024 13:15:53] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:15:53.931 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.043 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.069 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.123 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.149 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.177 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.208 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.259 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.280 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.329 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.354 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.381 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.433 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.571 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.621 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.645 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.696 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.722 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.749 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.777 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.802 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.825 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.850 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.875 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.902 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.926 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.953 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:54.978 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.031 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.057 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.105 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.140 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.199 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.272 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.298 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.322 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.376 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.403 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.427 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.451 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.478 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.506 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.534 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.559 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.590 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.624 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.680 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.694 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.720 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.743 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.800 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.827 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.851 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.876 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.903 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.929 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:55.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.040 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.060 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.099 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.125 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.179 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.205 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.258 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.484 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.507 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.564 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.610 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.647 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.711 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.729 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.756 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.835 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.857 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.879 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.931 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:56.981 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.006 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.031 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.057 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.079 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.418 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.469 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.524 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.546 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.574 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.599 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.622 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.673 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.731 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.755 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.781 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.828 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.850 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.876 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.901 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.952 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:57.975 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.036 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.061 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.086 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.147 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.202 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.203 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.226 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.247 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.273 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.337 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.365 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.388 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.416 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.440 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.488 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.556 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.587 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.607 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.635 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.660 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.682 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.785 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.961 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:58.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.009 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.085 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.136 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.159 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.185 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.211 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.264 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.291 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.315 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.388 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.416 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.441 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.468 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.579 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.630 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.658 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.685 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.728 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.802 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.804 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-05-30 13:15:59.986 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1570 completion_tokens=196 total_tokens=1766
2024-05-30 13:15:59.987 | SUCCESS  | server.app.queries:generate_llm:452 - query: '？' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
お客様、こんにちは！ご質問に答えるためには、提供されたコンテキストに基づいて必要な情報を分析する必要があります。しかし、提供された情報に基づいて、「？」に特定の答えを見つけることができません。 LangChain に関する情報での質問に答えることができます。ご質問が LangChain に関するサービスに関連していない場合、お答えすることができません。具体的な質問があれば、お聞きください。私は最善で答えを提供します。

### ソース
- ""
the total timecost is 15.087205410003662

172.20.156.165 - - [30/May/2024 13:18:23] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:18:23.516 | WARNING  | server.app.queries:generate_answer:210 - For query: '你好你好', detect the language is 'Chinese'!
2024-05-30 13:18:24.707 | WARNING  | server.app.queries:refine_query:105 - For the query: '你好你好', the refined query is '你好你好！请问你的问题是什么？'. The timecost is 1.1902351379394531
2024-05-30 13:18:24.708 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '你好你好', usage=prompt_tokens=681 completion_tokens=10 total_tokens=691
2024-05-30 13:18:24.977 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好你好', k: 10, the timecost is 0.2684957981109619
2024-05-30 13:18:25.003 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好你好！请问你的问题是什么？', k: 10, the timecost is 0.29193115234375
172.20.156.165 - - [30/May/2024 13:18:26] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 13:18:26.184 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.261 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.313 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.383 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.389 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.417 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.439 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.491 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.516 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.567 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.644 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.668 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.692 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.718 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.743 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.796 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.818 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.850 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.868 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.922 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.949 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.972 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:26.997 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:27.022 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:27.049 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=None
2024-05-30 13:18:27.162 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好你好', usage=prompt_tokens=1429 completion_tokens=37 total_tokens=1466
2024-05-30 13:18:27.163 | SUCCESS  | server.app.queries:generate_llm:452 - query: '你好你好' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
您好！我是人工智能助手，很高兴为您服务。如果您有任何关于LangChain的问题或需要帮助，请随时告诉我，我会尽力为您提供准确和相关的答案。
the total timecost is 3.647916078567505

172.20.156.165 - - [30/May/2024 14:29:11] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:29:11.999 | WARNING  | server.app.queries:generate_answer:210 - For query: '你好', detect the language is 'Chinese'!
2024-05-30 14:29:13.457 | WARNING  | server.app.queries:refine_query:105 - For the query: '你好', the refined query is '你好，请问您之前和助手交流了什么内容？是基于这些信息您想继续提问吗？'. The timecost is 1.4566504955291748
2024-05-30 14:29:13.457 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '你好', usage=prompt_tokens=323 completion_tokens=23 total_tokens=346
2024-05-30 14:29:13.711 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好', k: 10, the timecost is 0.25314927101135254
2024-05-30 14:29:13.729 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好，请问您之前和助手交流了什么内容？是基于这些信息您想继续提问吗？', k: 10, the timecost is 0.26879334449768066
172.20.156.165 - - [30/May/2024 14:29:14] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:29:14.862 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:14.887 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:14.912 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:14.939 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:14.966 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:14.992 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.018 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.046 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.077 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.104 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.130 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.280 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.309 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.340 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.389 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.413 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.472 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.525 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.607 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.628 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.655 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.685 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.795 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.849 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.875 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.900 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:15.929 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:29:16.031 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=prompt_tokens=1069 completion_tokens=37 total_tokens=1106
2024-05-30 14:29:16.032 | SUCCESS  | server.app.queries:generate_llm:452 - query: '你好' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
你好！我是人工智能助手，很高兴为您服务。如果您有任何关于LangChain的问题或需要帮助，请随时提问，我会尽力为您提供准确和相关的答案。
the total timecost is 4.033985137939453

172.30.194.232 - - [30/May/2024 14:42:54] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:42:54.545 | WARNING  | server.app.queries:generate_answer:210 - For query: '你好', detect the language is 'Chinese'!
2024-05-30 14:42:55.915 | WARNING  | server.app.queries:refine_query:105 - For the query: '你好', the refined query is '你好，请问您之前询问LangChain相关问题的时候，有什么具体的需求或疑问吗？'. The timecost is 1.3694467544555664
2024-05-30 14:42:55.916 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '你好', usage=prompt_tokens=311 completion_tokens=23 total_tokens=334
2024-05-30 14:42:56.228 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好，请问您之前询问LangChain相关问题的时候，有什么具体的需求或疑问吗？', k: 10, the timecost is 0.3098440170288086
2024-05-30 14:42:56.241 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好', k: 10, the timecost is 0.3247108459472656
172.30.194.232 - - [30/May/2024 14:42:57] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:42:57.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.200 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.238 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.263 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.287 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.364 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.392 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.405 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.421 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.448 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.497 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.522 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.551 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.574 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.599 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.622 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.695 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.720 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.792 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.814 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.874 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.916 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:57.921 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:58.078 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:58.122 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:58.148 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:58.169 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:58.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:42:58.315 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=prompt_tokens=1057 completion_tokens=37 total_tokens=1094
2024-05-30 14:42:58.316 | SUCCESS  | server.app.queries:generate_llm:452 - query: '你好' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
你好！我是人工智能助手，很高兴为您服务。如果您有任何关于LangChain的问题或需要帮助，请随时提问，我会尽力为您提供准确和相关的答案。
the total timecost is 3.771937370300293

172.31.160.26 - - [30/May/2024 14:59:05] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:59:05.954 | WARNING  | server.app.queries:generate_answer:210 - For query: '你好', detect the language is 'Chinese'!
2024-05-30 14:59:07.417 | WARNING  | server.app.queries:refine_query:105 - For the query: '你好', the refined query is '你好，请问您之前询问关于LangChain的什么问题？我现在需要更详细的信息来帮助您。'. The timecost is 1.462228536605835
2024-05-30 14:59:07.417 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '你好', usage=prompt_tokens=362 completion_tokens=26 total_tokens=388
2024-05-30 14:59:07.722 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好，请问您之前询问关于LangChain的什么问题？我现在需要更详细的信息来帮助您。', k: 10, the timecost is 0.30204248428344727
2024-05-30 14:59:07.740 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好', k: 10, the timecost is 0.32254528999328613
172.31.160.26 - - [30/May/2024 14:59:08] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 14:59:08.697 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.721 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.746 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.773 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.797 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.823 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.852 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.878 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.935 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:08.980 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.207 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.242 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.264 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.285 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.310 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.336 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.389 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.414 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.440 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.492 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.517 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.567 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.593 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.619 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.643 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.722 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.742 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.805 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.819 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.843 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.869 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.893 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:09.954 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.002 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.026 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.051 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.084 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.103 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.130 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.153 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.178 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.203 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.254 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.307 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.333 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.390 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.415 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.441 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.467 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.493 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.519 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.546 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.571 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.691 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.729 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.777 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.830 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.881 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.907 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.933 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.960 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:10.986 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:11.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:11.048 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:11.066 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:11.089 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:11.112 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:11.152 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:11.170 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:11.203 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 14:59:11.328 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=prompt_tokens=1108 completion_tokens=90 total_tokens=1198
2024-05-30 14:59:11.329 | SUCCESS  | server.app.queries:generate_llm:452 - query: '你好' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
你好！我是人工智能助手，很高兴为您服务。如果您有任何关于LangChain的问题或需要帮助，请随时提问，我会尽力为您提供准确和相关的答案。如果您想了解LangChain的相关信息，请访问我们的官方网站：[LangChain官网](http://www.langchain.com)。

Sources:
- [LangChain官网](http://www.langchain.com)
the total timecost is 5.376306056976318

172.31.160.26 - - [30/May/2024 15:00:03] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:00:03.831 | WARNING  | server.app.queries:generate_answer:210 - For query: '你们langchain能干什么', detect the language is 'Chinese'!
2024-05-30 15:00:04.956 | WARNING  | server.app.queries:refine_query:105 - For the query: '你们langchain能干什么', the refined query is 'LangChain能提供哪些服务或功能？'. The timecost is 1.1236329078674316
2024-05-30 15:00:04.957 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '你们langchain能干什么', usage=prompt_tokens=419 completion_tokens=13 total_tokens=432
2024-05-30 15:00:05.215 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'LangChain能提供哪些服务或功能？', k: 10, the timecost is 0.25598788261413574
2024-05-30 15:00:05.236 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你们langchain能干什么', k: 10, the timecost is 0.2787466049194336
172.31.160.26 - - [30/May/2024 15:00:06] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:00:06.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.525 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.555 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.577 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.629 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.656 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.684 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.711 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.766 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.791 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.817 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.872 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.897 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.925 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.949 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:06.974 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.007 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.034 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.057 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.083 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.136 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.163 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.195 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.216 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.266 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.400 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.407 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.433 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.460 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.486 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.541 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.567 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.593 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.624 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.676 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.701 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.738 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:07.978 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.004 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.029 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.055 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.081 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.107 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.140 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.184 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.216 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.238 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.263 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.288 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.322 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.365 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.462 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.494 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.521 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.573 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.623 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.676 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.710 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.737 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.793 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.839 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.891 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:08.950 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.008 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.088 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.089 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.090 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.116 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.142 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.167 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.194 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.230 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.347 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.373 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.397 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.424 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.450 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.484 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.501 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.553 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.583 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.684 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.767 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.793 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.822 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.867 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.947 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.974 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:09.998 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:10.025 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:10.044 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:10.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:10.094 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:10.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:10.147 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:10.171 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=None
2024-05-30 15:00:10.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你们langchain能干什么', usage=prompt_tokens=1173 completion_tokens=130 total_tokens=1303
2024-05-30 15:00:10.288 | SUCCESS  | server.app.queries:generate_llm:452 - query: '你们langchain能干什么' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
您好！我是人工智能助手，很高兴为您服务。根据我目前获取的信息，我无法直接回答“你们LangChain能干什么”的问题。不过，我这里是为了帮助您获取与LangChain相关的信息和帮助。如果您有关于LangChain的具体问题或需求，请随时告诉我，我会尽我所能为您提供准确和相关的答案。如果您想了解更多关于LangChain的信息，请访问我们的官方网站：[LangChain官网](http://www.langchain.com)。

Sources:
- [LangChain官网](http://www.langchain.com)
the total timecost is 6.457250595092773

172.31.160.26 - - [30/May/2024 15:00:20] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:00:20.811 | WARNING  | server.app.queries:generate_answer:210 - For query: '介绍一下java', detect the language is 'Chinese'!
2024-05-30 15:00:22.182 | WARNING  | server.app.queries:refine_query:105 - For the query: '介绍一下java', the refined query is '介绍一下Java这种编程语言的相关信息。'. The timecost is 1.3697116374969482
2024-05-30 15:00:22.182 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '介绍一下java', usage=prompt_tokens=513 completion_tokens=10 total_tokens=523
2024-05-30 15:00:22.443 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '介绍一下Java这种编程语言的相关信息。', k: 10, the timecost is 0.25927090644836426
2024-05-30 15:00:22.491 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '介绍一下java', k: 10, the timecost is 0.3085603713989258
172.31.160.26 - - [30/May/2024 15:00:24] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:00:24.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.386 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.417 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.450 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.476 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.501 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.526 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.553 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.602 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.627 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.655 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.683 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.713 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.738 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.763 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.791 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.843 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.871 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.893 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.921 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.975 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:24.997 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.024 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.047 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.122 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.149 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.174 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.200 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.230 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.253 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.309 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.329 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.354 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.380 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.457 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.506 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.559 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.590 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.647 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.673 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.724 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.749 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.773 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.798 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.823 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.854 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.875 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.901 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.959 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:25.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.071 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.090 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.140 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.219 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.246 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.266 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.291 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.316 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.341 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.371 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.394 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.419 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.447 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.473 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.496 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.524 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.547 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.572 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.623 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.650 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.682 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.703 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.725 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.781 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.827 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.853 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.939 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:26.990 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.041 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.523 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.549 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.575 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.611 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.627 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.652 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.704 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.734 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.772 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.797 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.822 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.849 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.871 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.945 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.974 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:27.998 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.025 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.050 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.077 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.104 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.132 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.160 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.215 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.293 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.319 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.346 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.372 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.399 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.428 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.460 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.486 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.537 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.589 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.615 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.645 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.699 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.723 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.784 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.831 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.889 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.941 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.967 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:28.994 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.022 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.051 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.078 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.113 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.143 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.166 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.193 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.271 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.323 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.352 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.378 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.404 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.482 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.510 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.563 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.594 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.645 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.675 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.700 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.730 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.752 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.779 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.805 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.897 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.898 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.919 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:29.998 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.027 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.064 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.101 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.173 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.232 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.296 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.321 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.371 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.513 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.568 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.620 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.647 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.708 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.764 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.791 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.818 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.872 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.927 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.952 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:30.976 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.005 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.031 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.059 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.085 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.138 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.164 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.195 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.218 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.246 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.268 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.295 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.400 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.425 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.508 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.535 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.588 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.614 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.643 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.668 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.694 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.720 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:31.747 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.088 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.116 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.144 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.172 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.229 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.286 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.314 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.368 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.400 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.426 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.453 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.514 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.567 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.594 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.623 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.675 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.711 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.734 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.759 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.840 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.868 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.922 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.948 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:32.975 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.016 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.043 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.067 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.094 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.147 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.177 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.208 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.350 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.403 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.454 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.510 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.563 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.592 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.617 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.644 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.699 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.728 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.755 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.781 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.843 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.893 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=None
2024-05-30 15:00:33.996 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '介绍一下java', usage=prompt_tokens=1261 completion_tokens=326 total_tokens=1587
2024-05-30 15:00:33.996 | SUCCESS  | server.app.queries:generate_llm:452 - query: '介绍一下java' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
Java是一种广泛使用的编程语言，以其“一次编写，到处运行”的理念著称。它是由Sun Microsystems公司在1995年推出的，后来被甲骨文公司（Oracle）收购。Java在企业级应用、移动应用（尤其是Android）、网络应用等方面有着广泛的应用。

Java的特点包括：

1. **跨平台性**：Java代码在不同的操作系统上可以被相同的Java虚拟机（JVM）执行。
2. **面向对象**：Java是一种面向对象的编程语言，支持封装、继承和多态等特性。
3. **强类型语言**：Java要求所有变量都必须声明类型，这有助于提高程序的稳定性和可维护性。
4. **安全性**：Java设计了多种机制来确保代码的安全性，如沙箱安全模型。
5. **多线程支持**：Java提供了内置的多线程支持，方便开发者进行并发编程。

Java生态系统非常丰富，有大量的开发工具、库和框架，如Eclipse、IntelliJ IDEA、Spring等。此外，Java社区也非常活跃，有许多在线资源和文档供开发者学习和参考。

如果您对LangChain有任何具体问题或需求，请随时告诉我，我会尽我所能为您提供准确和相关的答案。如果您想了解更多关于LangChain的信息，请访问我们的官方网站：[LangChain官网](http://www.langchain.com)。

Sources:
- [LangChain官网](http://www.langchain.com)
the total timecost is 13.186379432678223

172.30.154.145 - - [30/May/2024 15:14:19] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:14:19.343 | WARNING  | server.app.queries:generate_answer:210 - For query: '你好，请问java是什么？', detect the language is 'Chinese'!
2024-05-30 15:14:22.727 | WARNING  | server.app.queries:refine_query:105 - For the query: '你好，请问java是什么？', the refined query is '你好，请问Java是一种什么编程语言，它有哪些特点和应用场景？'. The timecost is 3.383230447769165
2024-05-30 15:14:22.728 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '你好，请问java是什么？', usage=prompt_tokens=753 completion_tokens=18 total_tokens=771
2024-05-30 15:14:22.997 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好，请问Java是一种什么编程语言，它有哪些特点和应用场景？', k: 10, the timecost is 0.26569032669067383
2024-05-30 15:14:23.003 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好，请问java是什么？', k: 10, the timecost is 0.27454376220703125
172.30.154.145 - - [30/May/2024 15:14:24] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:14:24.955 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.011 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.037 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.062 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.088 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.114 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.140 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.164 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.215 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.248 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.265 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.296 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.323 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.372 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.397 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.448 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.473 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.499 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.526 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.553 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.577 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.600 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.625 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.678 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.700 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.726 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.751 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.774 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.799 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.824 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.848 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.874 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.921 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.945 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.970 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:25.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.022 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.046 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.068 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.096 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.182 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.196 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.222 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.273 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.294 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.370 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.412 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.417 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.442 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.491 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.568 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.646 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.669 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.694 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.719 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.794 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.817 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.867 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.892 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.916 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.940 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.966 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:26.997 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.022 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.047 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.071 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.145 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.180 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.195 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.220 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.304 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.339 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.360 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.409 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.444 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.585 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.631 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.635 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.659 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.683 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.733 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.785 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.809 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.840 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.858 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.932 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.933 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:27.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.044 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.068 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.097 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.188 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.189 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.207 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.293 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.294 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.333 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.382 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.406 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.482 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.506 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.531 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.557 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.581 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.606 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.630 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.655 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.679 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.705 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.730 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.755 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.806 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.830 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.880 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.906 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:28.982 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.007 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.043 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.057 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.082 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.107 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.132 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.187 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.213 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.237 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.262 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.285 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.312 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.360 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.384 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.409 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.435 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.484 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.512 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.584 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.634 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.655 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.683 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.704 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.728 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.776 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.826 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.848 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.936 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:29.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.064 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.113 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.136 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.160 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.184 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.208 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.306 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.336 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.358 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.382 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.407 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.508 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.529 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.557 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.580 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.670 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.694 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.729 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.756 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.812 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.836 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.861 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.886 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.910 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.934 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.962 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:30.988 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.037 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.065 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.096 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.113 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.162 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.186 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.219 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.243 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.327 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.387 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.394 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=None
2024-05-30 15:14:31.516 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好，请问java是什么？', usage=prompt_tokens=1509 completion_tokens=246 total_tokens=1755
2024-05-30 15:14:31.517 | SUCCESS  | server.app.queries:generate_llm:452 - query: '你好，请问java是什么？' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
你好！Java是一种广泛使用的编程语言，以其“一次编写，到处运行”的理念著称。它是由Sun Microsystems公司在1995年推出的，后来被甲骨文公司（Oracle）收购。Java在企业级应用、移动应用（尤其是Android）、网络应用等方面有着广泛的应用。

Java的特点包括：

1. **跨平台性**：Java代码在不同的操作系统上可以被相同的Java虚拟机（JVM）执行。
2. **面向对象**：Java是一种面向对象的编程语言，支持封装、继承和多态等特性。
3. **强类型语言**：Java要求所有变量都必须声明类型，这有助于提高程序的稳定性和可维护性。
4. **安全性**：Java设计了多种机制来确保代码的安全性，如沙箱安全模型。
5. **多线程支持**：Java提供了内置的多线程支持，方便开发者进行并发编程。

Java生态系统非常丰富，有大量的开发工具、库和框架，如Eclipse、IntelliJ IDEA、Spring等。此外，Java社区也非常活跃，有许多在线资源和文档供开发者学习和参考。
the total timecost is 12.17470669746399

172.30.154.145 - - [30/May/2024 15:14:52] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:14:52.750 | WARNING  | server.app.queries:generate_answer:210 - For query: 'Java基本数据类型有哪些？', detect the language is 'Chinese'!
2024-05-30 15:14:54.071 | WARNING  | server.app.queries:refine_query:105 - For the query: 'Java基本数据类型有哪些？', the refined query is 'Java语言中的基本数据类型有哪些？'. The timecost is 1.3209331035614014
2024-05-30 15:14:54.072 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: 'Java基本数据类型有哪些？', usage=prompt_tokens=869 completion_tokens=10 total_tokens=879
2024-05-30 15:14:54.353 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Java基本数据类型有哪些？', k: 10, the timecost is 0.2807590961456299
2024-05-30 15:14:54.358 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Java语言中的基本数据类型有哪些？', k: 10, the timecost is 0.2825949192047119
172.30.154.145 - - [30/May/2024 15:14:55] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:14:55.667 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.688 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.716 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.744 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.792 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.825 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.919 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.941 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.969 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:55.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.025 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.049 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.075 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.100 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.126 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.150 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.180 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.255 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.281 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.306 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.331 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.413 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.455 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.608 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.632 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.659 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.689 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.719 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.744 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.787 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.831 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.884 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.908 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.932 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.960 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:56.982 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.007 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.058 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.086 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.115 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.137 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.161 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.234 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.235 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.238 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.312 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.337 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.362 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.388 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.412 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.441 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.466 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.490 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.569 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.596 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.666 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.688 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.718 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.744 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.767 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=None
2024-05-30 15:14:57.885 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: 'Java基本数据类型有哪些？', usage=prompt_tokens=1625 completion_tokens=82 total_tokens=1707
2024-05-30 15:14:57.887 | SUCCESS  | server.app.queries:generate_llm:452 - query: 'Java基本数据类型有哪些？' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
Java的基本数据类型包括以下几种：

- 整数类型：`byte`, `short`, `int`, `long`
- 浮点类型：`float`, `double`
- 字符类型：`char`
- 布尔类型：`boolean`

这些基本数据类型是Java编程语言中的基础，用于构建更复杂的程序和算法。
the total timecost is 5.136991024017334

172.30.154.145 - - [30/May/2024 15:15:34] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:15:34.530 | WARNING  | server.app.queries:generate_answer:210 - For query: '具体介绍一下Java中的文件读写', detect the language is 'Chinese'!
2024-05-30 15:15:36.006 | WARNING  | server.app.queries:refine_query:105 - For the query: '具体介绍一下Java中的文件读写', the refined query is 'Java中的文件读写功能是如何实现的，能详细说明吗？'. The timecost is 1.4751131534576416
2024-05-30 15:15:36.006 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '具体介绍一下Java中的文件读写', usage=prompt_tokens=630 completion_tokens=16 total_tokens=646
2024-05-30 15:15:36.400 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '具体介绍一下Java中的文件读写', k: 10, the timecost is 0.3925144672393799
2024-05-30 15:15:36.407 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Java中的文件读写功能是如何实现的，能详细说明吗？', k: 10, the timecost is 0.3973853588104248
172.30.154.145 - - [30/May/2024 15:15:37] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:15:37.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.565 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.586 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.611 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.639 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.662 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.692 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.718 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.747 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.775 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.827 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.854 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.878 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.904 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.932 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.956 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:37.984 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.008 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.038 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.062 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.112 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.139 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.162 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.188 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.212 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.263 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.317 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.343 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.370 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.420 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.476 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.525 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.555 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.575 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.599 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.628 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.650 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.770 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.776 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.827 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.854 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:38.877 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.110 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.231 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.232 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.237 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.238 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.333 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.334 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.334 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.360 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.361 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.362 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.362 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.383 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.409 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.458 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.483 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.515 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.558 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.584 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.621 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.648 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.691 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.725 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.760 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.801 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.826 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.857 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.884 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:39.908 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.118 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.142 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.168 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.194 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.221 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.245 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.742 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.790 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.841 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.868 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.893 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:40.982 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.033 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.060 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.087 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.115 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.140 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.165 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.191 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.218 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.294 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.317 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.348 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.426 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.449 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.502 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.554 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.629 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.678 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.679 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.693 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.729 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.782 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.796 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.841 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.884 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.910 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.937 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.963 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:41.990 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.013 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.045 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.064 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.155 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.184 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.265 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.287 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.313 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.364 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.391 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.421 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.444 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.566 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.590 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.625 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.642 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.671 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.697 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.725 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.750 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.777 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.810 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.836 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.865 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.891 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.920 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.950 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:42.976 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.020 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.050 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.073 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.099 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.126 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.157 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.189 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.223 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.266 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.343 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.370 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.402 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.431 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.543 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.589 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.601 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.631 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.670 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.697 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.729 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.772 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.797 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.825 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.854 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.881 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.909 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.935 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.960 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:43.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.039 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.065 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.098 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.146 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.174 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.198 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.225 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.313 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.544 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.545 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.545 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.546 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.575 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.575 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.576 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.576 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.578 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.605 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.631 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.685 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.794 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.885 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.910 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.936 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.965 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:44.990 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.017 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.070 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.094 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.121 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.242 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.269 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.358 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.381 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.412 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.426 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.451 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.479 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.504 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.555 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.584 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.606 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.632 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.660 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.688 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.793 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.819 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.866 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.900 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.951 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:45.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.003 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.083 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.226 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.491 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.492 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.492 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.493 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.493 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.493 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.517 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.518 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.519 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.541 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.602 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.620 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.645 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.673 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.700 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.752 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.783 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.810 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.835 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.896 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.943 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.973 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:46.998 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.024 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.076 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.113 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.129 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.159 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.185 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.213 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.236 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.265 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.292 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.376 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.393 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.423 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.449 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.475 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.527 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.553 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.611 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.637 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.663 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.740 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.768 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.794 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.845 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.871 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.898 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.925 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.950 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:47.977 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.002 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.032 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.057 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.084 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.135 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.162 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.191 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.217 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.270 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.317 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.330 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.398 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.398 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.429 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.456 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.488 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.544 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.604 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.627 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.653 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.676 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.712 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.760 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.786 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.851 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.852 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.873 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.892 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.918 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.944 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:48.972 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.204 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.205 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.205 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.206 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.207 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.208 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.209 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.233 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.311 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.339 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.368 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.394 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.448 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.479 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.533 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.557 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.585 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.638 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.665 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.709 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.717 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.743 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.796 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.822 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.860 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.915 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.937 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:49.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.014 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.042 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.068 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.099 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.138 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.153 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.179 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.207 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.232 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.288 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.316 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.342 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.374 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.514 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.515 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.539 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.565 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.597 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.643 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.672 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.698 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.750 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.776 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.804 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.859 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.887 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.917 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.941 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.971 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:50.995 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.020 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.255 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.257 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.257 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.260 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.261 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.281 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.282 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.291 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.320 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.344 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.401 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.423 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.449 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.536 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.561 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.587 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.617 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.659 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.734 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.735 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.736 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.765 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.790 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.816 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.871 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.900 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.925 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.951 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:51.981 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.010 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.037 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.067 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.099 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.136 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.162 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.186 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.215 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.240 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.267 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.295 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.321 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.380 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.404 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.432 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.482 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.505 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.530 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.556 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.585 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.612 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.637 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.662 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.691 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.719 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.744 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.772 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.797 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.823 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.858 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.884 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.913 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.939 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.964 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:52.992 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.017 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.045 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.075 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.119 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.156 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.188 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.209 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.235 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.313 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.351 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.377 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.403 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.430 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.459 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.487 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.516 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.560 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.618 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.690 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.714 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.739 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.766 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.793 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.821 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.864 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:53.889 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.125 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.126 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.126 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.127 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.127 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.128 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.154 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.155 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.174 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.202 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.229 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.335 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.363 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.387 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.414 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.488 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.517 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.541 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.570 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.603 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.623 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.705 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.731 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.759 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.789 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.815 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.842 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.869 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.895 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.921 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.959 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:54.986 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.015 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.044 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.082 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.109 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.137 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.163 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.190 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.217 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.244 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.279 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.305 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.334 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.359 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.402 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.474 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.500 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.526 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.552 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.609 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.632 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.659 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.686 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.727 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.753 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.780 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.816 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.844 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.869 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.894 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.924 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.953 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:55.979 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.004 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.031 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.058 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.086 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.120 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.145 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.172 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.199 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.225 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.252 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.281 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.307 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.334 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.361 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.405 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.434 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.458 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.490 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.515 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.544 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.570 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.621 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.649 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.677 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.702 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=None
2024-05-30 15:15:56.803 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '具体介绍一下Java中的文件读写', usage=prompt_tokens=1388 completion_tokens=666 total_tokens=2054
2024-05-30 15:15:56.805 | SUCCESS  | server.app.queries:generate_llm:452 - query: '具体介绍一下Java中的文件读写' and user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0' is processed successfully, the answer is:
Java中的文件读写操作是Java IO（输入/输出）的一部分，它允许程序读取和写入文件系统中的文件。在Java中，文件读写通常使用以下几种方式：

1. **使用 `FileInputStream` 和 `FileOutputStream`**：这些是用于读取和写入文件的字节流。`FileInputStream` 用于读取文件，而 `FileOutputStream` 用于写入文件。

   ```java
   // 读取文件
   FileInputStream in = new FileInputStream("file.txt");
   // 写入文件
   FileOutputStream out = new FileOutputStream("file.txt");
   ```

2. **使用 `BufferedReader` 和 `BufferedWriter`**：这些类提供了缓冲功能，可以更高效地读写文本文件。

   ```java
   // 读取文本文件
   BufferedReader reader = new BufferedReader(new FileReader("file.txt"));
   // 写入文本文件
   BufferedWriter writer = new BufferedWriter(new FileWriter("file.txt"));
   ```

3. **使用 `Scanner` 类**：可以用来读取文本文件中的数据，特别是当文件格式比较规范时。

   ```java
   Scanner scanner = new Scanner(new File("file.txt"));
   while (scanner.hasNextLine()) {
       String line = scanner.nextLine();
       // 处理每一行
   }
   ```

4. **使用 `java.nio.file` 包中的类**：在Java 7及以上版本，`java.nio.file` 包提供了更现代的文件操作API，如 `Files` 和 `Paths` 类。

   ```java
   // 读取所有行到List集合中
   List<String> lines = Files.readAllLines(Paths.get("file.txt"));
   // 将List中的内容写入文件
   Files.write(Paths.get("file.txt"), lines, StandardOpenOption.CREATE);
   ```

每种方法都有其用途和适用场景。字节流适合处理二进制文件，而字符流适合处理文本文件。缓冲流可以提高读写效率。`Scanner` 类和 `java.nio.file` 包中的类提供了更简洁、更易于理解的语法。

以上是关于Java中文件读写操作的基本介绍。如果您需要更详细的代码示例或其他高级特性，请告知我以便进一步提供帮助。

**Sources:**
- [Oracle Java Documentation](https://docs.oracle.com/javase/tutorial/essential/io/index.html)
- [Java NIO.2 API Specification](https://docs.oracle.com/javase/10/docs/api/java/nio/file/package-summary.html)
the total timecost is 22.275317907333374

172.30.155.138 - - [30/May/2024 15:32:21] "GET /open-kf-admin/ HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:21] "GET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:21] "GET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:22] "GET /open-kf-admin/assets/Dashboard-WB1KXATu.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:22] "GET /open-kf-admin/assets/Dashboard-BieUHPHe.css HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:22] "GET /open-kf-admin/assets/loading-vsHIitu7.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:22] "GET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:22] "GET /open-kf-admin/vite.svg HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:32:23] "GET /open-kf-admin/assets/Login-VKBBRRSv.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:26] "POST /open_kf_api/account/login HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:36] "GET /open-kf-chatbot HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:36] "GET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:36] "GET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1" 200 -
2024-05-30 15:33:37.253 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYzNjZmE0OTEtZmQ1ZC00MjEwLWFhOTgtOWFiNmQyYTkwNmVhIiwiZXhwIjoxNzE3NjU5MjE3fQ.RAPOHVM8Rj21nUL2shC2orq0YeA17fp_nhyuEuS51Es' with user_id: 'c3cfa491-fd5d-4210-aa98-9ab6d2a906ea'
172.30.155.138 - - [30/May/2024 15:33:37] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:37] "GET /open-kf-chatbot/vite.svg HTTP/1.1" 200 -
172.30.155.138 - - [30/May/2024 15:33:37] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-05-30 15:33:47.777 | WARNING  | server.app.queries:generate_answer:210 - For query: '你好', detect the language is 'Chinese'!
2024-05-30 15:33:49.425 | WARNING  | server.app.queries:refine_query:105 - For the query: '你好', the refined query is '你好，请问您之前和助手交流了什么内容？您想继续询问关于 `LangChain` 的哪些具体问题？'. The timecost is 1.6467335224151611
2024-05-30 15:33:49.425 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '你好', usage=prompt_tokens=323 completion_tokens=30 total_tokens=353
2024-05-30 15:33:49.687 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好，请问您之前和助手交流了什么内容？您想继续询问关于 `LangChain` 的哪些具体问题？', k: 10, the timecost is 0.25896763801574707
2024-05-30 15:33:49.748 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好', k: 10, the timecost is 0.3219790458679199
172.30.155.138 - - [30/May/2024 15:33:50] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-05-30 15:33:50.718 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:50.772 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:50.800 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:50.832 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:50.856 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:50.883 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:50.907 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:50.933 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:50.958 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:50.987 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.011 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.038 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.067 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.096 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.125 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.158 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.179 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.203 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.228 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.256 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.288 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.310 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.339 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.366 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.392 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.479 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.480 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.481 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.501 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.529 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.557 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.586 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.612 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.641 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.667 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-05-30 15:33:51.769 | WARNING  | server.app.queries:generate_llm:448 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=prompt_tokens=1069 completion_tokens=37 total_tokens=1106
2024-05-30 15:33:51.770 | SUCCESS  | server.app.queries:generate_llm:452 - query: '你好' and user_id: 'c3cfa491-fd5d-4210-aa98-9ab6d2a906ea' is processed successfully, the answer is:
你好！我是人工智能助手，很高兴为您服务。如果您有任何关于LangChain的问题或需要帮助，请随时提问，我会尽力为您提供准确和相关的答案。
the total timecost is 3.9938669204711914

172.20.157.198 - - [30/May/2024 22:58:40] code 400, message Bad request version ('À\x13À')
172.20.157.198 - - [30/May/2024 22:58:40] "[35m[1m\x16\x03\x01\x00á\x01\x00\x00Ý\x03\x03¢»ª\x16\x95éôµ\x0bP\x10äÈvíßû\x8aéü¢\x11ßI\x0c>\x02>\x95Ü{x \x18Kë¬)ü¬Åt\x7f¦%µ§\x1b_~½Òüs\x9c\x98",ò)qt\x17è~\x00$\x13\x01\x13\x02\x13\x03À/À+À0À,Ì©Ì¨À\x09À\x13À[0m" HTTPStatus.BAD_REQUEST -
Traceback (most recent call last):
  File "rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
Traceback (most recent call last):
  File "/home/zhy/RAG-GPT/rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
Traceback (most recent call last):
  File "/home/zhy/RAG-GPT/rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
2024-07-07 20:05:53.643 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:7000
 * Running on http://59.78.194.84:7000
[33mPress CTRL+C to quit[0m
172.20.146.14 - - [07/Jul/2024 20:06:34] "[33mGET / HTTP/1.1[0m" 404 -
172.20.146.14 - - [07/Jul/2024 20:06:34] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
172.20.146.14 - - [07/Jul/2024 20:06:41] "GET /open-kf-admin/ HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:41] "GET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:41] "GET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:42] "GET /open-kf-admin/assets/Setting-uk7UYz_k.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:42] "GET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:42] "GET /open-kf-admin/vite.svg HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:42] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:49] "GET /open-kf-chatbot/ HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:49] "GET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:50] "GET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1" 200 -
2024-07-07 20:06:53.660 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiMjAwMzQyZjAtMjUwZS00YzM4LTk3YjctMTlkZDU0N2M1N2ZkIiwiZXhwIjoxNzIwOTU4ODEzfQ.q0hKFAoe5Gf487qNzMB3ss1CrQOt3WyYa19U2W0KYGw' with user_id: '200342f0-250e-4c38-97b7-19dd547c57fd'
172.20.146.14 - - [07/Jul/2024 20:06:53] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:53] "GET /open-kf-chatbot/vite.svg HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:06:54] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
2024-07-07 20:06:58.469 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.14 - - [07/Jul/2024 20:07:06] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    response = generate_answer(query, user_id, True)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
2024-07-07 20:07:21.395 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.14 - - [07/Jul/2024 20:07:29] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    response = generate_answer(query, user_id, True)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
2024-07-07 20:09:43.773 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
Address already in use
Port 7000 is in use by another program. Either identify and stop that program, or start the server with a different port.
2024-07-07 20:12:32.362 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
Address already in use
Port 7000 is in use by another program. Either identify and stop that program, or start the server with a different port.
2024-07-07 20:12:50.577 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
 * Serving Flask app 'rag_gpt_app'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:7001
 * Running on http://59.78.194.84:7001
[33mPress CTRL+C to quit[0m
172.20.146.14 - - [07/Jul/2024 20:12:55] "[33mGET / HTTP/1.1[0m" 404 -
172.20.146.14 - - [07/Jul/2024 20:12:55] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
172.20.146.14 - - [07/Jul/2024 20:13:01] "GET /open-kf-chatbot/ HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:13:01] "GET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:13:01] "GET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1" 200 -
2024-07-07 20:13:04.146 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzIwOTU5MTg0fQ.QFTdFDongKX2eMJF2ezNg1GUEwDcKttwd8cBpldIdEE' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.146.14 - - [07/Jul/2024 20:13:04] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:13:04] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:13:04] "GET /open-kf-chatbot/vite.svg HTTP/1.1" 200 -
2024-07-07 20:13:06.708 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.14 - - [07/Jul/2024 20:13:14] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    response = generate_answer(query, user_id, True)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.14 - - [07/Jul/2024 20:14:07] "GET /open-kf-admin/ HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:08] "GET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:08] "GET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:11] "GET /open-kf-admin/assets/Setting-uk7UYz_k.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:11] "GET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:11] "GET /open-kf-admin/vite.svg HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:11] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:38] "GET /open-kf-admin/assets/Login-VKBBRRSv.js HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:14:47] "POST /open_kf_api/account/login HTTP/1.1" 200 -
2024-07-07 20:15:26.327 | INFO     | server.app.account:login:35 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWRtaW4iLCJleHAiOjE3MjA5NTkzMjZ9.yXmPvGT5IqA7OWt_10sui4F6I9P3qmifuCFe9UcLzZE'
172.20.146.14 - - [07/Jul/2024 20:15:26] "POST /open_kf_api/account/login HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:15:26] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:15:30] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:15:30] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:15:30] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-07-07 20:15:31.301 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzIwOTU5MzMxfQ.jO5coJKN30ajLrkpP5V5jqq64i-OGS8wHlPiGTNsf7Y' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.146.14 - - [07/Jul/2024 20:15:31] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:15:31] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:15:31] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
2024-07-07 20:15:33.124 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.14 - - [07/Jul/2024 20:15:41] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
2024-07-07 20:45:46.685 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.14 - - [07/Jul/2024 20:45:51] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:45:54] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
2024-07-07 20:46:41.647 | INFO     | server.rag.index.embedder.document_embedder:__init__:40 - [DOC_EMBEDDER] init, collection_name: 'mychroma_collection', persist_directory: 'chroma_dir', llm_name: 'ZhipuAI'
Create tables in the SQLite database
Create indexes for the tables
Initialize the admin account
[INFO] account_name:'admin' already exists.
Initialize the bot settings
[INFO] the bot setting already exists.
SQLite init Done!


Init Chroma DB
Init Chroma DB Done!
2024-07-07 20:46:45.892 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
172.20.146.14 - - [07/Jul/2024 20:46:53] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.14 - - [07/Jul/2024 20:47:28] "[36mGET /open-kf-chatbot/ HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:29] "[36mGET /open-kf-chatbot/assets/index-C_E2Bb74.js HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:29] "[36mGET /open-kf-chatbot/assets/index-wZrUKwbn.css HTTP/1.1[0m" 304 -
2024-07-07 20:47:29.753 | SUCCESS  | server.app.auth:get_token:19 - Generate token: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYWZjYmJjYTgtYTYyYy00ODA5LTkzMGMtNGUxOTYyMDQ3YWYwIiwiZXhwIjoxNzIwOTYxMjQ5fQ.gp1uT31p9cWRDuASPHOnAMDJocqOxotmTvzQHV5WOV4' with user_id: 'afcbbca8-a62c-4809-930c-4e1962047af0'
172.20.146.14 - - [07/Jul/2024 20:47:29] "POST /open_kf_api/auth/get_token HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:47:29] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:47:30] "[36mGET /open-kf-chatbot/vite.svg HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:33] "[36mGET /open-kf-admin/ HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:33] "[36mGET /open-kf-admin/assets/index-ck01-P-l.js HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:33] "[36mGET /open-kf-admin/assets/index-rz5QqEag.css HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:34] "[36mGET /open-kf-admin/assets/Setting-uk7UYz_k.js HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:34] "[36mGET /open-kf-admin/assets/textarea-eX4nx7v5.js HTTP/1.1[0m" 304 -
172.20.146.14 - - [07/Jul/2024 20:47:34] "POST /open_kf_api/bot_config/get_bot_setting HTTP/1.1" 200 -
172.20.146.14 - - [07/Jul/2024 20:47:36] "[36mGET /open-kf-admin/vite.svg HTTP/1.1[0m" 304 -
2024-07-07 20:47:36.835 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
172.20.146.14 - - [07/Jul/2024 20:47:44] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.14 - - [07/Jul/2024 20:55:58] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 20:55:58.166 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-07 20:56:01.046 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'お客様は以前、`java`に関する質問をしましたか？具体的な内容やご不明な点を教えていただけますか？お手伝いできることがありましたら、遠慮なくお知らせください。'. The timecost is 2.879232406616211
2024-07-07 20:56:01.047 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=557 completion_tokens=74 total_tokens=631
2024-07-07 20:56:01.983 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.9356746673583984
2024-07-07 20:56:01.984 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'お客様は以前、`java`に関する質問をしましたか？具体的な内容やご不明な点を教えていただけますか？お手伝いできることがありましたら、遠慮なくお知らせください。', k: 10, the timecost is 0.9347405433654785
172.20.146.14 - - [07/Jul/2024 20:56:03] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 20:56:03.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.439 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.440 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.443 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.443 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.444 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.802 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.803 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.804 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.804 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.805 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.805 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.806 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.806 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.807 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.807 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.829 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.830 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.831 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.881 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.914 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.939 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.966 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:03.988 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.012 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.037 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.077 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.102 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.125 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.150 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.181 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.206 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.231 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.281 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.304 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.329 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.363 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.407 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.447 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.471 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.496 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.526 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.559 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.576 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.600 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.624 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.656 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.677 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.704 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.728 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.752 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.776 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.828 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.882 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.907 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.931 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.956 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:04.983 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.013 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.030 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.057 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.123 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.147 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.171 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.216 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.241 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.268 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.290 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.319 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.343 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.367 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.421 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.446 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.470 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.495 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.520 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.544 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.569 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.594 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.619 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.646 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.670 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.692 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.718 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.743 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.767 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.791 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.816 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.842 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.869 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.902 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:05.976 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:06.003 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:06.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:06.058 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 20:56:06.157 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1301 completion_tokens=112 total_tokens=1413
2024-07-07 20:56:06.159 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
こんにちは！質問がありましたか？ご不明な点や`java`に関するサポートが必要な場合は、具体的な質問をお願いいたします。この度は何の質問も受け取っておりませんでしたが、お手伝いできることがあれば、遠慮なくお知らせください。

Sources: ''
the total timecost is 7.99364972114563

172.20.146.14 - - [07/Jul/2024 21:08:29] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:08:29.873 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-07 21:08:33.135 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry seeking assistance with a Java-related question. To capture the relevant context while adhering to the guidelines provided, the refined standalone question would be:

"In our previous interaction, you expressed a need for support regarding Java. Could you please provide a specific question or area of concern related to Java that you would like assistance with?"'. The timecost is 3.2610361576080322
2024-07-07 21:08:33.135 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=506 completion_tokens=94 total_tokens=600
2024-07-07 21:08:33.459 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry seeking assistance with a Java-related question. To capture the relevant context while adhering to the guidelines provided, the refined standalone question would be:

"In our previous interaction, you expressed a need for support regarding Java. Could you please provide a specific question or area of concern related to Java that you would like assistance with?"', k: 10, the timecost is 0.3203911781311035
2024-07-07 21:08:33.460 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.3241424560546875
172.20.146.14 - - [07/Jul/2024 21:08:34] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:08:34.468 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:34.489 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:34.513 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
172.20.146.14 - - [07/Jul/2024 21:08:38] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:08:38.701 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-07 21:08:42.098 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry seeking assistance with a Java-related question. To capture the relevant context while adhering to the guidelines, the refined standalone question would be:

"In our previous interaction, you expressed a need for support regarding Java. Could you please provide a specific question or area of concern related to Java that you would like assistance with now?"'. The timecost is 3.3962790966033936
2024-07-07 21:08:42.099 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=506 completion_tokens=94 total_tokens=600
2024-07-07 21:08:42.357 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry seeking assistance with a Java-related question. To capture the relevant context while adhering to the guidelines, the refined standalone question would be:

"In our previous interaction, you expressed a need for support regarding Java. Could you please provide a specific question or area of concern related to Java that you would like assistance with now?"', k: 10, the timecost is 0.25519490242004395
2024-07-07 21:08:42.380 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.2803530693054199
172.20.146.14 - - [07/Jul/2024 21:08:43] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:08:43.400 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.478 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.502 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.548 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.574 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.622 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.646 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.672 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.694 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.719 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.744 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.767 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.791 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.815 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.848 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.866 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.888 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.911 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.941 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.960 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:43.982 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.012 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.037 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.060 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.085 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.108 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.133 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.182 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.231 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.254 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.280 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.302 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.333 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.351 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.379 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.396 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.420 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.445 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.478 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.502 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.527 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.552 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.582 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.621 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.645 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.751 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.773 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.798 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.829 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.848 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.897 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.945 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:44.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.019 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.045 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.077 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.096 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.120 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.144 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.170 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.198 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.223 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.247 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.297 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.332 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.374 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.405 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.434 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.455 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.486 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.510 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.535 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.558 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.584 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.623 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.634 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.657 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.682 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.714 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.738 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.794 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.852 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.875 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.900 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.925 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.950 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:45.974 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:46.049 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:46.073 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:46.098 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:46.123 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:08:46.226 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1250 completion_tokens=106 total_tokens=1356
2024-07-07 21:08:46.227 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
お客様の質問に答えるためには、提供された情報からの特定の知識が必要です。しかし、提供された情報に基づいて、具体的な質問に答えることができません。お手伝いできることがありますか？具体的な質問やご不明な点をお知らせください。

Sources: ''
the total timecost is 7.526385068893433

172.20.146.14 - - [07/Jul/2024 21:08:53] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:08:53.221 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-07-07 21:08:58.893 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry or a request for assistance with a Java (`java`) related issue. However, the message is incomplete and lacks specific details. To capture the relevant context while adhering to the guidelines provided, the follow-up message should be rewritten as a standalone question that refers back to the original conversation with the assistant. The rewritten question should be concise and preserve the original intent of the follow-up message.

Refined Standalone Question: "In our previous interaction, you mentioned that you couldn't provide a specific answer based on the information provided. Could you please clarify which information you require to give a detailed response regarding Java support?"'. The timecost is 5.670899152755737
2024-07-07 21:08:58.894 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=503 completion_tokens=158 total_tokens=661
2024-07-07 21:08:59.139 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.2443525791168213
2024-07-07 21:08:59.169 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of their initial inquiry or a request for assistance with a Java (`java`) related issue. However, the message is incomplete and lacks specific details. To capture the relevant context while adhering to the guidelines provided, the follow-up message should be rewritten as a standalone question that refers back to the original conversation with the assistant. The rewritten question should be concise and preserve the original intent of the follow-up message.

Refined Standalone Question: "In our previous interaction, you mentioned that you couldn't provide a specific answer based on the information provided. Could you please clarify which information you require to give a detailed response regarding Java support?"', k: 10, the timecost is 0.27184104919433594
172.20.146.14 - - [07/Jul/2024 21:09:01] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:09:01.298 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.320 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.344 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.368 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.391 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.415 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.438 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.462 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.486 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.510 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.559 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.583 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.607 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.629 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.653 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.676 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.700 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.724 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.747 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.771 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.794 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.818 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.842 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.892 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.915 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.940 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.963 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:01.995 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.020 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.043 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.066 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.097 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.115 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.164 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.165 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.191 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.212 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.237 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.260 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.283 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.307 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.331 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.355 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.379 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.403 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.428 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.458 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.475 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.501 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-07 21:09:02.626 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1245 completion_tokens=53 total_tokens=1298
2024-07-07 21:09:02.627 | SUCCESS  | server.app.queries:generate_llm:451 - query: '?' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 9.405974388122559

172.20.146.14 - - [07/Jul/2024 21:10:20] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:10:21.042 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-07 21:10:25.459 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history, the follow-up message from the human appears to be a continuation of a request for assistance or information. However, without the content of the assistant's responses, it's unclear what specifically the human is seeking. Therefore, the best approach is to craft a question that acknowledges the human's need for further clarification or help, without directly referencing the assistant's messages. 

Refined Standalone Question:
```
前の質問に答えるために、どのような追加情報が必要ですか？
```
(Translation: What additional information do you need to answer the previous question?)'. The timecost is 4.41569185256958
2024-07-07 21:10:25.459 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=445 completion_tokens=144 total_tokens=589
2024-07-07 21:10:25.716 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.2562263011932373
2024-07-07 21:10:25.726 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message from the human appears to be a continuation of a request for assistance or information. However, without the content of the assistant's responses, it's unclear what specifically the human is seeking. Therefore, the best approach is to craft a question that acknowledges the human's need for further clarification or help, without directly referencing the assistant's messages. 

Refined Standalone Question:
```
前の質問に答えるために、どのような追加情報が必要ですか？
```
(Translation: What additional information do you need to answer the previous question?)', k: 10, the timecost is 0.26326751708984375
172.20.146.14 - - [07/Jul/2024 21:10:26] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:10:26.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:26.783 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:26.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:26.829 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:26.852 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:26.875 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:26.898 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:26.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:26.944 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.028 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.028 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.041 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.064 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.088 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.111 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.136 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.158 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.180 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.226 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.273 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.305 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.319 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.342 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.365 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.389 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.413 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.439 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.464 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.488 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.506 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.530 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.553 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.582 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.622 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.646 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.668 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.713 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.737 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.760 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.784 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.814 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.833 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.880 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.903 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.951 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.974 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:27.996 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.070 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.094 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.117 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.141 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.164 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.187 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.211 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.265 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.289 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.313 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.335 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.358 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.383 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.405 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.428 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.452 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.474 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.498 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.523 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.547 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.569 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.595 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.617 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.641 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.664 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.686 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.708 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.732 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.763 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.779 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.802 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.825 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.848 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.871 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.895 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.925 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.956 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:28.980 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:29.003 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:29.025 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:29.053 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:29.072 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:29.096 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:29.165 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:29.190 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:29.212 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:29.235 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:10:29.340 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1189 completion_tokens=106 total_tokens=1295
2024-07-07 21:10:29.341 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
お客様の質問に答えるためには、提供された情報からの特定の知識が必要です。しかし、提供された情報に基づいて、具体的な質問に答えることができません。お手伝いできることがありますか？具体的な質問やご不明な点をお知らせください。

Sources: ''
the total timecost is 8.299574613571167

172.20.146.14 - - [07/Jul/2024 21:15:54] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:15:54.780 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-07 21:15:57.503 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'お客様は、以前にどのような質問をしていたか？それに対する Assistant の回答は、どのような情報を提供していたか？それに基づいて、現在の質問に答えることができますか？'. The timecost is 2.7221977710723877
2024-07-07 21:15:57.504 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=445 completion_tokens=74 total_tokens=519
2024-07-07 21:15:57.808 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'お客様は、以前にどのような質問をしていたか？それに対する Assistant の回答は、どのような情報を提供していたか？それに基づいて、現在の質問に答えることができますか？', k: 10, the timecost is 0.301389217376709
2024-07-07 21:15:57.832 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.32740259170532227
172.20.146.14 - - [07/Jul/2024 21:15:58] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:15:58.847 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:58.992 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.020 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.068 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.099 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.130 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.147 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.171 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.248 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.269 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.297 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.332 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.346 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.370 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.394 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.447 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.470 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.494 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.518 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.543 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.567 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.619 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.642 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.668 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.721 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.744 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.771 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.793 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.825 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.844 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.870 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.893 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.918 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.943 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.967 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:15:59.993 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.017 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.068 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.092 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.142 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.167 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.192 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.216 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.242 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.268 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.291 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.316 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.343 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.369 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.393 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.417 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.443 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.471 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.494 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.518 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.543 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.569 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.596 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.620 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.644 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.671 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.695 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.720 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.744 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.768 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.795 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.833 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.845 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.897 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:00.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.001 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.025 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.051 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.074 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.099 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.149 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.224 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.279 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.305 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.329 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.353 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.377 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.418 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.460 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.492 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.567 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.593 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.617 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.654 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:16:01.746 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1189 completion_tokens=106 total_tokens=1295
2024-07-07 21:16:01.747 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
お客様の質問に答えるためには、提供された情報からの特定の知識が必要です。しかし、提供された情報に基づいて、具体的な質問に答えることができません。お手伝いできることがありますか？具体的な質問やご不明な点をお知らせください。

Sources: ''
the total timecost is 6.9681642055511475

172.20.146.14 - - [07/Jul/2024 21:24:43] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:24:43.174 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-07 21:24:45.516 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'お客様は、以前にどのような質問をしていたか？その質問に答えるために必要な情報を提供していただけますか？'. The timecost is 2.3406238555908203
2024-07-07 21:24:45.517 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=500 completion_tokens=49 total_tokens=549
2024-07-07 21:24:46.244 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'お客様は、以前にどのような質問をしていたか？その質問に答えるために必要な情報を提供していただけますか？', k: 10, the timecost is 0.7243831157684326
2024-07-07 21:24:46.259 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.741180419921875
172.20.146.14 - - [07/Jul/2024 21:24:47] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:24:47.221 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.244 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.269 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.292 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.317 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.341 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.366 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.391 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.416 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.439 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.464 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.489 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.514 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.563 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.588 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.613 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.638 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.662 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.717 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.742 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.766 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.791 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.814 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.840 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.868 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.892 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.919 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.945 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:47.999 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.052 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.075 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.100 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.148 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.175 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.197 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.223 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.247 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.271 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.295 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.322 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.347 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.395 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.418 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.440 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.463 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.487 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.511 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.532 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.555 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.578 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.601 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.625 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.648 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.670 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.694 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.718 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.742 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.764 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.788 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.811 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.834 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.881 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.905 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.950 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.972 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:48.996 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.019 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.065 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.088 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.114 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.137 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.160 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.182 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.231 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.253 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.276 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.300 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.322 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.345 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.368 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.393 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.415 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.438 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.462 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.485 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.510 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.558 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.581 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.719 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:24:49.835 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1244 completion_tokens=106 total_tokens=1350
2024-07-07 21:24:49.836 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
お客様の質問に答えるためには、提供された情報からの特定の知識が必要です。しかし、提供された情報に基づいて、具体的な質問に答えることができません。お手伝いできることがありますか？具体的な質問やご不明な点をお知らせください。

Sources: ''
the total timecost is 6.662122964859009

172.20.146.14 - - [07/Jul/2024 21:30:42] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:30:42.850 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-07 21:30:45.278 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'お客様は、以前にどのような質問をしていたか？その質問に答えるために必要な情報を提供していただけますか？'. The timecost is 2.4273524284362793
2024-07-07 21:30:45.279 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=500 completion_tokens=49 total_tokens=549
2024-07-07 21:30:45.597 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'お客様は、以前にどのような質問をしていたか？その質問に答えるために必要な情報を提供していただけますか？', k: 10, the timecost is 0.3144049644470215
2024-07-07 21:30:46.006 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.7264013290405273
172.20.146.14 - - [07/Jul/2024 21:30:47] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-07 21:30:47.039 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.122 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.146 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.170 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.195 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.244 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.269 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.293 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.317 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.389 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.391 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.418 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.440 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.463 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.487 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.512 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.537 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.565 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.584 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.608 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.635 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.663 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.686 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.712 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.736 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.758 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.782 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.810 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.834 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.859 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.881 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.906 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.930 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.954 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:47.981 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.004 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.035 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.051 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.076 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.100 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.125 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.149 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.172 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.227 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.250 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.297 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.322 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.347 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.370 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.393 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.417 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.452 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.465 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.490 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.515 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.564 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.565 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.589 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.612 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.670 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.725 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.744 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.768 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.791 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.817 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.840 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.899 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.912 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.940 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.964 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:48.987 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.013 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.035 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.059 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.128 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.153 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.201 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.226 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.250 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.331 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.355 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.379 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.402 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.432 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.457 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.487 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.505 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.530 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.554 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.583 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.752 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.778 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-07 21:30:49.945 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1244 completion_tokens=106 total_tokens=1350
2024-07-07 21:30:49.946 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
お客様の質問に答えるためには、提供された情報からの特定の知識が必要です。しかし、提供された情報に基づいて、具体的な質問に答えることができません。お手伝いできることがありますか？具体的な質問やご不明な点をお知らせください。

Sources: ''
the total timecost is 7.097132682800293

172.20.146.181 - - [08/Jul/2024 14:47:46] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:47:46.324 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
172.20.146.181 - - [08/Jul/2024 14:47:54] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:47:55] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:47:55.372 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
172.20.146.181 - - [08/Jul/2024 14:48:03] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:51:50] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:51:50.316 | WARNING  | server.app.queries:generate_answer:210 - For query: '?
', detect the language is 'English'!
172.20.146.181 - - [08/Jul/2024 14:51:58] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:52:54] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:52:54.488 | WARNING  | server.app.queries:generate_answer:210 - For query: '?
', detect the language is 'English'!
172.20.146.181 - - [08/Jul/2024 14:53:02] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:53:14] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:53:14.808 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.181 - - [08/Jul/2024 14:53:21] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:53:21.259 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.181 - - [08/Jul/2024 14:53:22] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:53:29] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
Traceback (most recent call last):
  File "rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
172.20.146.181 - - [08/Jul/2024 14:55:09] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:55:09.107 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
172.20.146.181 - - [08/Jul/2024 14:55:17] "[35m[1mPOST /open_kf_api/queries/smart_query_stream HTTP/1.1[0m" 500 -
Error on request:
Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 69, in map_httpcore_exceptions
    yield
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_backends/sync.py", line 213, in connect_tcp
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 241, in request
    response = self._client.send(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/httpx/_transports/default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 362, in run_wsgi
    execute(self.server.app)
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/serving.py", line 325, in execute
    for data in application_iter:
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wsgi.py", line 256, in __next__
    return self._next()
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/werkzeug/wrappers/response.py", line 32, in _iter_encoded
    for item in iterable:
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 437, in generate_llm
    answer_chunks = []
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 224, in generate_answer
    adjust_query = refine_query(query, history_context, lang)
  File "/home/zhy/RAG-GPT/server/app/queries.py", line 102, in refine_query
    response = llm_generator.generate(prompt, False, False)
  File "/home/zhy/RAG-GPT/server/rag/generation/llm.py", line 71, in generate
    response = self.client.chat.completions.create(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/api_resource/chat/completions.py", line 48, in create
    return self._post(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 292, in post
    return self.request(
  File "/home/zhy/anaconda3/envs/mathglm/lib/python3.9/site-packages/zhipuai/core/_http_client.py", line 247, in request
    raise APITimeoutError(request=request) from err
zhipuai.core._errors.APITimeoutError: Request Timeout
172.20.146.181 - - [08/Jul/2024 14:56:19] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:56:20.015 | WARNING  | server.app.queries:generate_answer:210 - For query: '?', detect the language is 'English'!
2024-07-08 14:56:23.537 | WARNING  | server.app.queries:refine_query:105 - For the query: '?', the refined query is 'Given the context of the conversation, the follow-up message "?" appears to be an inquiry seeking clarification or further information. To create a standalone question that captures the relevant context from the conversation, we can infer that the human is interested in a specific aspect of `LangChain`'s services, although the exact nature of their question is not explicit in the follow-up message.

Refined Standalone Question: "What additional information can you provide about LangChain's services?"'. The timecost is 3.5207910537719727
2024-07-08 14:56:23.537 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '?', usage=prompt_tokens=320 completion_tokens=108 total_tokens=428
2024-07-08 14:56:23.872 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the context of the conversation, the follow-up message "?" appears to be an inquiry seeking clarification or further information. To create a standalone question that captures the relevant context from the conversation, we can infer that the human is interested in a specific aspect of `LangChain`'s services, although the exact nature of their question is not explicit in the follow-up message.

Refined Standalone Question: "What additional information can you provide about LangChain's services?"', k: 10, the timecost is 0.3304874897003174
2024-07-08 14:56:23.922 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '?', k: 10, the timecost is 0.38358068466186523
172.20.146.181 - - [08/Jul/2024 14:56:24] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 14:56:24.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:24.950 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:24.968 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:24.996 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.028 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.052 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.080 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.104 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.130 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.156 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.183 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.235 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.294 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.310 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.335 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.367 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.391 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.414 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.439 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.462 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.486 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.510 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.559 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.581 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.606 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.631 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.661 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.680 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.703 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.728 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.752 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.776 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.799 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.847 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.882 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.896 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.919 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.944 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.971 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:25.997 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.026 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.054 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.076 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.100 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.123 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.148 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=None
2024-07-08 14:56:26.273 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '?', usage=prompt_tokens=1062 completion_tokens=53 total_tokens=1115
2024-07-08 14:56:26.274 | SUCCESS  | server.app.queries:generate_llm:451 - query: '?' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
I'm here to assist you with information related to `LangChain`. If you have any specific questions about our services or need help, feel free to ask, and I'll do my best to provide you with accurate and relevant answers.
the total timecost is 6.259382247924805

Traceback (most recent call last):
  File "rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
172.20.146.181 - - [08/Jul/2024 16:25:42] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:25:42.786 | WARNING  | server.app.queries:generate_answer:210 - For query: '？？？', detect the language is 'Chinese'!
2024-07-08 16:25:44.228 | WARNING  | server.app.queries:refine_query:105 - For the query: '？？？', the refined query is '您好，我之前询问了关于`LangChain`的服务信息，您是否能帮我详细解答一些相关问题？'. The timecost is 1.441460371017456
2024-07-08 16:25:44.229 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？？？', usage=prompt_tokens=324 completion_tokens=27 total_tokens=351
2024-07-08 16:25:44.543 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '您好，我之前询问了关于`LangChain`的服务信息，您是否能帮我详细解答一些相关问题？', k: 10, the timecost is 0.3110363483428955
2024-07-08 16:25:44.549 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？？？', k: 10, the timecost is 0.3193645477294922
172.20.146.181 - - [08/Jul/2024 16:25:45] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:25:45.569 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.591 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.616 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.640 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.665 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.690 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.713 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.737 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.786 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.812 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.838 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.861 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.884 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.909 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.940 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.957 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:45.981 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.005 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.029 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.056 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.078 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.100 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.125 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.175 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.203 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.227 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.256 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.278 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.303 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.327 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.374 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.400 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.423 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=None
2024-07-08 16:25:46.517 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？', usage=prompt_tokens=1070 completion_tokens=38 total_tokens=1108
2024-07-08 16:25:46.518 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？？？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
您好！我是人工智能助手，有什么可以帮助您的吗？如果您有关于`LangChain`的具体问题，请随时提问，我会尽力为您提供准确和相关的答案。
the total timecost is 3.732966899871826

172.20.146.181 - - [08/Jul/2024 16:26:14] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:26:14.527 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-08 16:26:15.913 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Sorry, I couldn't understand your question. Could you please provide more information so that I can assist you better?'. The timecost is 1.3852038383483887
2024-07-08 16:26:15.914 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=313 completion_tokens=27 total_tokens=340
2024-07-08 16:26:16.178 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.26366639137268066
2024-07-08 16:26:16.207 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Sorry, I couldn't understand your question. Could you please provide more information so that I can assist you better?', k: 10, the timecost is 0.2902979850769043
172.20.146.181 - - [08/Jul/2024 16:26:17] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:26:17.142 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.165 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.186 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.232 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.254 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.277 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.302 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.323 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.349 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.370 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.396 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.420 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.445 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.468 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.489 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.511 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.556 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.580 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.606 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.624 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.651 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.670 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.692 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.716 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.745 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.765 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.789 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.814 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.837 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.858 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.884 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.908 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:17.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.028 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.040 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.066 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.087 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.109 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.132 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.154 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.192 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.203 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.226 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.271 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.295 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.316 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.339 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.362 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.385 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.408 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.437 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.476 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.501 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.522 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.547 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.573 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.622 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.646 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.666 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.711 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.734 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.790 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.805 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.825 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.848 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.872 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.896 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.916 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.943 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.971 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:18.988 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.010 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.034 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.056 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.079 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.101 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.168 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.170 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.193 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.217 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.240 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.263 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.286 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.308 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.333 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.358 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.387 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.406 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.430 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.474 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.526 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.550 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.576 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.619 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.642 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.665 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.687 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.711 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.736 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.758 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.782 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.804 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.827 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.852 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.874 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.896 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.918 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.941 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.964 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:19.988 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.012 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.033 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.057 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.081 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.104 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.129 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.149 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.201 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.218 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.243 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.267 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.289 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.357 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.380 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.403 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.426 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.451 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.480 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.504 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.532 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.540 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.571 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.588 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.611 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.634 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.658 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.681 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.708 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.729 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.750 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.774 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.796 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.820 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.866 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.918 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:20.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.018 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.040 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.062 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.085 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.111 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.200 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.263 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.286 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.313 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.336 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.357 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.378 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.400 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.425 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.447 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.470 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.495 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.516 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.544 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.563 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.587 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.611 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.632 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.668 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.682 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.706 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.731 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.755 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.779 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.799 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.822 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.847 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.868 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.901 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.917 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.961 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:21.991 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.030 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.060 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.080 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.102 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.175 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.218 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.241 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.269 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.292 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.311 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.336 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.356 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.380 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.402 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.428 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.450 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.474 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.498 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.521 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.544 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.570 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.590 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.614 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.644 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.660 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.728 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.752 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.775 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.851 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.875 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.898 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.944 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.981 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:22.999 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:23.013 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:23.037 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:23.059 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:23.082 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:23.106 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:23.128 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:23.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:23.178 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:23.197 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:26:23.314 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1057 completion_tokens=259 total_tokens=1316
2024-07-08 16:26:23.315 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
您好！我是人工智能助手，有什么可以帮助您的吗？如果您有关于`LangChain`的具体问题，请随时提问，我会尽力为您提供准确和相关的答案。

如果您的问题是关于如何使用`LangChain`进行自然语言处理，我可以为您提供一些基本的信息。`LangChain`是一个开源的自然语言处理框架，它提供了丰富的工具和库，用于处理各种自然语言任务，如文本分类、命名实体识别、情感分析等。它基于Python语言，易于安装和使用。您可以在其官方网站[LangChain官网](https://www.langchain.org/)上找到更多关于它的信息。

如果您的问题是关于`LangChain`的某个特定功能或应用，请提供更多的上下文信息，以便我能够为您提供更具体的答案。

如果您的問題是与`LangChain`无关的其他內容，我可能無法提供相關的答案。在这种情况下，我建議您尋找其他適當的來源或專業人士以獲得所需的幫助。

以上是關於`LangChain`的基本信息，如果您有其他問題，請隨時提問。

Sources:
- [LangChain官网](https://www.langchain.org/)
the total timecost is 8.788235425949097

172.20.146.181 - - [08/Jul/2024 16:26:29] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:26:29.839 | WARNING  | server.app.queries:generate_answer:210 - For query: '？？？？', detect the language is 'Chinese'!
2024-07-08 16:26:32.549 | WARNING  | server.app.queries:refine_query:105 - For the query: '？？？？', the refined query is '请问您之前询问关于`LangChain`的问题是什么？这样我可以更好地理解您的需求并提供更准确的回答。'. The timecost is 2.7090954780578613
2024-07-08 16:26:32.550 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？？？？', usage=prompt_tokens=587 completion_tokens=27 total_tokens=614
2024-07-08 16:26:32.783 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '请问您之前询问关于`LangChain`的问题是什么？这样我可以更好地理解您的需求并提供更准确的回答。', k: 10, the timecost is 0.22902441024780273
2024-07-08 16:26:32.840 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？？？？', k: 10, the timecost is 0.28870081901550293
172.20.146.181 - - [08/Jul/2024 16:26:33] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:26:33.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:33.951 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:33.973 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.004 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.051 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.076 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.101 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.174 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.230 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.256 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.276 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.300 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.325 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.352 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.375 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.400 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.425 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.448 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.473 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.500 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.549 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.573 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.602 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.644 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.667 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.717 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.745 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.770 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.815 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.845 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.871 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.897 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.944 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:34.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.020 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.047 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.076 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.107 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.150 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.172 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.197 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.252 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.272 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.296 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.394 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.468 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.499 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.526 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.550 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.573 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.599 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.622 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.648 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.702 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.726 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.751 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.776 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.851 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.874 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=None
2024-07-08 16:26:35.979 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？？？？', usage=prompt_tokens=1333 completion_tokens=80 total_tokens=1413
2024-07-08 16:26:35.980 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？？？？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
对不起，我无法从提供的信息中找到关于'？？？？'的具体答案。我在此为您提供与`LangChain`相关的信息服务。如果您有关于我们的服务或需要帮助的具体问题，请随时提问，我将尽力为您提供准确和相关的答案。

Sources:
- [LangChain官网](https://www.langchain.org/)
the total timecost is 6.141411542892456

172.20.146.181 - - [08/Jul/2024 16:27:29] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:27:29.505 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-08 16:27:33.800 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures all relevant context from the conversation would be:

```
前回の質問に答えてください。LangChainの使い方や特定の機能についての質問です。
```

This question is in Japanese, which matches the original language of the follow-up message, and it references the previous conversation about LangChain without directly using the Assistant's responses. It also remains concise to avoid altering the original intent of the follow-up message.'. The timecost is 4.2943525314331055
2024-07-08 16:27:33.801 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=628 completion_tokens=137 total_tokens=765
2024-07-08 16:27:34.075 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.2728431224822998
2024-07-08 16:27:34.131 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history and the follow-up message from the human, the refined standalone question in Japanese that captures all relevant context from the conversation would be:

```
前回の質問に答えてください。LangChainの使い方や特定の機能についての質問です。
```

This question is in Japanese, which matches the original language of the follow-up message, and it references the previous conversation about LangChain without directly using the Assistant's responses. It also remains concise to avoid altering the original intent of the follow-up message.', k: 10, the timecost is 0.3270101547241211
172.20.146.181 - - [08/Jul/2024 16:27:35] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:27:35.281 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.354 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.380 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.404 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.435 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.454 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.484 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.503 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.535 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.554 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.579 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.604 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.651 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.657 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.685 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.706 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.730 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.756 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.780 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.807 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.831 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.855 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.881 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.905 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.931 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:35.979 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.003 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.057 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.080 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.102 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.126 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.152 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.180 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.206 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.225 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.250 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.299 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.328 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.347 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.373 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.396 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.421 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.446 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.484 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.499 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.551 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.584 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.622 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.695 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.719 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.794 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.818 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.864 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.890 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.912 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:36.935 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.120 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.298 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.324 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.351 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.420 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.422 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.447 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.473 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.495 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.558 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.577 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.612 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.624 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.649 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.675 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.698 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.727 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.746 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.771 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.836 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.853 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.878 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.901 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.925 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:37.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.025 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.053 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.073 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.097 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.122 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.146 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.181 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.260 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.273 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.299 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.325 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.363 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.421 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.459 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.482 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.508 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.530 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.558 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.578 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.602 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.627 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.649 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.674 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.700 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.728 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.751 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.775 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.825 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.850 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.874 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.902 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.925 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:38.973 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.000 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.023 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.048 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.072 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.098 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.122 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.155 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.204 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.227 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.279 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.303 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.330 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.369 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.395 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.466 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.491 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.553 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.583 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.607 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.632 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.672 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.685 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.708 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.736 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.760 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.783 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.807 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.834 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.882 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.913 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.933 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.955 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:39.980 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.009 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.034 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.058 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.084 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.108 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.137 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.157 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.182 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.212 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.232 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.281 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.304 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.329 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.464 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.490 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.513 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.562 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.589 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.613 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.636 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.667 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.699 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.718 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.741 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.766 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.793 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.817 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.890 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.919 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.982 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.983 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:40.993 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.015 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.039 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.071 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.098 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.116 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.140 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.167 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.208 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.215 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.240 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.264 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.338 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.362 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.388 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.415 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.438 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.465 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.486 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.518 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.563 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.595 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.620 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.661 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.683 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.705 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.729 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.756 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.779 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.812 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.828 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.854 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.877 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.904 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.929 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:41.980 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.009 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.032 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.064 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.083 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.106 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.130 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.156 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.186 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.204 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.230 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.278 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.304 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.327 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.357 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.379 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.403 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.429 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.505 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.530 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.554 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.612 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.632 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.657 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.679 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.704 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.731 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.757 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.779 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.829 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.862 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.882 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.910 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.948 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.957 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:42.986 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.008 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.033 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.114 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.115 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.115 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.133 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.158 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.183 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.233 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.281 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.312 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.336 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.362 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.385 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.411 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.461 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.485 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.511 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.535 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.561 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.591 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.609 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.638 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.661 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.685 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.709 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.737 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.763 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.787 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.813 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.836 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.861 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.887 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.911 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.952 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.962 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:43.987 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.011 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.066 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.067 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.088 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.150 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.167 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.190 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.214 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.263 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.294 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.316 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.342 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.378 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.393 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.421 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.446 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.473 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.498 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.526 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.549 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.623 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.654 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.722 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.746 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.774 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.796 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.819 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.890 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.912 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.937 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.959 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:44.981 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.009 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.041 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.062 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.084 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.109 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.131 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.155 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.177 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.200 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.224 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.294 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.315 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.341 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.364 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.388 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.473 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.496 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.511 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.604 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.626 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.697 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.721 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.753 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.775 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.797 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.814 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.850 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:45.865 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.094 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.123 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.164 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.188 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.215 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.236 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.283 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.365 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.383 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.412 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.455 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.482 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.502 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.528 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.552 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.589 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.600 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.626 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.648 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.678 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.722 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.743 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.773 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.797 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.822 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.844 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.871 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.906 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.917 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.958 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.974 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:46.992 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:47.015 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:47.046 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:47.064 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:47.086 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:47.111 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:27:47.256 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1372 completion_tokens=451 total_tokens=1823
2024-07-08 16:27:47.257 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
お客様、こんにちは！どういたしまして、何かお困りでしょうか？ LangChainに関する質問や、サービスについての質問など、どうぞお知らせください。私はそれに答えることができる限り、最大の努力をします。

LangChainは、オープンソースの自然言語処理フレームワークであり、テキスト分類、名前の実体認識、感情分析など、さまざまな自然言語のタスクに対応しています。Python言語ベースで、簡単にインストール・使用できます。詳細は公式ウェブサイト[LangChain公式](https://www.langchain.org/)をご覧ください。

特定の機能や応用についての質問があれば、より具体的な情報を提供していただけますようにお願いします。

質問がLangChainに関連していない場合は、そのことを伝えさせていただき、それに答えることができないと言います。その場合、適切な情報源や専門家に尋ねることをお勧めします。

以上、LangChainに関する基本情報です。他の質問があれば、どうぞお知らせください。

情報源:
- [LangChain公式](https://www.langchain.org/)

文献情報:
現在の質問に直接関連する文献を見つけることができませんでした。
the total timecost is 17.75220775604248

172.20.146.181 - - [08/Jul/2024 16:28:27] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:28:27.591 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-08 16:28:32.317 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Given the conversation history, the follow-up message "？" seems to be a continuation of the human's inquiry. However, without additional context or a clear indication of the human's intent, it's challenging to rewrite the message as a standalone question. If the human's true intent cannot be determined, it is best not to modify the follow-up message to avoid generating an incorrect question.

As the follow-up message is short and lacks context, the refined standalone question based on the conversation history would simply be:

"In relation to the previous discussion about LangChain, what specific information are you seeking?"'. The timecost is 4.72478461265564
2024-07-08 16:28:32.317 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=820 completion_tokens=137 total_tokens=957
2024-07-08 16:28:32.603 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.28475522994995117
2024-07-08 16:28:32.613 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Given the conversation history, the follow-up message "？" seems to be a continuation of the human's inquiry. However, without additional context or a clear indication of the human's intent, it's challenging to rewrite the message as a standalone question. If the human's true intent cannot be determined, it is best not to modify the follow-up message to avoid generating an incorrect question.

As the follow-up message is short and lacks context, the refined standalone question based on the conversation history would simply be:

"In relation to the previous discussion about LangChain, what specific information are you seeking?"', k: 10, the timecost is 0.2922182083129883
172.20.146.181 - - [08/Jul/2024 16:28:33] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:28:33.872 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:33.925 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:33.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:33.974 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.009 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.024 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.053 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.077 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.100 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.125 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.153 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.175 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.229 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.254 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.278 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.302 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.326 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.374 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.398 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.422 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.447 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.470 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.492 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.516 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.540 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.564 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.588 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.618 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.640 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.666 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.692 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.714 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.739 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.782 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.807 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.822 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.847 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.871 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.894 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.919 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.943 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.966 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:34.990 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.014 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.072 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.095 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.119 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.143 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.167 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.197 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.215 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.239 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.263 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.287 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.361 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.382 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.406 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.430 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.457 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.486 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.510 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.563 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.586 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.611 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.640 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.658 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.681 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.709 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.737 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.766 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.777 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.802 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.872 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.899 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.923 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.947 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:35.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.017 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.066 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.091 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.114 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.137 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.162 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.187 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.212 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.234 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.264 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.335 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.361 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.384 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.407 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.432 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.458 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.480 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.503 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.527 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.551 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.579 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.623 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.646 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.682 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.720 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.744 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.780 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.792 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.829 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.839 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.865 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.891 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.916 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.943 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.965 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:36.986 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.011 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.043 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.057 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.081 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.106 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.131 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.156 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.204 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.227 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.252 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.299 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.322 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.346 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.394 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.419 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.466 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.491 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.572 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.595 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.621 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.645 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.695 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.718 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.746 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.768 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.793 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.832 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.846 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.873 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.897 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.948 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.970 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:37.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.021 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.053 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.068 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.094 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.117 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.142 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.203 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.215 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.241 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.273 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.293 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.321 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.343 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.373 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.418 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.441 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.469 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.495 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.519 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.566 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.591 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.618 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.641 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.665 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.697 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.720 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.748 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.775 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.796 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.820 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.846 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.869 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.902 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.922 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:38.979 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.004 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.027 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.103 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.104 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.105 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.133 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.178 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.225 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.252 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.281 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.303 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.340 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.354 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.377 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.402 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.431 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.455 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.480 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.504 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.561 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.632 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.664 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.705 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.712 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.741 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.763 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.799 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.810 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.855 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.862 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.889 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.920 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.961 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.962 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:39.985 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.022 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.037 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.072 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.086 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.112 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.154 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.172 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.197 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.300 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.324 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.348 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.376 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.401 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.426 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.449 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.476 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.500 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.553 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.600 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.625 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.649 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.674 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.698 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.722 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.752 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.817 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.842 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.869 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.893 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.916 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.942 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.966 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:40.989 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.013 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.063 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.089 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.114 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.147 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.165 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.186 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.243 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.286 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.311 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.346 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.396 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.420 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.444 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.466 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.491 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.533 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.561 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.571 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.871 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.896 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.922 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.947 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.971 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:41.997 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.022 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.046 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.073 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.096 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.120 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.150 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.173 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.198 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.225 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.252 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.285 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.301 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.325 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.377 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.400 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.425 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.450 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.475 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.504 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.529 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.555 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.584 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.611 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.633 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.659 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.686 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.712 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.737 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.800 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.813 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.838 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.864 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.891 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.917 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.941 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.967 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:42.992 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.019 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.048 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.069 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.094 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.171 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.247 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.280 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.296 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.325 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.347 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.373 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.399 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.425 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.477 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.502 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.536 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.555 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.575 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.599 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.630 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.672 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.721 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.745 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.769 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.801 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.880 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.905 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.930 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:43.954 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:44.018 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:44.060 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:44.084 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:44.109 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:44.132 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:44.156 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:28:44.280 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1564 completion_tokens=394 total_tokens=1958
2024-07-08 16:28:44.281 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
お客様、こんにちは！どういたしまして、何かお困りでしょうか？ LangChainに関する質問や、サービスについての質問など、どうぞお知らせください。私はそれに答えることができる限り、最大の努力をします。

LangChainは、オープンソースの自然言語処理フレームワークであり、テキスト分類、名前の実体認識、感情分析など、さまざまな自然言語のタスクに対応しています。Python言語ベースで、簡単にインストール・使用できます。詳細は公式ウェブサイト[LangChain公式](https://www.langchain.org/)をご覧ください。

特定の機能や応用についての質問があれば、より具体的な情報を提供していただけますようにお願いします。

質問がLangChainに関連していない場合は、そのことを伝えさせていただき、それに答えることができないと言います。その場合、適切な情報源や専門家に尋ねることをお勧めします。

以上、LangChainに関する基本情報です。他の質問があれば、どうぞお知らせください。
the total timecost is 16.69029402732849

172.20.146.181 - - [08/Jul/2024 16:28:46] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:28:46.713 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-08 16:29:02.979 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Messages from Human:
- **Human:** ？
- **Human:** ？

Messages from Assistant:
- **Assistant:** お客様、こんにちは！どういたしまして、何かお困りでしょうか？ LangChainに関する質問や、サービスについての質問など、どうぞお知らせください。私はそれに答えることができる限り、最大の努力をします。
- **Assistant:** LangChainは、オープンソースの自然言語処理フレームワークであり、テキスト分類、名前の実体認識、感情分析など、さまざまな自然言語のタスクに対応しています。Python言語ベースで、簡単にインストール・使用できます。詳細は公式ウェブサイト[LangChain公式](https://www.langchain.org/)をご覧ください。
- **Assistant:** 特定の機能や応用についての質問があれば、より具体的な情報を提供していただけますようにお願いします。
- **Assistant:** 質問がLangChainに関連していない場合は、そのことを伝えさせていただき、それに答えることができないと言います。その場合、適切な情報源や専門家に尋ねることをお勧めします。
- **Assistant:** 以上、LangChainに関する基本情報です。他の質問があれば、どうぞお知らせください。
- **Assistant:** 情報源:
  - [LangChain公式](https://www.langchain.org/)

Refined Standalone Question: お客様が最初に送信した「？」というメッセージに基づいて、どのような質問がありましたか？LangChainに関する質問や、サービスについての質問など、お知らせください。'. The timecost is 16.264931678771973
2024-07-08 16:29:02.980 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=1133 completion_tokens=562 total_tokens=1695
2024-07-08 16:29:03.293 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.31269049644470215
2024-07-08 16:29:03.336 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Messages from Human:
- **Human:** ？
- **Human:** ？

Messages from Assistant:
- **Assistant:** お客様、こんにちは！どういたしまして、何かお困りでしょうか？ LangChainに関する質問や、サービスについての質問など、どうぞお知らせください。私はそれに答えることができる限り、最大の努力をします。
- **Assistant:** LangChainは、オープンソースの自然言語処理フレームワークであり、テキスト分類、名前の実体認識、感情分析など、さまざまな自然言語のタスクに対応しています。Python言語ベースで、簡単にインストール・使用できます。詳細は公式ウェブサイト[LangChain公式](https://www.langchain.org/)をご覧ください。
- **Assistant:** 特定の機能や応用についての質問があれば、より具体的な情報を提供していただけますようにお願いします。
- **Assistant:** 質問がLangChainに関連していない場合は、そのことを伝えさせていただき、それに答えることができないと言います。その場合、適切な情報源や専門家に尋ねることをお勧めします。
- **Assistant:** 以上、LangChainに関する基本情報です。他の質問があれば、どうぞお知らせください。
- **Assistant:** 情報源:
  - [LangChain公式](https://www.langchain.org/)

Refined Standalone Question: お客様が最初に送信した「？」というメッセージに基づいて、どのような質問がありましたか？LangChainに関する質問や、サービスについての質問など、お知らせください。', k: 10, the timecost is 0.35330891609191895
172.20.146.181 - - [08/Jul/2024 16:29:04] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:29:04.625 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:04.648 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
172.20.146.181 - - [08/Jul/2024 16:29:19] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:29:19.141 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-08 16:29:36.621 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'Messages from Human:
- **Human:** ？
- **Human:** ？

Messages from Assistant:
- **Assistant:** お客様、こんにちは！どういたしまして、何かお困りでしょうか？ LangChainに関する質問や、サービスについての質問など、どうぞお知らせください。私はそれに答えることができる限り、最大の努力をします。
- **Assistant:** LangChainは、オープンソースの自然言語処理フレームワークであり、テキスト分類、名前の実体認識、感情分析など、さまざまな自然言語のタスクに対応しています。Python言語ベースで、簡単にインストール・使用できます。詳細は公式ウェブサイト[LangChain公式](https://www.langchain.org/)をご覧ください。
- **Assistant:** 特定の機能や応用についての質問があれば、より具体的な情報を提供していただけますようにお願いします。
- **Assistant:** 質問がLangChainに関連していない場合は、そのことを伝えさせていただき、それに答えることができないと言います。その場合、適切な情報源や専門家に尋ねることをお勧めします。
- **Assistant:** 以上、LangChainに関する基本情報です。他の質問があれば、どうぞお知らせください。
- **Assistant:** 情報源:
  - [LangChain公式](https://www.langchain.org/)

Refined Standalone Question: お客様が最初に送信した「？」というメッセージに基づいて、LangChainに関するどのような質問がありましたか？具体的な質問内容を教えていただけますか？'. The timecost is 17.479336500167847
2024-07-08 16:29:36.622 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=1133 completion_tokens=552 total_tokens=1685
2024-07-08 16:29:38.113 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 1.4906928539276123
2024-07-08 16:29:38.171 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'Messages from Human:
- **Human:** ？
- **Human:** ？

Messages from Assistant:
- **Assistant:** お客様、こんにちは！どういたしまして、何かお困りでしょうか？ LangChainに関する質問や、サービスについての質問など、どうぞお知らせください。私はそれに答えることができる限り、最大の努力をします。
- **Assistant:** LangChainは、オープンソースの自然言語処理フレームワークであり、テキスト分類、名前の実体認識、感情分析など、さまざまな自然言語のタスクに対応しています。Python言語ベースで、簡単にインストール・使用できます。詳細は公式ウェブサイト[LangChain公式](https://www.langchain.org/)をご覧ください。
- **Assistant:** 特定の機能や応用についての質問があれば、より具体的な情報を提供していただけますようにお願いします。
- **Assistant:** 質問がLangChainに関連していない場合は、そのことを伝えさせていただき、それに答えることができないと言います。その場合、適切な情報源や専門家に尋ねることをお勧めします。
- **Assistant:** 以上、LangChainに関する基本情報です。他の質問があれば、どうぞお知らせください。
- **Assistant:** 情報源:
  - [LangChain公式](https://www.langchain.org/)

Refined Standalone Question: お客様が最初に送信した「？」というメッセージに基づいて、LangChainに関するどのような質問がありましたか？具体的な質問内容を教えていただけますか？', k: 10, the timecost is 1.5463428497314453
172.20.146.181 - - [08/Jul/2024 16:29:39] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:29:39.403 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.445 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.469 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.493 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.522 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.548 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.569 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.593 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.617 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.640 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.669 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.691 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.719 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.743 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.768 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.792 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.818 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.866 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.889 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.913 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.937 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.961 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:39.985 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.010 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.033 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.058 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.083 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.106 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.134 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.160 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.182 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.231 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.254 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.282 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.304 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.330 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.352 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.376 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.401 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.426 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.450 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.473 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.498 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.523 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.552 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.580 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.607 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.627 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.695 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.718 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:40.742 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.693 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.717 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.743 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.820 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.848 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.868 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.893 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.917 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.944 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.974 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:41.999 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.023 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.047 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.073 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.110 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.121 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.148 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.199 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.223 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.248 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.273 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.535 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.536 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.536 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.537 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.537 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.538 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.539 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.539 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.919 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.920 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.948 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.949 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.950 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.950 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.951 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.951 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.952 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.952 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.953 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.954 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.954 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.978 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:42.993 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.018 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.042 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.070 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.095 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.124 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.145 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.167 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.193 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.215 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.249 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.277 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.299 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.323 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.359 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.394 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.422 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.446 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.465 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.492 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.521 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:43.539 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.174 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.175 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.177 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.177 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.203 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.204 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.205 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.205 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.206 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.206 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.208 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.208 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.232 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.242 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.266 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.293 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.314 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.342 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.371 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.417 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.439 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.512 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.524 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.547 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.573 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.620 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.644 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.672 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.696 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.719 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.741 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.766 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.792 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.820 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.850 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.867 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.887 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.910 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.964 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:44.982 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.005 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.034 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.053 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.077 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.104 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.129 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.179 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.202 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.226 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.250 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.274 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.299 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.327 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.427 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.481 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.502 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.526 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.550 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.574 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.623 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.649 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.676 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.700 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.725 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.749 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.773 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.801 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.822 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.849 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.872 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.898 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.921 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:45.948 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.020 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.047 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.069 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.097 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.122 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.144 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.169 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.195 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.218 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.245 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.268 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.303 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.318 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.347 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.366 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.393 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.417 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.442 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.465 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.490 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.516 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.540 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.567 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.593 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.616 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.640 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.666 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.689 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.731 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.739 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.764 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.789 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.814 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.839 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.863 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.889 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.914 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.940 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.965 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:46.992 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.017 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.041 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.066 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.092 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.164 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.205 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.214 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.239 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.474 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.499 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.525 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.549 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.575 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.601 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.626 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.653 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.677 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.702 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.728 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.759 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.784 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.809 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.836 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.861 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.892 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.915 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.941 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.965 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:47.994 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.017 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.041 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.069 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.102 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.120 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.143 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.169 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.219 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.220 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.323 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.324 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.324 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.326 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.346 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.374 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.397 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.426 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.453 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.482 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.499 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.527 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.552 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.576 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.611 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.627 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.659 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.678 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.710 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.738 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.759 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.784 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.809 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.839 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.859 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.885 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.914 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.934 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.961 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:48.990 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.012 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.036 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.063 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.087 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.111 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.134 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.157 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.183 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.210 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.233 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.257 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.279 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.304 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.327 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.352 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.392 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.406 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.517 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.565 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.589 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.614 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.635 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.658 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.683 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.707 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.730 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.762 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.778 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.801 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.843 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.883 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.904 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.932 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.958 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.976 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:49.998 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.023 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.045 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.069 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.092 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.118 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.141 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.213 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.290 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.315 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.338 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.361 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.386 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.411 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.436 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.465 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.482 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.576 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.596 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.623 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.701 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.717 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.747 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.763 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.787 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.810 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.835 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.857 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.881 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.905 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:50.931 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:51.318 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:51.318 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:51.324 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:51.375 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:51.395 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:29:51.512 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=prompt_tokens=1877 completion_tokens=418 total_tokens=2295
2024-07-08 16:29:51.513 | SUCCESS  | server.app.queries:generate_llm:451 - query: '？' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
お客様、こんにちは！どういたしまして、何かお困りでしょうか？LangChainに関する質問や、サービスについての質問など、どうぞお知らせください。私はそれに答えることができる限り、最大の努力をします。

LangChainは、オープンソースの自然言語処理フレームワークであり、テキスト分類、名前の実体認識、感情分析など、さまざまな自然言語のタスクに対応しています。Python言語ベースで、簡単にインストール・使用できます。詳細は公式ウェブサイト[LangChain公式](https://www.langchain.org/)をご覧ください。

特定の機能や応用についての質問があれば、より具体的な情報を提供していただけますようにお願いします。

質問がLangChainに関連していない場合は、そのことを伝えさせていただき、それに答えることができないと言います。その場合、適切な情報源や専門家に尋ねることをお勧めします。

以上、LangChainに関する基本情報です。他の質問があれば、どうぞお知らせください。

情報源:
- [LangChain公式](https://www.langchain.org/)
the total timecost is 32.373093605041504

172.20.146.181 - - [08/Jul/2024 16:30:01] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:30:01.601 | WARNING  | server.app.queries:generate_answer:210 - For query: '？', detect the language is 'Japanese'!
2024-07-08 16:30:05.525 | WARNING  | server.app.queries:refine_query:105 - For the query: '？', the refined query is 'LangChainについて、公式ウェブサイトを参照していましたが、より詳細な情報を提供していただけますか？特に、Python言語ベースのLangChainの簡単なインストール方法や、自然言語処理の機能についての詳細な情報を求めています。'. The timecost is 3.923297643661499
2024-07-08 16:30:05.526 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '？', usage=prompt_tokens=1100 completion_tokens=97 total_tokens=1197
2024-07-08 16:30:05.787 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: 'LangChainについて、公式ウェブサイトを参照していましたが、より詳細な情報を提供していただけますか？特に、Python言語ベースのLangChainの簡単なインストール方法や、自然言語処理の機能についての詳細な情報を求めています。', k: 10, the timecost is 0.25786876678466797
2024-07-08 16:30:05.801 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '？', k: 10, the timecost is 0.2739379405975342
172.20.146.181 - - [08/Jul/2024 16:30:07] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:30:07.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
2024-07-08 16:30:07.216 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '？', usage=None
172.20.146.181 - - [08/Jul/2024 16:47:46] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:47:46.273 | WARNING  | server.app.queries:generate_answer:210 - For query: '您好', detect the language is 'Chinese'!
2024-07-08 16:47:48.154 | WARNING  | server.app.queries:refine_query:105 - For the query: '您好', the refined query is '您好！请问您之前提到的LangChain是什么，它能用于哪些自然语言处理任务？'. The timecost is 1.8803341388702393
2024-07-08 16:47:48.155 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '您好', usage=prompt_tokens=1100 completion_tokens=22 total_tokens=1122
2024-07-08 16:47:48.435 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '您好', k: 10, the timecost is 0.27903056144714355
2024-07-08 16:47:48.475 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '您好！请问您之前提到的LangChain是什么，它能用于哪些自然语言处理任务？', k: 10, the timecost is 0.31711292266845703
172.20.146.181 - - [08/Jul/2024 16:47:49] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 16:47:49.799 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:49.818 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:49.847 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:49.870 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:49.902 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:49.920 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:49.945 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:49.997 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.050 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.075 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.101 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.125 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.151 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.176 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.207 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.225 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.250 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.276 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.300 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.329 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.355 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.381 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.408 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.430 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.458 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.480 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.505 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.534 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.563 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.582 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.608 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.632 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.662 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.687 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.710 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.735 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.760 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.785 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.808 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:50.832 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.430 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.450 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.475 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.501 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.533 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.552 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.575 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.600 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.628 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.649 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.674 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.701 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.781 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.804 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.831 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.852 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.882 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.900 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.923 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.948 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.972 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:51.996 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.196 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.222 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.248 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.270 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.295 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.320 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.345 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.370 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.394 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.418 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.444 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.469 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.495 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.520 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.545 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.574 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.598 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.625 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.685 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.700 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.724 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.777 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.802 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.828 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.852 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.876 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.902 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.928 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.951 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:52.976 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.001 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.028 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.055 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.097 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.105 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.131 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.155 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.184 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.211 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.234 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.259 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.283 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.306 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.331 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.357 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.379 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.403 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.428 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.452 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.572 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.573 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.576 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.601 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.637 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.651 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.673 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.698 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.721 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.747 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.769 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.796 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.824 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.842 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.866 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.891 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.916 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.942 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.965 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:53.991 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.020 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.036 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.061 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.084 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.111 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.133 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.157 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.181 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.203 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.232 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.253 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.276 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.302 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.326 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.350 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.375 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.399 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.423 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.448 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.472 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.545 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.568 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.593 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.617 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.650 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.667 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.692 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.715 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.740 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.764 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.788 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.825 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.837 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.864 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.886 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.909 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.934 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.958 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:54.983 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.112 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.136 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.161 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.209 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.234 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.258 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.282 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.315 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.330 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.360 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.383 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.409 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.434 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.457 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.480 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.521 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.530 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.574 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.578 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.602 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=None
2024-07-08 16:47:55.713 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '您好', usage=prompt_tokens=1844 completion_tokens=202 total_tokens=2046
2024-07-08 16:47:55.714 | SUCCESS  | server.app.queries:generate_llm:451 - query: '您好' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
您好！我是LangChain的人工智能助手，很高兴为您服务。请问有什么可以帮助您的吗？如果您有任何关于LangChain的问题，或者需要我们的服务帮助，请随时告诉我，我会尽我最大的努力为您提供准确和相关的答案。

LangChain是一个开源的自然语言处理框架，能够应对各种自然语言任务，如文本分类、实体识别、情感分析等。基于Python语言，易于安装和使用。更多信息请查看我们的官方网站[LangChain官方](https://www.langchain.org/)。

如果您有关于特定功能或应用的问题，我可以为您提供更具体的信息。如果您的问题与LangChain无关，我会告知您这一点，并建议您向适当的资料来源或专家咨询。

以上是关于LangChain的基本信息。如果您有其他问题，请随时告诉我。

资料来源：
- [LangChain官方](https://www.langchain.org/)
the total timecost is 9.441723585128784

Traceback (most recent call last):
  File "rag_gpt_app.py", line 2, in <module>
    from dotenv import load_dotenv
ModuleNotFoundError: No module named 'dotenv'
172.20.146.181 - - [08/Jul/2024 17:27:21] "OPTIONS /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 17:27:21.236 | WARNING  | server.app.queries:generate_answer:210 - For query: '你好', detect the language is 'Chinese'!
2024-07-08 17:27:22.775 | WARNING  | server.app.queries:refine_query:105 - For the query: '你好', the refined query is '你好，请问您之前和助手交流了什么内容？您想继续询问关于 `LangChain` 的哪些具体问题？'. The timecost is 1.5381453037261963
2024-07-08 17:27:22.776 | WARNING  | server.app.queries:refine_query:107 - [Track token consumption] for refine_query: '你好', usage=prompt_tokens=323 completion_tokens=30 total_tokens=353
2024-07-08 17:27:23.699 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好', k: 10, the timecost is 0.9221596717834473
2024-07-08 17:27:23.715 | WARNING  | server.app.queries:search_documents:115 - search_documents, query: '你好，请问您之前和助手交流了什么内容？您想继续询问关于 `LangChain` 的哪些具体问题？', k: 10, the timecost is 0.9362144470214844
172.20.146.181 - - [08/Jul/2024 17:27:24] "POST /open_kf_api/queries/smart_query_stream HTTP/1.1" 200 -
2024-07-08 17:27:24.699 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.720 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.743 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.766 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.789 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.812 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.835 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.858 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.883 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.904 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.927 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.952 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:24.976 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.000 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.022 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.046 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.069 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.092 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.185 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.208 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.232 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.256 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.314 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.338 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.363 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.390 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.421 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.436 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.492 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.514 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.537 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.574 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.597 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.621 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.644 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.675 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.692 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.788 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.813 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.858 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:25.900 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=None
2024-07-08 17:27:26.000 | WARNING  | server.app.queries:generate_llm:447 - [Track token consumption of streaming] for smart_query_stream: '你好', usage=prompt_tokens=1067 completion_tokens=43 total_tokens=1110
2024-07-08 17:27:26.001 | SUCCESS  | server.app.queries:generate_llm:451 - query: '你好' and user_id: '9ddc73e1-4992-4618-9e58-5bdf57bf3b91' is processed successfully, the answer is:
你好！我是人工智能助手，很高兴为您服务。请问有什么可以帮助您的吗？如果您有任何关于LangChain的问题或需要帮助，请随时告诉我，我会尽力为您提供准确和相关的答案。
the total timecost is 4.765963554382324

